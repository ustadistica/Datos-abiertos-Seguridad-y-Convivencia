# -*- coding: utf-8 -*-
"""22y24.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xuwKxFa-AsM3FmVee94E4CLgUlyrXYqr
"""



"""2022"""

import pandas as pd

def cargar_delito(url, delito, debug=False):
    # Posibles filas de encabezado (var√≠a entre archivos)
    posibles_headers = [9, 10, 11, 12, 8, 7, 6, 13, 14, 15]

    for header_row in posibles_headers:
        try:
            df = pd.read_excel(url, header=header_row).copy()

            # üîß Normalizar nombres de columnas
            df.columns = (
                df.columns.astype(str)
                .str.strip()
                .str.upper()
                .str.replace(" ", "_")
                .str.replace("*", "")
                .str.replace("/", "_")
            )

            if debug:
                print(f"\nüîç {delito} - Header {header_row}:")
                print(f"Columnas encontradas: {list(df.columns[:10])}")

            # üî§ Corregir errores comunes de nombres
            renombrar = {
                "ARMAS_MEDIOS": "ARMAS_MEDIOS",
                "ARMAS_MEDIO": "ARMAS_MEDIOS",
                "ARMA_MEDIO": "ARMAS_MEDIOS",
                "ARMAS_Y_MEDIOS": "ARMAS_MEDIOS",
                "CODIGO_DANE": "CODIGO_DANE",
                "FECHA": "FECHA_HECHO",
                "FECHA_HECHO": "FECHA_HECHO",
                "GENERO": "GENERO",
                "CANTIDAD": "CANTIDAD",
                "AGRUPA_EDAD_PERSONA": "AGRUPA_EDAD_PERSONA",
                "AGRUPA_EDAD_PER_SONA": "AGRUPA_EDAD_PERSONA",
                "MUNICICPIO": "MUNICIPIO",  # üëà Corregido
                "DEPARTAMENTO_": "DEPARTAMENTO",  # por si hay espacio o guion
            }
            df = df.rename(columns=lambda x: renombrar.get(x, x))

            # üîç Filtrar columnas v√°lidas
            columnas_validas = [
                "DEPARTAMENTO", "MUNICIPIO", "CODIGO_DANE",
                "ARMAS_MEDIOS", "FECHA_HECHO", "GENERO",
                "AGRUPA_EDAD_PERSONA", "CANTIDAD"
            ]
            columnas_presentes = [col for col in columnas_validas if col in df.columns]
            tiene_ubicacion = "DEPARTAMENTO" in columnas_presentes or "MUNICIPIO" in columnas_presentes
            tiene_suficientes = len(columnas_presentes) >= 3

            if not (tiene_ubicacion and tiene_suficientes):
                if debug:
                    print(f"   ‚ùå Solo tiene {len(columnas_presentes)} columnas v√°lidas: {columnas_presentes}")
                continue

            if debug:
                print(f"   ‚úÖ Tiene {len(columnas_presentes)} columnas v√°lidas: {columnas_presentes}")

            df = df[[col for col in columnas_validas if col in df.columns]]

            # üßπ Eliminar filas completamente vac√≠as
            df = df.dropna(how="all")

            # üßπ Eliminar filas donde las columnas de ubicaci√≥n est√©n vac√≠as
            if "DEPARTAMENTO" in df.columns and "MUNICIPIO" in df.columns:
                df = df.dropna(subset=["DEPARTAMENTO", "MUNICIPIO"], how="all")
            elif "DEPARTAMENTO" in df.columns:
                df = df.dropna(subset=["DEPARTAMENTO"])
            elif "MUNICIPIO" in df.columns:
                df = df.dropna(subset=["MUNICIPIO"])

            # üß± Cortar desde "TOTAL" hacia abajo si aparece
            for col in ["DEPARTAMENTO", "MUNICIPIO", "ARMAS_MEDIOS"]:
                if col in df.columns:
                    mask_total = df[col].astype(str).str.contains("TOTAL", na=False, case=False)
                    if mask_total.any():
                        primera_fila_total = mask_total.idxmax()
                        df = df.loc[:primera_fila_total - 1]
                        break

            # üßΩ Limpieza reforzada
            basura_regex = (
                "TOTAL|FUENTE|SIEDCO|Elaborado|Revisado|Autorizado|Ley 1098|"
                "Agrupaci√≥n referente|Contador|DUIN|POLIC√çA NACIONAL|"
                "DIRECCI√ìN|GRUPO DE INFORMACI√ìN|LESIONES|PER√çODO|MINISTERIO"
            )
            for col in ["DEPARTAMENTO", "MUNICIPIO", "ARMAS_MEDIOS"]:
                if col in df.columns:
                    df = df[~df[col].astype(str).str.contains(basura_regex, na=False, case=False)]

            # Eliminar filas vac√≠as o con solo espacios
            df = df[df.apply(lambda row: row.astype(str).str.strip().str.len().gt(0).any(), axis=1)]

            # Eliminar filas sin municipio
            if "MUNICIPIO" in df.columns:
                df = df[df["MUNICIPIO"].notna() & (df["MUNICIPIO"].astype(str).str.strip() != "")]

            # Convertir c√≥digo DANE a num√©rico
            if "CODIGO_DANE" in df.columns:
                df["CODIGO_DANE"] = pd.to_numeric(df["CODIGO_DANE"], errors="coerce")

            # Agregar tipo de delito
            df["TIPO_DELITO"] = delito

            if not df.empty:
                print(f"üìå {delito}: encabezado fijo en fila {header_row}")
                return df

        except Exception as e:
            if debug:
                print(f"‚ùå Error en header {header_row}: {str(e)}")
            continue

    print(f"‚ö†Ô∏è {delito}: no se pudo leer con headers {posibles_headers}")
    if debug:
        print(f"   Intenta ejecutar: cargar_delito('{url}', '{delito}', debug=True)")
    return pd.DataFrame()

# Diccionario de URLs y delitos 2022
urls_2022 = [
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/abigeato.xls_2.xlsx", "HURTO CABEZAS GANADO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/amenazas_13.xls", "AMENAZAS"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/delitos_sexuales_11.xls", "DELITOS SEXUALES"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/extorsion_11.xls", "EXTORSI√ìN"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/Homicidio%20Intencional%202022.xlsx", "HOMICIDIO INTENCIONAL"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/homicidios_en_accidente_de_transito_11.xls", "HOMICIDIOS EN ACCIDENTE DE TR√ÅNSITO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto_a_personas_17.xlsx", "HURTO A PERSONAS"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto_a_residencias_4.xls", "HURTO A RESIDENCIAS"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto_automotores_4.xls", "HURTO AUTOMOTORES"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto_a_motocicletas_7.xls", "HURTO MOTOCICLETAS"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto_a_comercio_11.xls", "HURTO A COMERCIO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto_entidades_financieras_11.xls", "HURTO A ENTIDADES FINANCIERAS"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/lesiones_en_accidente_de_transito_7.xlsx", "LESIONES EN ACCIDENTE DE TR√ÅNSITO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/lesiones_personales_0.xlsx", "LESIONES PERSONALES"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto_a_pirateria_terrestre_11.xls", "PIRATER√çA TERRESTRE"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/secuestro_11.xls", "SECUESTRO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/terrorismo_11.xls", "TERRORISMO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/violencia_intrafamiliar_12.xls", "VIOLENCIA INTRAFAMILIAR"),
]

# Procesar todos los archivos
dfs_2022 = []
for url, delito in urls_2022:
    df = cargar_delito(url, delito)
    if not df.empty:
        dfs_2022.append(df)
        print(f"‚úÖ {delito}: {df.shape[0]} filas")

# Concatenar todo en un solo DataFrame
df_2022 = pd.concat(dfs_2022, ignore_index=True)

# Ordenar por MUNICIPIO y DEPARTAMENTO
df_2022 = df_2022.sort_values(by=["MUNICIPIO", "DEPARTAMENTO"]).reset_index(drop=True)

print(f"\n Total final 2022: {df_2022.shape[0]} filas y {df_2022.shape[1]} columnas")
display(df_2022.head())

# === 14. Valores √∫nicos por columna en df_2018 ===
for col in df_2022.columns:
    print(f"\n=== {col} ===")
    print(df_2022[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {df_2022[col].nunique()}")

# Commented out IPython magic to ensure Python compatibility.
# %pip install unidecode

import pandas as pd
import numpy as np
import unidecode
import re

# --- Estandarizar DEPARTAMENTO ---
df_2022['DEPARTAMENTO'] = df_2022['DEPARTAMENTO'].astype(str).str.strip().str.upper()
df_2022['DEPARTAMENTO'] = df_2022['DEPARTAMENTO'].apply(lambda x: unidecode.unidecode(x))

# --- Estandarizar MUNICIPIO ---
def limpiar_municipio(nombre):
    if pd.isna(nombre):
        return nombre
    nombre = str(nombre).upper().strip()
    nombre = re.sub(r'\(CT\)', '', nombre)  # eliminar (CT)
    nombre = unidecode.unidecode(nombre)     # quitar tildes
    return nombre

df_2022['MUNICIPIO'] = df_2022['MUNICIPIO'].apply(limpiar_municipio)

# Reemplazar 'NAN' como string por NaN
df_2022['MUNICIPIO'] = df_2022['MUNICIPIO'].replace('NAN', np.nan)

# Opcional: eliminar filas donde MUNICIPIO sea NaN
df_2022 = df_2022.dropna(subset=['MUNICIPIO'])

# --- Arreglar FECHA_HECHO ---
def convertir_fecha(valor):
    if isinstance(valor, (float, int)):
        valor_str = str(int(valor))
        return pd.to_datetime(valor_str, format='%Y%m%d', errors='coerce')
    else:
        return pd.to_datetime(valor, errors='coerce')

df_2022['FECHA_HECHO'] = df_2022['FECHA_HECHO'].apply(convertir_fecha)

# --- Resumen de nulos ---
resumen_nulos = pd.DataFrame({
    'Columna': df_2022.columns,
    'Nulos': df_2022.isnull().sum(),
    'Porcentaje_nulos': df_2022.isnull().mean() * 100
})

print(resumen_nulos)

for col in df_2022.columns:
    print(f"\n=== {col} ===")
    print(df_2022[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {df_2022[col].nunique()}")

df_2022.isna().sum()

df_2022['MUNICIPIO'].value_counts(dropna=False).head(10)

print(df_2022['MUNICIPIO'].dtype)   # tipo de dato real
print(df_2022['MUNICIPIO'].isna().sum())  # conteo de nulos
print(df_2022['MUNICIPIO'].head(20))      # primeros valores

df_2022[df_2022['MUNICIPIO'].isna()]

# Ordenar alfab√©ticamente por MUNICIPIO
df_2022 = df_2022.sort_values(by=["MUNICIPIO"], ascending=True).reset_index(drop=True)

print(f"\n Total ordenado: {df_2022.shape[0]} filas y {df_2022.shape[1]} columnas")
display(df_2022.head(20))  # muestra los primeros 20 municipios ordenados

import pandas as pd
import numpy as np

# Crear tabla resumen de nulos
resumen_nulos = pd.DataFrame({
    'Columna': df_2022.columns,
    'Nulos': df_2022.isnull().sum(),
    'NaN explicitos': df_2022.apply(lambda x: x.isna().sum())
})

# Ordenar opcionalmente de mayor a menor nulos
resumen_nulos = resumen_nulos.sort_values(by='Nulos', ascending=False).reset_index(drop=True)

print(resumen_nulos)

import numpy as np

# Reemplazar 'NAN' como string por valores NaN
df_2022['MUNICIPIO'] = df_2022['MUNICIPIO'].replace('NAN', np.nan)

# Ahora contamos nulos y NaN
resumen_nulos = pd.DataFrame({
    'Columna': df_2022.columns,
    'Nulos': df_2022.isnull().sum(),
    'Porcentaje_nulos': df_2022.isnull().mean() * 100
})

print(resumen_nulos)

import numpy as np

# Asegurarnos de que los 'NAN' como texto sean NaN reales
df_2022['MUNICIPIO'].replace('NAN', np.nan, inplace=True)

# Eliminar filas donde MUNICIPIO sea NaN
df_2022 = df_2022.dropna(subset=['MUNICIPIO'])

# Revisar
print(df_2022['MUNICIPIO'].isnull().sum())  # deber√≠a dar 0

import numpy as np

# Reemplazar 'NAN' como string por valores NaN
df_2022['MUNICIPIO'] = df_2022['MUNICIPIO'].replace('NAN', np.nan)

# Ahora contamos nulos y NaN
resumen_nulos = pd.DataFrame({
    'Columna': df_2022.columns,
    'Nulos': df_2022.isnull().sum(),
    'Porcentaje_nulos': df_2022.isnull().mean() * 100
})

print(resumen_nulos)

for col in df_2022.columns:
    print(f"\n=== {col} ===")
    print(df_2022[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {df_2022[col].nunique()}")

"""Poblacion Y DAVIPOLA"""

import pandas as pd
import requests
import numpy as np

# --------------------------
# URLs de insumos externos
# --------------------------
url_poblacion = "https://www.dane.gov.co/files/censo2018/proyecciones-de-poblacion/Municipal/PPED-AreaSexoEdadMun-2018-2042_VP.xlsx"
api_url_divipola = "https://www.datos.gov.co/resource/gdxc-w37w.json?$limit=2000"

# Cargar DIVIPOLA desde la API de datos abiertos
divipola = pd.read_json(api_url_divipola)

# Mostrar las columnas originales
print("üßê Columnas originales en DIVIPOLA:")
print(divipola.columns.tolist())

# (Opcional) ver las primeras filas
display(divipola.head())

df_2022['MUNICIPIO'] = (
    df_2022['MUNICIPIO']
    .astype(str)
    .str.strip()
    .str.upper()
    .apply(lambda x: unidecode.unidecode(x))
)

df_2022['DEPARTAMENTO'] = (
    df_2022['DEPARTAMENTO']
    .astype(str)
    .str.strip()
    .str.upper()
    .apply(lambda x: unidecode.unidecode(x))
)

# =========================================================
# üîó MERGE FINAL: Base de delitos + DIVIPOLA (A√±o 2020)
# =========================================================

# --- 1. Importar librer√≠as ---
import pandas as pd
import unidecode

# --- 2. Normalizaci√≥n de texto ---
def normalizar(texto):
    """Convierte a may√∫sculas, elimina tildes, espacios extra y caracteres no est√°ndar"""
    if pd.isna(texto):
        return ''
    texto = str(texto).strip().upper()
    texto = unidecode.unidecode(texto)
    texto = ' '.join(texto.split())  # elimina dobles espacios
    return texto

# --- 3. Estandarizar nombres en ambas bases ---
df_2022['DEPARTAMENTO'] = df_2022['DEPARTAMENTO'].apply(normalizar)
df_2022['MUNICIPIO'] = df_2022['MUNICIPIO'].apply(normalizar)
divipola['dpto'] = divipola['dpto'].apply(normalizar)
divipola['nom_mpio'] = divipola['nom_mpio'].apply(normalizar)

# --- 4. Eliminar registros sin informaci√≥n ---
df_2022 = df_2022[~df_2022['MUNICIPIO'].isin(['NO REGISTRA'])]
df_2022 = df_2022[~df_2022['DEPARTAMENTO'].isin(['NO REGISTRA'])]

# --- 5. Estandarizar valores en variables categ√≥ricas ---
# Genero
df_2022['GENERO'] = df_2022['GENERO'].replace({
    'NO REPORTA': 'NO REPORTADO',
    'NO REPORTADO ': 'NO REPORTADO',
    '-': 'NO REPORTADO'
})
# Agrupaci√≥n de edad
df_2022['AGRUPA_EDAD_PERSONA'] = df_2022['AGRUPA_EDAD_PERSONA'].replace({
    'NO REPORTA': 'NO REPORTADO',
    'NO REPORTADO ': 'NO REPORTADO',
    ' ': 'NO REPORTADO'
})

# --- 6. Reemplazos de departamentos ---
reemplazos_dptos = {
    "GUAJIRA": "LA GUAJIRA",
    "VALLE": "VALLE DEL CAUCA",
    "SAN ANDRES": "ARCHIPIELAGO DE SAN ANDRES, PROVIDENCIA Y SANTA CATALINA",
    "BOGOTA": "CUNDINAMARCA",  # Bogot√° se trata como municipio de Cundinamarca
}
df_2022['DEPARTAMENTO'] = df_2022['DEPARTAMENTO'].replace(reemplazos_dptos)
divipola['dpto'] = divipola['dpto'].replace({"BOGOTA, D.C.": "CUNDINAMARCA"})

# --- 7. Correcciones finales de municipios problem√°ticos ---
reemplazos_mpios_final = {
    "CARTAGENA": "CARTAGENA DE INDIAS",
    "CUCUTA": "SAN JOSE DE CUCUTA",
    "DON MATIAS": "DONMATIAS",
    "GUICAN": "GUICAN DE LA SIERRA",
    "LOPEZ": "LOPEZ DE MICAY",
    "MANAURE": "MANAURE BALCON DEL CESAR",
    "MOMPOS": "SANTA CRUZ DE MOMPOX",
    "SAN ANDRES DE TUMACO": "SAN ANDRES DE TUMACO",
    "SAN ANDRES SOTAVENTO": "SAN ANDRES DE SOTAVENTO",
    "SAN JUAN DE RIO SECO": "SAN JUAN DE RIOSECO",
    "SAN PEDRO": "SAN PEDRO DE LOS MILAGROS",
    "SAN VICENTE": "SAN VICENTE FERRER",
    "SANTAFE DE ANTIOQUIA": "SANTA FE DE ANTIOQUIA",
    "TOLU VIEJO": "SAN JOSE DE TOLUVIEJO",
    "CALI": "SANTIAGO DE CALI",
    "PURISIMA": "PURISIMA DE LA CONCEPCION",
    "PIENDAMO": "PIENDAMO - TUNIA",
    "SOTARA": "SOTARA - PAISPAMBA",
    "CUASPUD": "CUASPUD CARLOSAMA"
}
df_2022['MUNICIPIO'] = df_2022['MUNICIPIO'].replace(reemplazos_mpios_final)

# --- 8. Correcci√≥n de departamentos espec√≠ficos ---
df_2022.loc[df_2022['MUNICIPIO'] == "MANAURE BALCON DEL CESAR", 'DEPARTAMENTO'] = "CESAR"
df_2022.loc[df_2022['MUNICIPIO'] == "SAN ANDRES DE TUMACO", 'DEPARTAMENTO'] = "NARINO"
df_2022.loc[df_2022['MUNICIPIO'] == "SAN ANDRES", 'DEPARTAMENTO'] = "ARCHIPIELAGO DE SAN ANDRES, PROVIDENCIA Y SANTA CATALINA"

# --- 9. Ajuste especial de Bogot√° ---
mask_bogota = df_2022['MUNICIPIO'].str.contains('BOGOTA', case=False, na=False)
df_2022.loc[mask_bogota, 'DEPARTAMENTO'] = 'CUNDINAMARCA'
df_2022.loc[mask_bogota, 'MUNICIPIO'] = 'BOGOTA, D.C.'

divipola.loc[
    divipola['nom_mpio'].str.contains('BOGOTA', case=False, na=False),
    ['dpto', 'nom_mpio']
] = ['CUNDINAMARCA', 'BOGOTA, D.C.']

# --- 10. Correcciones finales (√∫ltimos 5 municipios) ---
reemplazos_finales_extra = {
    "CERRO SAN ANTONIO": "CERRO DE SAN ANTONIO",
    "CHIBOLO": "CHIVOLO",
    "MARIQUITA": "SAN SEBASTIAN DE MARIQUITA",
}
df_2022['MUNICIPIO'] = df_2022['MUNICIPIO'].replace(reemplazos_finales_extra)

# --- 11. Corregir departamentos err√≥neos ---
df_2022.loc[df_2022['MUNICIPIO'] == "SAN PEDRO DE LOS MILAGROS", 'DEPARTAMENTO'] = "ANTIOQUIA"

# --- 12. Agregar a√±o ---
df_2022['A√ëO'] = 2022

# --- 13. Merge final con DIVIPOLA ---
merged_final = df_2022.merge(
    divipola,
    left_on=['DEPARTAMENTO', 'MUNICIPIO'],
    right_on=['dpto', 'nom_mpio'],
    how='left',
    indicator=True
)

# --- 14. Verificar sin coincidencias ---
sin_match_final = (
    merged_final[merged_final['_merge'] == 'left_only'][['DEPARTAMENTO', 'MUNICIPIO']]
    .drop_duplicates()
    .sort_values(['DEPARTAMENTO', 'MUNICIPIO'])
)
print(f"‚úÖ Municipios sin coincidencia tras correcci√≥n final: {len(sin_match_final)}")
display(sin_match_final)

# --- 15. Resultado final ---
print(f"\n‚úÖ Base unida correctamente: {merged_final.shape[0]:,} filas √ó {merged_final.shape[1]} columnas")

# =========================================================
# üîó MERGE FINAL: Base de delitos 2022 + DIVIPOLA + POBLACI√ìN
# =========================================================

import pandas as pd
import unidecode

# --- 1. Funci√≥n de normalizaci√≥n ---
def normalizar(texto):
    """Convierte a may√∫sculas, elimina tildes y espacios extra."""
    if pd.isna(texto):
        return ''
    texto = str(texto).strip().upper()
    texto = unidecode.unidecode(texto)
    texto = ' '.join(texto.split())  # quita espacios dobles
    return texto

# --- 2. Normalizar texto en df_2022 y divipola ---
for col in ['DEPARTAMENTO', 'MUNICIPIO']:
    if col in df_2022.columns:
        df_2022[col] = df_2022[col].astype(str).apply(normalizar)

for col in ['dpto', 'nom_mpio']:
     if col in divipola.columns:
        divipola[col] = divipola[col].astype(str).apply(normalizar)


# --- 3. Reemplazos y correcciones en municipios (df_2022) ---
reemplazos_mpios = {
    "CARTAGENA": "CARTAGENA DE INDIAS",
    "CUCUTA": "SAN JOSE DE CUCUTA",
    "DON MATIAS": "DONMATIAS",
    "GUICAN": "GUICAN DE LA SIERRA",
    "LOPEZ": "LOPEZ DE MICAY",
    "MANAURE": "MANAURE BALCON DEL CESAR",
    "SAN ANDRES DE TUMACO": "SAN ANDRES DE TUMACO",
    "SAN ANDRES SOTAVENTO": "SAN ANDRES DE SOTAVENTO",
    "SAN JUAN DE RIO SECO": "SAN JUAN DE RIOSECO",
    "SAN PEDRO": "SAN PEDRO DE LOS MILAGROS",
    "SAN VICENTE": "SAN VICENTE FERRER",
    "SANTAFE DE ANTIOQUIA": "SANTA FE DE ANTIOQUIA",
    "TOLU VIEJO": "SAN JOSE DE TOLUVIEJO",
    "CALI": "SANTIAGO DE CALI",
    "PURISIMA": "PURISIMA DE LA CONCEPCION",
    "PIENDAMO": "PIENDAMO - TUNIA",
    "SOTARA": "SOTARA - PAISPAMBA",
    "CUASPUD": "CUASPUD CARLOSAMA",
    "CERRO SAN ANTONIO": "CERRO DE SAN ANTONIO",
    "CHIBOLO": "CHIVOLO",
    "MARIQUITA": "SAN SEBASTIAN DE MARIQUITA",
}
if 'MUNICIPIO' in df_2022.columns:
    df_2022['MUNICIPIO'] = df_2022['MUNICIPIO'].replace(reemplazos_mpios)


# --- 4. Reemplazos y correcciones en departamentos (df_2022) ---
reemplazos_dptos = {
    "GUAJIRA": "LA GUAJIRA",
    "VALLE": "VALLE DEL CAUCA",
    "SAN ANDRES": "ARCHIPIELAGO DE SAN ANDRES, PROVIDENCIA Y SANTA CATALINA",
    "BOGOTA": "CUNDINAMARCA",
}
if 'DEPARTAMENTO' in df_2022.columns:
    df_2022['DEPARTAMENTO'] = df_2022['DEPARTAMENTO'].replace(reemplazos_dptos)

# --- 5. Correcci√≥n especial de Bogot√° ---
if 'MUNICIPIO' in df_2022.columns and 'DEPARTAMENTO' in df_2022.columns:
    mask_bogota = df_2022['MUNICIPIO'].str.contains('BOGOTA', case=False, na=False)
    df_2022.loc[mask_bogota, 'DEPARTAMENTO'] = 'CUNDINAMARCA'
    df_2022.loc[mask_bogota, 'MUNICIPIO'] = 'BOGOT√Å, D.C.'

# --- 6. Reemplazos y correcciones en municipios (divipola) ---
if 'nom_mpio' in divipola.columns:
    divipola['nom_mpio'] = divipola['nom_mpio'].replace({
        'MOMPOS': 'SANTA CRUZ DE MOMPOX',
        'SOTARA PAISPAMBA': 'SOTARA - PAISPAMBA'
    })

# --- 7. Ajuste especial de Bogot√° en divipola ---
if 'nom_mpio' in divipola.columns and 'dpto' in divipola.columns:
    divipola.loc[
        divipola['nom_mpio'].str.contains('BOGOTA', case=False, na=False),
        ['dpto', 'nom_mpio']
    ] = ['CUNDINAMARCA', 'BOGOT√Å, D.C.']

# --- 8. Agregar a√±o a df_2022 ---
df_2022['A√ëO'] = 2022

# --- 9. Filtrar datos de poblaci√≥n para el a√±o 2022 ---
# Assuming 'pob' DataFrame contains population data for multiple years
# If 'pob' is not available, you might need to load it first.
# Replace 'pob' with the actual DataFrame name if it's different.
if 'pob' in locals() or 'pob' in globals():
    pob_2022 = pob[pob['A√ëO'] == 2022].copy()

    # --- Eliminar duplicados en poblaci√≥n ---
    if 'DEPARTAMENTO' in pob_2022.columns and 'MUNICIPIO' in pob_2022.columns:
        pob_2022 = pob_2022.drop_duplicates(subset=['DEPARTAMENTO', 'MUNICIPIO'])

    # --- Merge df_2022 with Divipola ---
    df_merged_divipola_2022 = df_2022.merge(
        divipola,
        left_on=['DEPARTAMENTO', 'MUNICIPIO'],
        right_on=['dpto', 'nom_mpio'],
        how='left',
        indicator='_merge_divipola'
    )

    # --- Merge with Population data ---
    df_final_2022 = df_merged_divipola_2022.merge(
        pob_2022,
        on=['DEPARTAMENTO', 'MUNICIPIO', 'A√ëO'],
        how='left',
        indicator='_merge_pob'
    )

    # --- Verificar coincidencias faltantes ---
    sin_divipola = (
        df_final_2022[df_final_2022['_merge_divipola'] == 'left_only']
        [['DEPARTAMENTO', 'MUNICIPIO']]
        .drop_duplicates()
        .sort_values(['DEPARTAMENTO', 'MUNICIPIO'])
    )
    print(f"‚ö†Ô∏è Municipios sin coincidencia de DIVIPOLA para 2022: {len(sin_divipola)}")
    display(sin_divipola)

    sin_pob = (
        df_final_2022[df_final_2022['_merge_pob'] == 'left_only']
        [['DEPARTAMENTO', 'MUNICIPIO']]
        .drop_duplicates()
        .sort_values(['DEPARTAMENTO', 'MUNICIPIO'])
    )
    print(f"‚ö†Ô∏è Municipios sin coincidencia de poblaci√≥n para 2022: {len(sin_pob)}")
    display(sin_pob)

    # --- Limpieza final ---
    df_final_2022 = df_final_2022.drop(columns=['_merge_divipola', '_merge_pob'])

    print(f"\n‚úÖ Base final combinada con DIVIPOLA y poblaci√≥n para 2022: {df_final_2022.shape[0]:,} filas √ó {df_final_2022.shape[1]} columnas")
    display(df_final_2022.head(10))

    # --- Exportar resultado ---
    df_final_2022.to_excel("delitos_con_poblacion_final2022.xlsx", index=False)
    print("üìÅ Archivo exportado: delitos_con_poblacion_final2022.xlsx")

else:
    print("‚ö†Ô∏è Population data (DataFrame 'pob') not found. Skipping merge with population.")
    # If population data is not available, you can merge with Divipola only
    df_final_2022 = df_2022.merge(
        divipola,
        left_on=['DEPARTAMENTO', 'MUNICIPIO'],
        right_on=['dpto', 'nom_mpio'],
        how='left',
        indicator='_merge_divipola'
    )
    sin_divipola = (
        df_final_2022[df_final_2022['_merge_divipola'] == 'left_only']
        [['DEPARTAMENTO', 'MUNICIPIO']]
        .drop_duplicates()
        .sort_values(['DEPARTAMENTO', 'MUNICIPIO'])
    )
    print(f"‚ö†Ô∏è Municipios sin coincidencia de DIVIPOLA para 2022: {len(sin_divipola)}")
    display(sin_divipola)
    df_final_2022 = df_final_2022.drop(columns=['_merge_divipola'])
    print(f"\n‚úÖ Base final combinada con DIVIPOLA para 2022: {df_final_2022.shape[0]:,} filas √ó {df_final_2022.shape[1]} columnas")
    display(df_final_2022.head(10))
    df_final_2022.to_excel("delitos_con_divipola_final2022.xlsx", index=False)
    print("üìÅ Archivo exportado: delitos_con_divipola_final2022.xlsx")

for col in merged_final.columns:
    print(f"\n=== {col} ===")
    print(merged_final[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {merged_final[col].nunique()}")

# Comparar los departamentos de ambos DataFrames
set_df = set(df_2022['DEPARTAMENTO'].unique())
set_divi = set(divipola['dpto'].unique())

faltante_en_df2022 = set_divi - set_df
faltante_en_divipola = set_df - set_divi

print("üß© Departamento(s) que est√°n en DIVIPOLA pero no en df_2022:")
print(faltante_en_df2022)

print("\nüîπ Departamento(s) que est√°n en df_2022 pero no en DIVIPOLA:")
print(faltante_en_divipola)

# ========================================
# 2. CARGAR Y PROCESAR POBLACI√ìN
# ========================================

import pandas as pd
import unidecode

print("\nüì• Descargando datos de poblaci√≥n...")

# Leer archivo Excel del DANE
pob = pd.read_excel(
    url_poblacion,
    sheet_name='PobMunicipalx√ÅreaSexoEdad',
    header=7
)

# --- Normalizar nombres de columnas ---
pob.columns = (
    pob.columns.str.upper()
    .str.strip()
    .str.replace(' ', '_')
    .str.replace('√Å', 'A')
    .str.replace('.', '', regex=False)
)

# --- Verificaci√≥n de nombres existentes ---
print(f"Columnas detectadas: {list(pob.columns)}")

# --- Seleccionar solo columnas que existan ---
columnas_requeridas = ['DP', 'DPNOM', 'MPIO', 'MPNOM', 'DPMP', 'A√ëO', 'AREA_GEOGRAFICA', 'TOTAL']
cols_existentes = [col for col in columnas_requeridas if col in pob.columns]
pob = pob[cols_existentes].copy()

print(f"\nColumnas seleccionadas para procesamiento: {pob.columns.tolist()}")

# --- Si no existe MPNOM, intentar usar el nombre alternativo (MPIO) ---
if 'MPNOM' not in pob.columns and 'MPIO' in pob.columns:
    pob = pob.rename(columns={'MPIO': 'MPNOM'})

# --- Normalizar texto de nombres ---
def normalizar(texto):
    if pd.isna(texto):
        return ''
    texto = str(texto).strip().upper()
    texto = unidecode.unidecode(texto)
    texto = ' '.join(texto.split())
    return texto

pob['DPNOM'] = pob['DPNOM'].apply(normalizar)
pob['MPNOM'] = pob['MPNOM'].apply(normalizar)

# --- Filtrar solo filas donde el √°rea geogr√°fica sea TOTAL o TOTALES ---
if 'AREA_GEOGRAFICA' in pob.columns:
    pob = pob[pob['AREA_GEOGRAFICA'].str.contains('TOTAL', case=False, na=False)]

# --- Renombrar columnas para merge posterior ---
pob = pob.rename(columns={
    'DPNOM': 'DEPARTAMENTO',
    'MPNOM': 'CODIGO_DANE_POB	',
    'DPMP': 'MUNICIPIO',
    'TOTAL': 'POBLACION_TOTAL'
})

# --- Filtrar solo a√±o 2018 ---
pob_2022 = pob[pob['A√ëO'] == 2022].copy()

# --- Eliminar duplicados ---
pob_2022 = pob_2022.drop_duplicates(subset=['DEPARTAMENTO', 'MUNICIPIO'])

print(f"‚úÖ Registros de poblaci√≥n 2022 (√°rea TOTAL) procesados: {len(pob_2022):,}")

# --- Vista previa ---
display(pob_2022.head(10))

for col in pob_2022.columns:
    print(f"\n=== {col} ===")
    print(pob_2022[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {pob_2022[col].nunique()}")

# ====================================================
# üî† PASAR TODA LA BASE pob_2022 A MAY√öSCULAS Y NORMALIZAR
# ====================================================

import unidecode
import pandas as pd

def normalizar_texto(valor):
    """Convierte todo texto a may√∫sculas, quita tildes y espacios dobles."""
    if isinstance(valor, str):
        valor = unidecode.unidecode(valor)  # quita tildes
        valor = valor.upper().strip()
        valor = ' '.join(valor.split())      # elimina espacios dobles
    return valor

# Aplicar a todas las columnas de tipo texto
for col in pob_2022.columns:
    if pob_2022[col].dtype == 'object':
        pob_2022[col] = pob_2022[col].apply(normalizar_texto)

print("‚úÖ Toda la base de poblaci√≥n est√° ahora en MAY√öSCULAS y sin tildes.")
display(pob_2022.head(10))

municipios_pob = sorted(pob_2022['MUNICIPIO'].dropna().unique())
print(f"Total de municipios en pob_2022: {len(municipios_pob)}\n")
print(municipios_pob)

# =========================================================
# üîó MERGE FINAL: Base de delitos + DIVIPOLA + POBLACI√ìN
# Compatible con cualquier a√±o (ej. 2018, 2019, 2022)
# =========================================================

import pandas as pd
import unidecode

# --- 1. Funci√≥n de normalizaci√≥n ---
def normalizar(texto):
    """Convierte a may√∫sculas, elimina tildes y espacios extra."""
    if pd.isna(texto):
        return ''
    texto = str(texto).strip().upper()
    texto = unidecode.unidecode(texto)
    texto = ' '.join(texto.split())  # quita espacios dobles
    return texto


# --- 2. Normalizar texto en todas las bases ---
for col in ['DEPARTAMENTO', 'MUNICIPIO']:
    merged_final[col] = merged_final[col].astype(str).apply(normalizar)
    pob_2022[col] = pob_2022[col].astype(str).apply(normalizar)


# --- 3. Reemplazos y correcciones en municipios ---
reemplazos_mpios = {
    "CARTAGENA": "CARTAGENA DE INDIAS",
    "CUCUTA": "SAN JOSE DE CUCUTA",
    "DON MATIAS": "DONMATIAS",
    "GUICAN": "GUICAN DE LA SIERRA",
    "LOPEZ": "LOPEZ DE MICAY",
    "MANAURE": "MANAURE BALCON DEL CESAR",
    "SAN ANDRES DE TUMACO": "SAN ANDRES DE TUMACO",
    "SAN ANDRES SOTAVENTO": "SAN ANDRES DE SOTAVENTO",
    "SAN JUAN DE RIO SECO": "SAN JUAN DE RIOSECO",
    "SAN PEDRO": "SAN PEDRO DE LOS MILAGROS",
    "SAN VICENTE": "SAN VICENTE FERRER",
    "SANTAFE DE ANTIOQUIA": "SANTA FE DE ANTIOQUIA",
    "TOLU VIEJO": "SAN JOSE DE TOLUVIEJO",
    "CALI": "SANTIAGO DE CALI",
    "PURISIMA": "PURISIMA DE LA CONCEPCION",
    "PIENDAMO": "PIENDAMO - TUNIA",
    "SOTARA": "SOTARA - PAISPAMBA",
    "CUASPUD": "CUASPUD CARLOSAMA",
    "CERRO SAN ANTONIO": "CERRO DE SAN ANTONIO",
    "CHIBOLO": "CHIVOLO",
    "MARIQUITA": "SAN SEBASTIAN DE MARIQUITA",
}
merged_final['MUNICIPIO'] = merged_final['MUNICIPIO'].replace(reemplazos_mpios)
pob_2022['MUNICIPIO'] = pob_2022['MUNICIPIO'].replace(reemplazos_mpios)


# --- 4. Reemplazos y correcciones en departamentos ---
reemplazos_dptos = {
    "GUAJIRA": "LA GUAJIRA",
    "VALLE": "VALLE DEL CAUCA",
    "SAN ANDRES": "ARCHIPIELAGO DE SAN ANDRES, PROVIDENCIA Y SANTA CATALINA",
    "BOGOTA": "CUNDINAMARCA",
}
merged_final['DEPARTAMENTO'] = merged_final['DEPARTAMENTO'].replace(reemplazos_dptos)
pob_2022['DEPARTAMENTO'] = pob_2022['DEPARTAMENTO'].replace(reemplazos_dptos)


# --- 5. Correcci√≥n especial de Bogot√° ---
mask_bogota = merged_final['MUNICIPIO'].str.contains('BOGOTA', case=False, na=False)
merged_final.loc[mask_bogota, 'DEPARTAMENTO'] = 'CUNDINAMARCA'
merged_final.loc[mask_bogota, 'MUNICIPIO'] = 'BOGOT√Å, D.C.'

mask_bogota_pob = pob_2022['MUNICIPIO'].str.contains('BOGOTA', case=False, na=False)
pob_2022.loc[mask_bogota_pob, 'DEPARTAMENTO'] = 'CUNDINAMARCA'
pob_2022.loc[mask_bogota_pob, 'MUNICIPIO'] = 'BOGOT√Å, D.C.'


# --- 6. Correcciones espec√≠ficas para empalmar con poblaci√≥n ---
pob_2022['MUNICIPIO'] = pob_2022['MUNICIPIO'].replace({
    'MOMPOS': 'SANTA CRUZ DE MOMPOX',
    'SOTARA PAISPAMBA': 'SOTARA - PAISPAMBA'
})


# --- üö® 7. Eliminar filas "NO REPORTADO" ---
merged_final = merged_final[
    (merged_final['MUNICIPIO'] != 'NO REPORTADO') &
    (merged_final['DEPARTAMENTO'] != 'NO REPORTADO')
]


# --- 8. Asegurar a√±o como entero ---
merged_final['A√ëO'] = merged_final['A√ëO'].astype(int)
pob_2022['A√ëO'] = pob_2022['A√ëO'].astype(int)


# --- 9. Merge final por departamento, municipio y a√±o ---
df_final_pob = merged_final.merge(
    pob_2022,
    on=['DEPARTAMENTO', 'MUNICIPIO', 'A√ëO'],
    how='left',
    indicator='_merge_pob'
)


# --- 10. Verificar coincidencias faltantes ---
sin_pob = (
    df_final_pob[df_final_pob['_merge_pob'] == 'left_only']
    [['DEPARTAMENTO', 'MUNICIPIO']]
    .drop_duplicates()
    .sort_values(['DEPARTAMENTO', 'MUNICIPIO'])
)
print(f"‚ö†Ô∏è Municipios sin coincidencia de poblaci√≥n: {len(sin_pob)}")
display(sin_pob)


# --- 11. Limpieza final ---
df_final_pob = df_final_pob.drop(columns=['_merge_pob'])

print(f"\n‚úÖ Base final combinada con poblaci√≥n: {df_final_pob.shape[0]:,} filas √ó {df_final_pob.shape[1]} columnas")
display(df_final_pob.head(10))


# --- 12. Exportar resultado ---
df_final_pob.to_excel("delitos_con_poblacion_final2022.xlsx", index=False)
print("üìÅ Archivo exportado: delitos_con_poblacion_final2022.xlsx")

for col in df_final_pob.columns:
    print(f"\n=== {col} ===")
    print(df_final_pob[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {df_final_pob[col].nunique()}")

"""2023"""

def cargar_delito(url, delito):
    # Probar varios posibles encabezados
    posibles_headers = [8, 9, 10, 11, 12]

    for header_row in posibles_headers:
        try:
            df = pd.read_excel(url, header=header_row).copy()
            df.columns = df.columns.str.strip().str.upper().str.replace(" ", "_")

            renombrar = {
                "ARMAS_MEDIOS": "ARMAS_MEDIOS",
                "ARMA_MEDIO": "ARMAS_MEDIOS",
                "ARMAS/MEDIOS": "ARMAS_MEDIOS",
                "ARMAS_Y_MEDIOS": "ARMAS_MEDIOS",
                "CODIGO_DANE": "CODIGO_DANE",
                "FECHA_HECHO": "FECHA_HECHO",
                "GENERO": "GENERO",
                "CANTIDAD": "CANTIDAD",
                "AGRUPA_EDAD_PERSONA": "AGRUPA_EDAD_PERSONA",
                "*AGRUPA_EDAD_PERSONA": "AGRUPA_EDAD_PERSONA",
                "*AGRUPA_EDAD_PERSONA*": "AGRUPA_EDAD_PERSONA"
            }
            df = df.rename(columns=lambda x: renombrar.get(x, x))

            columnas_validas = [
                "DEPARTAMENTO", "MUNICIPIO", "CODIGO_DANE",
                "ARMAS_MEDIOS", "FECHA_HECHO", "GENERO",
                "AGRUPA_EDAD_PERSONA", "CANTIDAD"
            ]
            df = df[[col for col in columnas_validas if col in df.columns]]

            df = df.dropna(how="all")

            basura_regex = "TOTAL|FUENTE|Elaborado|Revisado|Autorizado|Ley 1098|Agrupaci√≥n referente|Contador"
            for col in ["DEPARTAMENTO", "ARMAS_MEDIOS"]:
                if col in df.columns:
                    df = df[~df[col].astype(str).str.contains(basura_regex, na=False, case=False)]

            if not df.empty:
                if "CODIGO_DANE" in df.columns:
                    df["CODIGO_DANE"] = pd.to_numeric(df["CODIGO_DANE"], errors="coerce")

                df["TIPO_DELITO"] = delito
                print(f"üìå {delito}: encabezado fijo en fila {header_row}")
                return df
        except Exception:
            continue

    # Si lleg√≥ aqu√≠, fall√≥ con todas
    print(f"‚ö†Ô∏è {delito}: no se pudo leer con headers {posibles_headers}")
    return pd.DataFrame()

# Diccionario de URLs y delitos 2023
urls_2023 = [
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto%20cabezas%20de%20ganado.._0.xlsx", "HURTO CABEZAS GANADO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/amenzas..xlsx", "AMENAZAS"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/delitos%20sexuales.xlsx", "DELITOS SEXUALES"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/extorsion_11.xlsx", "EXTORSI√ìN"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/homicidio%20intencional_0.xlsx", "HOMICIDIO INTENCIONAL"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/homicidios%20en%20accidente%20de%20transito....xlsx", "HOMICIDIOS EN ACCIDENTE DE TR√ÅNSITO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto%20a%20personas.xlsx", "HURTO A PERSONAS"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto%20a%20residencias....xlsx", "HURTO A RESIDENCIAS"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto%20automotores....xlsx", "HURTO AUTOMOTORES"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto%20a%20motocicletas....xlsx", "HURTO MOTOCICLETAS"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto%20a%20comercio..._0.xlsx", "HURTO A COMERCIO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto%20entidades%20financieras.xlsx", "HURTO A ENTIDADES FINANCIERAS"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/lesiones%20en%20accidente%20de%20transito....xlsx", "LESIONES EN ACCIDENTE DE TR√ÅNSITO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/lesiones%20personales..._0.xlsx", "LESIONES PERSONALES"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto%20pirateria%20terrestre_1.xlsx", "PIRATER√çA TERRESTRE"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/secuestro..._0.xlsx", "SECUESTRO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/terrorismo_4.xlsx", "TERRORISMO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/violencia%20intrafamiliar....xlsx", "VIOLENCIA INTRAFAMILIAR"),
]

# Procesar todos los archivos
dfs_2023 = []
for url, delito in urls_2023:
    df = cargar_delito(url, delito)
    if not df.empty:
        dfs_2023.append(df)
        print(f"‚úÖ {delito}: {df.shape[0]} filas")

# Concatenar todo en un solo DataFrame
df_2023 = pd.concat(dfs_2023, ignore_index=True)

# Ordenar por MUNICIPIO y DEPARTAMENTO
df_2023 = df_2023.sort_values(by=["MUNICIPIO", "DEPARTAMENTO"]).reset_index(drop=True)

print(f"\n Total final 2023: {df_2023.shape[0]} filas y {df_2023.shape[1]} columnas")
display(df_2023.head())

# === 14. Valores √∫nicos por columna en df_2018 ===
for col in df_2023.columns:
    print(f"\n=== {col} ===")
    print(df_2023[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {df_2023[col].nunique()}")

# Commented out IPython magic to ensure Python compatibility.
# %pip install unidecode

import pandas as pd
import numpy as np
import unidecode
import re

# --- Estandarizar DEPARTAMENTO ---
df_2023['DEPARTAMENTO'] = df_2023['DEPARTAMENTO'].astype(str).str.strip().str.upper()
df_2023['DEPARTAMENTO'] = df_2023['DEPARTAMENTO'].apply(lambda x: unidecode.unidecode(x))

# --- Estandarizar MUNICIPIO ---
def limpiar_municipio(nombre):
    if pd.isna(nombre):
        return nombre
    nombre = str(nombre).upper().strip()
    nombre = re.sub(r'\(CT\)', '', nombre)  # eliminar (CT)
    nombre = unidecode.unidecode(nombre)     # quitar tildes
    return nombre

df_2023['MUNICIPIO'] = df_2023['MUNICIPIO'].apply(limpiar_municipio)

# Reemplazar 'NAN' como string por NaN
df_2023['MUNICIPIO'] = df_2023['MUNICIPIO'].replace('NAN', np.nan)

# Opcional: eliminar filas donde MUNICIPIO sea NaN
df_2023 = df_2023.dropna(subset=['MUNICIPIO'])

# --- Arreglar FECHA_HECHO ---
def convertir_fecha(valor):
    if isinstance(valor, (float, int)):
        valor_str = str(int(valor))
        return pd.to_datetime(valor_str, format='%Y%m%d', errors='coerce')
    else:
        return pd.to_datetime(valor, errors='coerce')

df_2023['FECHA_HECHO'] = df_2023['FECHA_HECHO'].apply(convertir_fecha)

# --- Resumen de nulos ---
resumen_nulos = pd.DataFrame({
    'Columna': df_2023.columns,
    'Nulos': df_2023.isnull().sum(),
    'Porcentaje_nulos': df_2023.isnull().mean() * 100
})

print(resumen_nulos)

for col in df_2023.columns:
    print(f"\n=== {col} ===")
    print(df_2023[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {df_2023[col].nunique()}")

df_2023.isna().sum()

df_2023['MUNICIPIO'].value_counts(dropna=False).head(10)

print(df_2023['MUNICIPIO'].dtype)   # tipo de dato real
print(df_2023['MUNICIPIO'].isna().sum())  # conteo de nulos
print(df_2023['MUNICIPIO'].head(20))      # primeros valores

df_2023[df_2023['MUNICIPIO'].isna()]

# Ordenar alfab√©ticamente por MUNICIPIO
df_2023 = df_2023.sort_values(by=["MUNICIPIO"], ascending=True).reset_index(drop=True)

print(f"\n Total ordenado: {df_2023.shape[0]} filas y {df_2023.shape[1]} columnas")
display(df_2023.head(20))  # muestra los primeros 20 municipios ordenados

import pandas as pd
import numpy as np

# Crear tabla resumen de nulos
resumen_nulos = pd.DataFrame({
    'Columna': df_2023.columns,
    'Nulos': df_2023.isnull().sum(),
    'NaN explicitos': df_2023.apply(lambda x: x.isna().sum())
})

# Ordenar opcionalmente de mayor a menor nulos
resumen_nulos = resumen_nulos.sort_values(by='Nulos', ascending=False).reset_index(drop=True)

print(resumen_nulos)

import numpy as np

# Reemplazar 'NAN' como string por valores NaN
df_2023['MUNICIPIO'] = df_2023['MUNICIPIO'].replace('NAN', np.nan)

# Ahora contamos nulos y NaN
resumen_nulos = pd.DataFrame({
    'Columna': df_2023.columns,
    'Nulos': df_2023.isnull().sum(),
    'Porcentaje_nulos': df_2023.isnull().mean() * 100
})

print(resumen_nulos)

import numpy as np

# Asegurarnos de que los 'NAN' como texto sean NaN reales
df_2023['MUNICIPIO'].replace('NAN', np.nan, inplace=True)

# Eliminar filas donde MUNICIPIO sea NaN
df_2023 = df_2023.dropna(subset=['MUNICIPIO'])

# Revisar
print(df_2023['MUNICIPIO'].isnull().sum())  # deber√≠a dar 0

import numpy as np

# Reemplazar 'NAN' como string por valores NaN
df_2023['MUNICIPIO'] = df_2023['MUNICIPIO'].replace('NAN', np.nan)

# Ahora contamos nulos y NaN
resumen_nulos = pd.DataFrame({
    'Columna': df_2023.columns,
    'Nulos': df_2023.isnull().sum(),
    'Porcentaje_nulos': df_2023.isnull().mean() * 100
})

print(resumen_nulos)

for col in df_2023.columns:
    print(f"\n=== {col} ===")
    print(df_2023[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {df_2023[col].nunique()}")

"""Poblacion Y DAVIPOLA"""

import pandas as pd
import requests
import numpy as np

# --------------------------
# URLs de insumos externos
# --------------------------
url_poblacion = "https://www.dane.gov.co/files/censo2018/proyecciones-de-poblacion/Municipal/PPED-AreaSexoEdadMun-2018-2042_VP.xlsx"
api_url_divipola = "https://www.datos.gov.co/resource/gdxc-w37w.json?$limit=2000"

# Cargar DIVIPOLA desde la API de datos abiertos
divipola = pd.read_json(api_url_divipola)

# Mostrar las columnas originales
print("üßê Columnas originales en DIVIPOLA:")
print(divipola.columns.tolist())

# (Opcional) ver las primeras filas
display(divipola.head())

df_2023['MUNICIPIO'] = (
    df_2023['MUNICIPIO']
    .astype(str)
    .str.strip()
    .str.upper()
    .apply(lambda x: unidecode.unidecode(x))
)

df_2023['DEPARTAMENTO'] = (
    df_2023['DEPARTAMENTO']
    .astype(str)
    .str.strip()
    .str.upper()
    .apply(lambda x: unidecode.unidecode(x))
)

# --- 1. Importar librer√≠as ---
import pandas as pd
import unidecode

# --- 2. Normalizaci√≥n de texto ---
def normalizar(texto):
    """Convierte a may√∫sculas, elimina tildes, espacios extra y caracteres no est√°ndar"""
    if pd.isna(texto):
        return ''
    texto = str(texto).strip().upper()
    texto = unidecode.unidecode(texto)
    texto = ' '.join(texto.split())  # elimina dobles espacios
    return texto

# --- 3. Estandarizar nombres en ambas bases ---
df_2023['DEPARTAMENTO'] = df_2023['DEPARTAMENTO'].apply(normalizar)
df_2023['MUNICIPIO'] = df_2023['MUNICIPIO'].apply(normalizar)
divipola['dpto'] = divipola['dpto'].apply(normalizar)
divipola['nom_mpio'] = divipola['nom_mpio'].apply(normalizar)

# --- 4. Eliminar registros sin informaci√≥n ---
df_2023 = df_2023[~df_2023['MUNICIPIO'].isin(['NO REGISTRA'])]
df_2023 = df_2023[~df_2023['DEPARTAMENTO'].isin(['NO REGISTRA'])]

# --- 5. Reemplazos de departamentos ---
reemplazos_dptos = {
    "GUAJIRA": "LA GUAJIRA",
    "VALLE": "VALLE DEL CAUCA",
    "SAN ANDRES": "ARCHIPIELAGO DE SAN ANDRES, PROVIDENCIA Y SANTA CATALINA",
    "BOGOTA": "CUNDINAMARCA",  # Bogot√° se trata como municipio de Cundinamarca
}
df_2023['DEPARTAMENTO'] = df_2023['DEPARTAMENTO'].replace(reemplazos_dptos)
divipola['dpto'] = divipola['dpto'].replace({"BOGOTA, D.C.": "CUNDINAMARCA"})

# --- 6. Correcciones finales de municipios problem√°ticos ---
reemplazos_mpios_final = {
    "CARTAGENA": "CARTAGENA DE INDIAS",
    "CUCUTA": "SAN JOSE DE CUCUTA",
    "DON MATIAS": "DONMATIAS",
    "GUICAN": "GUICAN DE LA SIERRA",
    "LOPEZ": "LOPEZ DE MICAY",
    "MANAURE": "MANAURE BALCON DEL CESAR",
    "MOMPOS": "SANTA CRUZ DE MOMPOX",  # ‚úÖ corregido aqu√≠
    "SAN ANDRES DE TUMACO": "SAN ANDRES DE TUMACO",
    "SAN ANDRES SOTAVENTO": "SAN ANDRES DE SOTAVENTO",
    "SAN JUAN DE RIO SECO": "SAN JUAN DE RIOSECO",
    "SAN PEDRO": "SAN PEDRO DE LOS MILAGROS",
    "SAN VICENTE": "SAN VICENTE FERRER",
    "SANTAFE DE ANTIOQUIA": "SANTA FE DE ANTIOQUIA",
    "TOLU VIEJO": "SAN JOSE DE TOLUVIEJO",
    "CALI": "SANTIAGO DE CALI",
    "PURISIMA": "PURISIMA DE LA CONCEPCION",
    "PIENDAMO": "PIENDAMO - TUNIA",
    "SOTARA": "SOTARA - PAISPAMBA",
    "CUASPUD": "CUASPUD CARLOSAMA"
}
df_2023['MUNICIPIO'] = df_2023['MUNICIPIO'].replace(reemplazos_mpios_final)

# --- 7. Correcci√≥n de departamentos espec√≠ficos ---
df_2023.loc[df_2023['MUNICIPIO'] == "MANAURE BALCON DEL CESAR", 'DEPARTAMENTO'] = "CESAR"
df_2023.loc[df_2023['MUNICIPIO'] == "SAN ANDRES DE TUMACO", 'DEPARTAMENTO'] = "NARINO"
df_2023.loc[df_2023['MUNICIPIO'] == "SAN ANDRES", 'DEPARTAMENTO'] = "ARCHIPIELAGO DE SAN ANDRES, PROVIDENCIA Y SANTA CATALINA"

# --- 8. Ajuste especial de Bogot√° ---
mask_bogota = df_2023['MUNICIPIO'].str.contains('BOGOTA', case=False, na=False)
df_2023.loc[mask_bogota, 'DEPARTAMENTO'] = 'CUNDINAMARCA'
df_2023.loc[mask_bogota, 'MUNICIPIO'] = 'BOGOTA, D.C.'

divipola.loc[
    divipola['nom_mpio'].str.contains('BOGOTA', case=False, na=False),
    ['dpto', 'nom_mpio']
] = ['CUNDINAMARCA', 'BOGOTA, D.C.']

# --- 9. Correcciones finales (√∫ltimos 5 municipios) ---
reemplazos_finales_extra = {
    "CERRO SAN ANTONIO": "CERRO DE SAN ANTONIO",
    "CHIBOLO": "CHIVOLO",
    "MARIQUITA": "SAN SEBASTIAN DE MARIQUITA",
}
df_2023['MUNICIPIO'] = df_2023['MUNICIPIO'].replace(reemplazos_finales_extra)

# --- 10. Corregir departamentos err√≥neos ---
df_2023.loc[df_2023['MUNICIPIO'] == "SAN PEDRO DE LOS MILAGROS", 'DEPARTAMENTO'] = "ANTIOQUIA"

# --- 11. Agregar a√±o ---
df_2023['A√ëO'] = 2023

# --- 12. Merge final con DIVIPOLA ---
merged_final = df_2023.merge(
    divipola,
    left_on=['DEPARTAMENTO', 'MUNICIPIO'],
    right_on=['dpto', 'nom_mpio'],
    how='left',
    indicator=True
)

# --- 13. Verificar sin coincidencias ---
sin_match_final = (
    merged_final[merged_final['_merge'] == 'left_only'][['DEPARTAMENTO', 'MUNICIPIO']]
    .drop_duplicates()
    .sort_values(['DEPARTAMENTO', 'MUNICIPIO'])
)
print(f"‚úÖ Municipios sin coincidencia tras correcci√≥n final: {len(sin_match_final)}")
display(sin_match_final)

# --- 14. Resultado final ---
print(f"\n‚úÖ Base unida correctamente: {merged_final.shape[0]:,} filas √ó {merged_final.shape[1]} columnas")

for col in merged_final.columns:
    print(f"\n=== {col} ===")
    print(merged_final[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {merged_final[col].nunique()}")

# Comparar los departamentos de ambos DataFrames
set_df = set(df_2023['DEPARTAMENTO'].unique())
set_divi = set(divipola['dpto'].unique())

faltante_en_df2023 = set_divi - set_df
faltante_en_divipola = set_df - set_divi

print("üß© Departamento(s) que est√°n en DIVIPOLA pero no en df_2019:")
print(faltante_en_df2023)

print("\nüîπ Departamento(s) que est√°n en df_2019 pero no en DIVIPOLA:")
print(faltante_en_divipola)

# ========================================
# 2. CARGAR Y PROCESAR POBLACI√ìN
# ========================================

import pandas as pd
import unidecode

print("\nüì• Descargando datos de poblaci√≥n...")

# Leer archivo Excel del DANE
pob = pd.read_excel(
    url_poblacion,
    sheet_name='PobMunicipalx√ÅreaSexoEdad',
    header=7
)

# --- Normalizar nombres de columnas ---
pob.columns = (
    pob.columns.str.upper()
    .str.strip()
    .str.replace(' ', '_')
    .str.replace('√Å', 'A')
    .str.replace('.', '', regex=False)
)

# --- Verificaci√≥n de nombres existentes ---
print(f"Columnas detectadas: {list(pob.columns)}")

# --- Seleccionar solo columnas que existan ---
columnas_requeridas = ['DP', 'DPNOM', 'MPIO', 'MPNOM', 'DPMP', 'A√ëO', 'AREA_GEOGRAFICA', 'TOTAL']
cols_existentes = [col for col in columnas_requeridas if col in pob.columns]
pob = pob[cols_existentes].copy()

print(f"\nColumnas seleccionadas para procesamiento: {pob.columns.tolist()}")

# --- Si no existe MPNOM, intentar usar el nombre alternativo (MPIO) ---
if 'MPNOM' not in pob.columns and 'MPIO' in pob.columns:
    pob = pob.rename(columns={'MPIO': 'MPNOM'})

# --- Normalizar texto de nombres ---
def normalizar(texto):
    if pd.isna(texto):
        return ''
    texto = str(texto).strip().upper()
    texto = unidecode.unidecode(texto)
    texto = ' '.join(texto.split())
    return texto

pob['DPNOM'] = pob['DPNOM'].apply(normalizar)
pob['MPNOM'] = pob['MPNOM'].apply(normalizar)

# --- Filtrar solo filas donde el √°rea geogr√°fica sea TOTAL o TOTALES ---
if 'AREA_GEOGRAFICA' in pob.columns:
    pob = pob[pob['AREA_GEOGRAFICA'].str.contains('TOTAL', case=False, na=False)]

# --- Renombrar columnas para merge posterior ---
pob = pob.rename(columns={
    'DPNOM': 'DEPARTAMENTO',
    'MPNOM': 'CODIGO_DANE_POB   ',
    'DPMP': 'MUNICIPIO',
    'TOTAL': 'POBLACION_TOTAL'
})

# --- Filtrar solo a√±o 2020 ---
pob_2023 = pob[pob['A√ëO'] == 2023].copy()

# --- Eliminar duplicados ---
pob_2023 = pob_2023.drop_duplicates(subset=['DEPARTAMENTO', 'MUNICIPIO'])

print(f"‚úÖ Registros de poblaci√≥n 2020 (√°rea TOTAL) procesados: {len(pob_2023):,}")

# --- Vista previa ---
display(pob_2023.head(10))

for col in pob_2023.columns:
    print(f"\n=== {col} ===")
    print(pob_2023[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {pob_2023[col].nunique()}")

# ====================================================
# üî† PASAR TODA LA BASE pob_2018 A MAY√öSCULAS Y NORMALIZAR
# ====================================================

import unidecode
import pandas as pd

def normalizar_texto(valor):
    """Convierte todo texto a may√∫sculas, quita tildes y espacios dobles."""
    if isinstance(valor, str):
        valor = unidecode.unidecode(valor)  # quita tildes
        valor = valor.upper().strip()
        valor = ' '.join(valor.split())      # elimina espacios dobles
    return valor

# Aplicar a todas las columnas de tipo texto
for col in pob_2023.columns:
    if pob_2023[col].dtype == 'object':
        pob_2023[col] = pob_2023[col].apply(normalizar_texto)

print("‚úÖ Toda la base de poblaci√≥n est√° ahora en MAY√öSCULAS y sin tildes.")
display(pob_2023.head(10))

municipios_pob = sorted(pob_2023['MUNICIPIO'].dropna().unique())
print(f"Total de municipios en pob_2023: {len(municipios_pob)}\n")
print(municipios_pob)

# =========================================================
# üîó MERGE FINAL: Base de delitos + DIVIPOLA + POBLACI√ìN
# Compatible con cualquier a√±o (ej. 2018, 2019, 2022)
# =========================================================

import pandas as pd
import unidecode

# --- 1. Funci√≥n de normalizaci√≥n ---
def normalizar(texto):
    """Convierte a may√∫sculas, elimina tildes y espacios extra."""
    if pd.isna(texto):
        return ''
    texto = str(texto).strip().upper()
    texto = unidecode.unidecode(texto)
    texto = ' '.join(texto.split())  # quita espacios dobles
    return texto


# --- 2. Normalizar texto en todas las bases ---
for col in ['DEPARTAMENTO', 'MUNICIPIO']:
    merged_final[col] = merged_final[col].astype(str).apply(normalizar)
    pob_2023[col] = pob_2023[col].astype(str).apply(normalizar)


# --- 3. Reemplazos y correcciones en municipios ---
reemplazos_mpios = {
    "CARTAGENA": "CARTAGENA DE INDIAS",
    "CUCUTA": "SAN JOSE DE CUCUTA",
    "DON MATIAS": "DONMATIAS",
    "GUICAN": "GUICAN DE LA SIERRA",
    "LOPEZ": "LOPEZ DE MICAY",
    "MANAURE": "MANAURE BALCON DEL CESAR",
    "SAN ANDRES DE TUMACO": "SAN ANDRES DE TUMACO",
    "SAN ANDRES SOTAVENTO": "SAN ANDRES DE SOTAVENTO",
    "SAN JUAN DE RIO SECO": "SAN JUAN DE RIOSECO",
    "SAN PEDRO": "SAN PEDRO DE LOS MILAGROS",
    "SAN VICENTE": "SAN VICENTE FERRER",
    "SANTAFE DE ANTIOQUIA": "SANTA FE DE ANTIOQUIA",
    "TOLU VIEJO": "SAN JOSE DE TOLUVIEJO",
    "CALI": "SANTIAGO DE CALI",
    "PURISIMA": "PURISIMA DE LA CONCEPCION",
    "PIENDAMO": "PIENDAMO - TUNIA",
    "SOTARA": "SOTARA - PAISPAMBA",
    "CUASPUD": "CUASPUD CARLOSAMA",
    "CERRO SAN ANTONIO": "CERRO DE SAN ANTONIO",
    "CHIBOLO": "CHIVOLO",
    "MARIQUITA": "SAN SEBASTIAN DE MARIQUITA",
}
merged_final['MUNICIPIO'] = merged_final['MUNICIPIO'].replace(reemplazos_mpios)
pob_2023['MUNICIPIO'] = pob_2023['MUNICIPIO'].replace(reemplazos_mpios)


# --- 4. Reemplazos y correcciones en departamentos ---
reemplazos_dptos = {
    "GUAJIRA": "LA GUAJIRA",
    "VALLE": "VALLE DEL CAUCA",
    "SAN ANDRES": "ARCHIPIELAGO DE SAN ANDRES, PROVIDENCIA Y SANTA CATALINA",
    "BOGOTA": "CUNDINAMARCA",
}
merged_final['DEPARTAMENTO'] = merged_final['DEPARTAMENTO'].replace(reemplazos_dptos)
pob_2023['DEPARTAMENTO'] = pob_2023['DEPARTAMENTO'].replace(reemplazos_dptos)


# --- 5. Correcci√≥n especial de Bogot√° ---
mask_bogota = merged_final['MUNICIPIO'].str.contains('BOGOTA', case=False, na=False)
merged_final.loc[mask_bogota, 'DEPARTAMENTO'] = 'CUNDINAMARCA'
merged_final.loc[mask_bogota, 'MUNICIPIO'] = 'BOGOT√Å, D.C.'

mask_bogota_pob = pob_2023['MUNICIPIO'].str.contains('BOGOTA', case=False, na=False)
pob_2023.loc[mask_bogota_pob, 'DEPARTAMENTO'] = 'CUNDINAMARCA'
pob_2023.loc[mask_bogota_pob, 'MUNICIPIO'] = 'BOGOT√Å, D.C.'


# --- 6. Correcciones espec√≠ficas para empalmar con poblaci√≥n ---
pob_2023['MUNICIPIO'] = pob_2023['MUNICIPIO'].replace({
    'MOMPOS': 'SANTA CRUZ DE MOMPOX',
    'SOTARA PAISPAMBA': 'SOTARA - PAISPAMBA'
})


# --- üö® 7. Eliminar filas "NO REPORTADO" ---
merged_final = merged_final[
    (merged_final['MUNICIPIO'] != 'NO REPORTADO') &
    (merged_final['DEPARTAMENTO'] != 'NO REPORTADO')
]


# --- 8. Asegurar a√±o como entero ---
merged_final['A√ëO'] = merged_final['A√ëO'].astype(int)
pob_2023['A√ëO'] = pob_2023['A√ëO'].astype(int)


# --- 9. Merge final por departamento, municipio y a√±o ---
df_final_pob = merged_final.merge(
    pob_2023,
    on=['DEPARTAMENTO', 'MUNICIPIO', 'A√ëO'],
    how='left',
    indicator='_merge_pob'
)


# --- 10. Verificar coincidencias faltantes ---
sin_pob = (
    df_final_pob[df_final_pob['_merge_pob'] == 'left_only']
    [['DEPARTAMENTO', 'MUNICIPIO']]
    .drop_duplicates()
    .sort_values(['DEPARTAMENTO', 'MUNICIPIO'])
)
print(f"‚ö†Ô∏è Municipios sin coincidencia de poblaci√≥n: {len(sin_pob)}")
display(sin_pob)


# --- 11. Limpieza final ---
df_final_pob = df_final_pob.drop(columns=['_merge_pob'])

print(f"\n‚úÖ Base final combinada con poblaci√≥n: {df_final_pob.shape[0]:,} filas √ó {df_final_pob.shape[1]} columnas")
display(df_final_pob.head(10))


# --- 12. Exportar resultado ---
df_final_pob.to_excel("delitos_con_poblacion_final2023.xlsx", index=False)
print("üìÅ Archivo exportado: delitos_con_poblacion_final2023.xlsx")

for col in df_final_pob.columns:
    print(f"\n=== {col} ===")
    print(df_final_pob[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {df_final_pob[col].nunique()}")

"""2024"""

import pandas as pd
def cargar_delito(url, delito):
    # Probar varios posibles encabezados
    posibles_headers = [8, 9, 10, 11, 12]

    for header_row in posibles_headers:
        try:
            df = pd.read_excel(url, header=header_row).copy()
            df.columns = df.columns.str.strip().str.upper().str.replace(" ", "_")

            renombrar = {
                "ARMAS_MEDIOS": "ARMAS_MEDIOS",
                "ARMA_MEDIO": "ARMAS_MEDIOS",
                "ARMAS/MEDIOS": "ARMAS_MEDIOS",
                "ARMAS_Y_MEDIOS": "ARMAS_MEDIOS",
                "CODIGO_DANE": "CODIGO_DANE",
                "FECHA_HECHO": "FECHA_HECHO",
                "GENERO": "GENERO",
                "CANTIDAD": "CANTIDAD",
                "AGRUPA_EDAD_PERSONA": "AGRUPA_EDAD_PERSONA",
                "*AGRUPA_EDAD_PERSONA": "AGRUPA_EDAD_PERSONA",
                "*AGRUPA_EDAD_PERSONA*": "AGRUPA_EDAD_PERSONA"
            }
            df = df.rename(columns=lambda x: renombrar.get(x, x))

            columnas_validas = [
                "DEPARTAMENTO", "MUNICIPIO", "CODIGO_DANE",
                "ARMAS_MEDIOS", "FECHA_HECHO", "GENERO",
                "AGRUPA_EDAD_PERSONA", "CANTIDAD"
            ]
            df = df[[col for col in columnas_validas if col in df.columns]]

            df = df.dropna(how="all")

            basura_regex = "TOTAL|FUENTE|Elaborado|Revisado|Autorizado|Ley 1098|Agrupaci√≥n referente|Contador"
            for col in ["DEPARTAMENTO", "ARMAS_MEDIOS"]:
                if col in df.columns:
                    df = df[~df[col].astype(str).str.contains(basura_regex, na=False, case=False)]

            if not df.empty:
                if "CODIGO_DANE" in df.columns:
                    df["CODIGO_DANE"] = pd.to_numeric(df["CODIGO_DANE"], errors="coerce")

                df["TIPO_DELITO"] = delito
                print(f"üìå {delito}: encabezado fijo en fila {header_row}")
                return df
        except Exception:
            continue

    # Si lleg√≥ aqu√≠, fall√≥ con todas
    print(f"‚ö†Ô∏è {delito}: no se pudo leer con headers {posibles_headers}")
    return pd.DataFrame()


    # ------------------------
# BASES 2024
# ------------------------
urls_2024 = [
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/Hurto%20a%20cabezas%20de%20ganado2024_0.xlsx", "HURTO CABEZAS GANADO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/Amenazas2024_0.xlsx", "AMENAZAS"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/Delitos%20sexuales2024_0.xlsx", "DELITOS SEXUALES"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/Extorsi%C3%B3n2024_0.xlsx", "EXTORSI√ìN"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/Homicidio%20Intencional2024_0.xlsx", "HOMICIDIO INTENCIONAL"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/Homicidios%20en%20accidente%20de%20tr%C3%A1nsito2024_0.xlsx", "HOMICIDIOS EN ACCIDENTE DE TR√ÅNSITO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/Hurto%20a%20personas2024_0.xlsx", "HURTO A PERSONAS"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/Hurto%20a%20residencias2024_0.xlsx", "HURTO A RESIDENCIAS"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/Hurto%20automotores2024_0.xlsx", "HURTO AUTOMOTORES"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/Hurto%20a%20motocicletas2024_0.xlsx", "HURTO MOTOCICLETAS"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/Hurto%20a%20comercio2024_0.xlsx", "HURTO A COMERCIO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/Hurto%20a%20entidades%20Financieras2024_0.xlsx", "HURTO A ENTIDADES FINANCIERAS"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/Lesiones%20en%20accidente%20de%20tr%C3%A1nsito2024_2.xlsx", "LESIONES EN ACCIDENTE DE TR√ÅNSITO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/Lesiones%20personales2024_0.xlsx", "LESIONES PERSONALES"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/Hurto%20pirater%C3%ADa%20terrestre2024_0.xlsx", "PIRATER√çA TERRESTRE"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/Secuestro2024_0.xlsx", "SECUESTRO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/Terrorismo2024_0.xlsx", "TERRORISMO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/Violencia%20intrafamiliar2024_0.xlsx", "VIOLENCIA INTRAFAMILIAR"),
]

# Procesar todos los archivos 2024
dfs_2024 = []
for url, delito in urls_2024:
    df = cargar_delito(url, delito)
    if not df.empty:
        dfs_2024.append(df)
        print(f"‚úÖ {delito}: {df.shape[0]} filas")

# Concatenar todo en un solo DataFrame
df_2024 = pd.concat(dfs_2024, ignore_index=True)

# Ordenar por MUNICIPIO y DEPARTAMENTO
df_2024 = df_2024.sort_values(by=["MUNICIPIO", "DEPARTAMENTO"]).reset_index(drop=True)

print(f"\n Total final 2024: {df_2024.shape[0]} filas y {df_2024.shape[1]} columnas")
display(df_2024.head())

# === 14. Valores √∫nicos por columna en df_2018 ===
for col in df_2024.columns:
    print(f"\n=== {col} ===")
    print(df_2024[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {df_2024[col].nunique()}")

# Commented out IPython magic to ensure Python compatibility.
# %pip install unidecode

import pandas as pd
import numpy as np
import unidecode
import re

# --- Estandarizar DEPARTAMENTO ---
df_2024['DEPARTAMENTO'] = df_2024['DEPARTAMENTO'].astype(str).str.strip().str.upper()
df_2024['DEPARTAMENTO'] = df_2024['DEPARTAMENTO'].apply(lambda x: unidecode.unidecode(x))

# --- Estandarizar MUNICIPIO ---
def limpiar_municipio(nombre):
    if pd.isna(nombre):
        return nombre
    nombre = str(nombre).upper().strip()
    nombre = re.sub(r'\(CT\)', '', nombre)  # eliminar (CT)
    nombre = unidecode.unidecode(nombre)     # quitar tildes
    return nombre

df_2024['MUNICIPIO'] = df_2024['MUNICIPIO'].apply(limpiar_municipio)

# Reemplazar 'NAN' como string por NaN
df_2024['MUNICIPIO'] = df_2024['MUNICIPIO'].replace('NAN', np.nan)

# Opcional: eliminar filas donde MUNICIPIO sea NaN
df_2024 = df_2024.dropna(subset=['MUNICIPIO'])

# --- Arreglar FECHA_HECHO ---
def convertir_fecha(valor):
    if isinstance(valor, (float, int)):
        valor_str = str(int(valor))
        return pd.to_datetime(valor_str, format='%Y%m%d', errors='coerce')
    else:
        return pd.to_datetime(valor, errors='coerce')

df_2024['FECHA_HECHO'] = df_2024['FECHA_HECHO'].apply(convertir_fecha)

# --- Resumen de nulos ---
resumen_nulos = pd.DataFrame({
    'Columna': df_2024.columns,
    'Nulos': df_2024.isnull().sum(),
    'Porcentaje_nulos': df_2024.isnull().mean() * 100
})

print(resumen_nulos)

for col in df_2024.columns:
    print(f"\n=== {col} ===")
    print(df_2024[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {df_2024[col].nunique()}")

df_2024.isna().sum()

df_2024['MUNICIPIO'].value_counts(dropna=False).head(10)

print(df_2024['MUNICIPIO'].dtype)   # tipo de dato real
print(df_2024['MUNICIPIO'].isna().sum())  # conteo de nulos
print(df_2024['MUNICIPIO'].head(20))      # primeros valores

df_2024[df_2024['MUNICIPIO'].isna()]

# Ordenar alfab√©ticamente por MUNICIPIO
df_2024 = df_2024.sort_values(by=["MUNICIPIO"], ascending=True).reset_index(drop=True)

print(f"\n Total ordenado: {df_2024.shape[0]} filas y {df_2024.shape[1]} columnas")
display(df_2024.head(20))  # muestra los primeros 20 municipios ordenados

import pandas as pd
import numpy as np

# Crear tabla resumen de nulos
resumen_nulos = pd.DataFrame({
    'Columna': df_2024.columns,
    'Nulos': df_2024.isnull().sum(),
    'NaN explicitos': df_2024.apply(lambda x: x.isna().sum())
})

# Ordenar opcionalmente de mayor a menor nulos
resumen_nulos = resumen_nulos.sort_values(by='Nulos', ascending=False).reset_index(drop=True)

print(resumen_nulos)

import numpy as np

# Reemplazar 'NAN' como string por valores NaN
df_2024['MUNICIPIO'] = df_2024['MUNICIPIO'].replace('NAN', np.nan)

# Ahora contamos nulos y NaN
resumen_nulos = pd.DataFrame({
    'Columna': df_2024.columns,
    'Nulos': df_2024.isnull().sum(),
    'Porcentaje_nulos': df_2024.isnull().mean() * 100
})

print(resumen_nulos)

import numpy as np

# Asegurarnos de que los 'NAN' como texto sean NaN reales
df_2024['MUNICIPIO'].replace('NAN', np.nan, inplace=True)

# Eliminar filas donde MUNICIPIO sea NaN
df_2024 = df_2024.dropna(subset=['MUNICIPIO'])

# Revisar
print(df_2024['MUNICIPIO'].isnull().sum())  # deber√≠a dar 0

import numpy as np

# Reemplazar 'NAN' como string por valores NaN
df_2024['MUNICIPIO'] = df_2024['MUNICIPIO'].replace('NAN', np.nan)

# Ahora contamos nulos y NaN
resumen_nulos = pd.DataFrame({
    'Columna': df_2024.columns,
    'Nulos': df_2024.isnull().sum(),
    'Porcentaje_nulos': df_2024.isnull().mean() * 100
})

print(resumen_nulos)

for col in df_2024.columns:
    print(f"\n=== {col} ===")
    print(df_2024[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {df_2024[col].nunique()}")

"""Poblacion Y DAVIPOLA"""

import pandas as pd
import requests
import numpy as np

# --------------------------
# URLs de insumos externos
# --------------------------
url_poblacion = "https://www.dane.gov.co/files/censo2018/proyecciones-de-poblacion/Municipal/PPED-AreaSexoEdadMun-2018-2042_VP.xlsx"
api_url_divipola = "https://www.datos.gov.co/resource/gdxc-w37w.json?$limit=2000"

# Cargar DIVIPOLA desde la API de datos abiertos
divipola = pd.read_json(api_url_divipola)

# Mostrar las columnas originales
print("üßê Columnas originales en DIVIPOLA:")
print(divipola.columns.tolist())

# (Opcional) ver las primeras filas
display(divipola.head())

df_2024['MUNICIPIO'] = (
    df_2024['MUNICIPIO']
    .astype(str)
    .str.strip()
    .str.upper()
    .apply(lambda x: unidecode.unidecode(x))
)

df_2024['DEPARTAMENTO'] = (
    df_2024['DEPARTAMENTO']
    .astype(str)
    .str.strip()
    .str.upper()
    .apply(lambda x: unidecode.unidecode(x))
)

# --- 1. Importar librer√≠as ---
import pandas as pd
import unidecode

# --- 2. Normalizaci√≥n de texto ---
def normalizar(texto):
    """Convierte a may√∫sculas, elimina tildes, espacios extra y caracteres no est√°ndar"""
    if pd.isna(texto):
        return ''
    texto = str(texto).strip().upper()
    texto = unidecode.unidecode(texto)
    texto = ' '.join(texto.split())  # elimina dobles espacios
    return texto

# --- 3. Estandarizar nombres en ambas bases ---
df_2024['DEPARTAMENTO'] = df_2024['DEPARTAMENTO'].apply(normalizar)
df_2024['MUNICIPIO'] = df_2024['MUNICIPIO'].apply(normalizar)
divipola['dpto'] = divipola['dpto'].apply(normalizar)
divipola['nom_mpio'] = divipola['nom_mpio'].apply(normalizar)

# --- 4. Eliminar registros sin informaci√≥n ---
df_2024 = df_2024[~df_2024['MUNICIPIO'].isin(['NO REGISTRA'])]
df_2024 = df_2024[~df_2024['DEPARTAMENTO'].isin(['NO REGISTRA'])]

# --- 5. Reemplazos de departamentos ---
reemplazos_dptos = {
    "GUAJIRA": "LA GUAJIRA",
    "VALLE": "VALLE DEL CAUCA",
    "SAN ANDRES": "ARCHIPIELAGO DE SAN ANDRES, PROVIDENCIA Y SANTA CATALINA",
    "BOGOTA": "CUNDINAMARCA",  # Bogot√° se trata como municipio de Cundinamarca
}
df_2024['DEPARTAMENTO'] = df_2024['DEPARTAMENTO'].replace(reemplazos_dptos)
divipola['dpto'] = divipola['dpto'].replace({"BOGOTA, D.C.": "CUNDINAMARCA"})

# --- 6. Correcciones finales de municipios problem√°ticos ---
reemplazos_mpios_final = {
    "CARTAGENA": "CARTAGENA DE INDIAS",
    "CUCUTA": "SAN JOSE DE CUCUTA",
    "DON MATIAS": "DONMATIAS",
    "GUICAN": "GUICAN DE LA SIERRA",
    "LOPEZ": "LOPEZ DE MICAY",
    "MANAURE": "MANAURE BALCON DEL CESAR",
    "MOMPOS": "SANTA CRUZ DE MOMPOX",  # ‚úÖ corregido aqu√≠
    "SAN ANDRES DE TUMACO": "SAN ANDRES DE TUMACO",
    "SAN ANDRES SOTAVENTO": "SAN ANDRES DE SOTAVENTO",
    "SAN JUAN DE RIO SECO": "SAN JUAN DE RIOSECO",
    "SAN PEDRO": "SAN PEDRO DE LOS MILAGROS",
    "SAN VICENTE": "SAN VICENTE FERRER",
    "SANTAFE DE ANTIOQUIA": "SANTA FE DE ANTIOQUIA",
    "TOLU VIEJO": "SAN JOSE DE TOLUVIEJO",
    "CALI": "SANTIAGO DE CALI",
    "PURISIMA": "PURISIMA DE LA CONCEPCION",
    "PIENDAMO": "PIENDAMO - TUNIA",
    "SOTARA": "SOTARA - PAISPAMBA",
    "CUASPUD": "CUASPUD CARLOSAMA"
}
df_2024['MUNICIPIO'] = df_2024['MUNICIPIO'].replace(reemplazos_mpios_final)

# --- 7. Correcci√≥n de departamentos espec√≠ficos ---
df_2024.loc[df_2024['MUNICIPIO'] == "MANAURE BALCON DEL CESAR", 'DEPARTAMENTO'] = "CESAR"
df_2024.loc[df_2024['MUNICIPIO'] == "SAN ANDRES DE TUMACO", 'DEPARTAMENTO'] = "NARINO"
df_2024.loc[df_2024['MUNICIPIO'] == "SAN ANDRES", 'DEPARTAMENTO'] = "ARCHIPIELAGO DE SAN ANDRES, PROVIDENCIA Y SANTA CATALINA"

# --- 8. Ajuste especial de Bogot√° ---
mask_bogota = df_2024['MUNICIPIO'].str.contains('BOGOTA', case=False, na=False)
df_2024.loc[mask_bogota, 'DEPARTAMENTO'] = 'CUNDINAMARCA'
df_2024.loc[mask_bogota, 'MUNICIPIO'] = 'BOGOTA, D.C.'

divipola.loc[
    divipola['nom_mpio'].str.contains('BOGOTA', case=False, na=False),
    ['dpto', 'nom_mpio']
] = ['CUNDINAMARCA', 'BOGOTA, D.C.']

# --- 9. Correcciones finales (√∫ltimos 5 municipios) ---
reemplazos_finales_extra = {
    "CERRO SAN ANTONIO": "CERRO DE SAN ANTONIO",
    "CHIBOLO": "CHIVOLO",
    "MARIQUITA": "SAN SEBASTIAN DE MARIQUITA",
}
df_2024['MUNICIPIO'] = df_2024['MUNICIPIO'].replace(reemplazos_finales_extra)

# --- 10. Corregir departamentos err√≥neos ---
df_2024.loc[df_2024['MUNICIPIO'] == "SAN PEDRO DE LOS MILAGROS", 'DEPARTAMENTO'] = "ANTIOQUIA"

# --- 11. Agregar a√±o ---
df_2024['A√ëO'] = 2024

# --- 12. Merge final con DIVIPOLA ---
merged_final = df_2024.merge(
    divipola,
    left_on=['DEPARTAMENTO', 'MUNICIPIO'],
    right_on=['dpto', 'nom_mpio'],
    how='left',
    indicator=True
)

# --- 13. Verificar sin coincidencias ---
sin_match_final = (
    merged_final[merged_final['_merge'] == 'left_only'][['DEPARTAMENTO', 'MUNICIPIO']]
    .drop_duplicates()
    .sort_values(['DEPARTAMENTO', 'MUNICIPIO'])
)
print(f"‚úÖ Municipios sin coincidencia tras correcci√≥n final: {len(sin_match_final)}")
display(sin_match_final)

# --- 14. Resultado final ---
print(f"\n‚úÖ Base unida correctamente: {merged_final.shape[0]:,} filas √ó {merged_final.shape[1]} columnas")

for col in merged_final.columns:
    print(f"\n=== {col} ===")
    print(merged_final[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {merged_final[col].nunique()}")

# Comparar los departamentos de ambos DataFrames
set_df = set(df_2024['DEPARTAMENTO'].unique())
set_divi = set(divipola['dpto'].unique())

faltante_en_df2024 = set_divi - set_df
faltante_en_divipola = set_df - set_divi

print("üß© Departamento(s) que est√°n en DIVIPOLA pero no en df_2024:")
print(faltante_en_df2024)

print("\nüîπ Departamento(s) que est√°n en df_2024 pero no en DIVIPOLA:")
print(faltante_en_divipola)

# ========================================
# 2. CARGAR Y PROCESAR POBLACI√ìN
# ========================================

import pandas as pd
import unidecode

print("\nüì• Descargando datos de poblaci√≥n...")

# Leer archivo Excel del DANE
pob = pd.read_excel(
    url_poblacion,
    sheet_name='PobMunicipalx√ÅreaSexoEdad',
    header=7
)

# --- Normalizar nombres de columnas ---
pob.columns = (
    pob.columns.str.upper()
    .str.strip()
    .str.replace(' ', '_')
    .str.replace('√Å', 'A')
    .str.replace('.', '', regex=False)
)

# --- Verificaci√≥n de nombres existentes ---
print(f"Columnas detectadas: {list(pob.columns)}")

# --- Seleccionar solo columnas que existan ---
columnas_requeridas = ['DP', 'DPNOM', 'MPIO', 'MPNOM', 'DPMP', 'A√ëO', 'AREA_GEOGRAFICA', 'TOTAL']
cols_existentes = [col for col in columnas_requeridas if col in pob.columns]
pob = pob[cols_existentes].copy()

print(f"\nColumnas seleccionadas para procesamiento: {pob.columns.tolist()}")

# --- Si no existe MPNOM, intentar usar el nombre alternativo (MPIO) ---
if 'MPNOM' not in pob.columns and 'MPIO' in pob.columns:
    pob = pob.rename(columns={'MPIO': 'MPNOM'})

# --- Normalizar texto de nombres ---
def normalizar(texto):
    if pd.isna(texto):
        return ''
    texto = str(texto).strip().upper()
    texto = unidecode.unidecode(texto)
    texto = ' '.join(texto.split())
    return texto

pob['DPNOM'] = pob['DPNOM'].apply(normalizar)
pob['MPNOM'] = pob['MPNOM'].apply(normalizar)

# --- Filtrar solo filas donde el √°rea geogr√°fica sea TOTAL o TOTALES ---
if 'AREA_GEOGRAFICA' in pob.columns:
    pob = pob[pob['AREA_GEOGRAFICA'].str.contains('TOTAL', case=False, na=False)]

# --- Renombrar columnas para merge posterior ---
pob = pob.rename(columns={
    'DPNOM': 'DEPARTAMENTO',
    'MPNOM': 'CODIGO_DANE_POB	',
    'DPMP': 'MUNICIPIO',
    'TOTAL': 'POBLACION_TOTAL'
})

# --- Filtrar solo a√±o 2018 ---
pob_2024 = pob[pob['A√ëO'] == 2024].copy()

# --- Eliminar duplicados ---
pob_2024 = pob_2024.drop_duplicates(subset=['DEPARTAMENTO', 'MUNICIPIO'])

print(f"‚úÖ Registros de poblaci√≥n 2024 (√°rea TOTAL) procesados: {len(pob_2024):,}")

# --- Vista previa ---
display(pob_2024.head(10))

for col in pob_2024.columns:
    print(f"\n=== {col} ===")
    print(pob_2024[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {pob_2024[col].nunique()}")

# ====================================================
# üî† PASAR TODA LA BASE pob_2018 A MAY√öSCULAS Y NORMALIZAR
# ====================================================

import unidecode
import pandas as pd

def normalizar_texto(valor):
    """Convierte todo texto a may√∫sculas, quita tildes y espacios dobles."""
    if isinstance(valor, str):
        valor = unidecode.unidecode(valor)  # quita tildes
        valor = valor.upper().strip()
        valor = ' '.join(valor.split())      # elimina espacios dobles
    return valor

# Aplicar a todas las columnas de tipo texto
for col in pob_2024.columns:
    if pob_2024[col].dtype == 'object':
        pob_2024[col] = pob_2024[col].apply(normalizar_texto)

print("‚úÖ Toda la base de poblaci√≥n est√° ahora en MAY√öSCULAS y sin tildes.")
display(pob_2024.head(10))

municipios_pob = sorted(pob_2024['MUNICIPIO'].dropna().unique())
print(f"Total de municipios en pob_2024: {len(municipios_pob)}\n")
print(municipios_pob)

# =========================================================
# üîó MERGE FINAL: Base de delitos + DIVIPOLA + POBLACI√ìN
# =========================================================

import pandas as pd
import unidecode

# --- 1. Funci√≥n de normalizaci√≥n ---
def normalizar(texto):
    """Convierte a may√∫sculas, elimina tildes y espacios extra."""
    if pd.isna(texto):
        return ''
    texto = str(texto).strip().upper()
    texto = unidecode.unidecode(texto)
    texto = ' '.join(texto.split())  # quita espacios dobles
    return texto


# --- 2. Normalizar texto en todas las bases ---
for col in ['DEPARTAMENTO', 'MUNICIPIO']:
    merged_final[col] = merged_final[col].astype(str).apply(normalizar)
    pob_2024[col] = pob_2024[col].astype(str).apply(normalizar)


# --- 3. Reemplazos y correcciones en municipios ---
reemplazos_mpios = {
    "CARTAGENA": "CARTAGENA DE INDIAS",
    "CUCUTA": "SAN JOSE DE CUCUTA",
    "DON MATIAS": "DONMATIAS",
    "GUICAN": "GUICAN DE LA SIERRA",
    "LOPEZ": "LOPEZ DE MICAY",
    "MANAURE": "MANAURE BALCON DEL CESAR",
    "SAN ANDRES DE TUMACO": "SAN ANDRES DE TUMACO",
    "SAN ANDRES SOTAVENTO": "SAN ANDRES DE SOTAVENTO",
    "SAN JUAN DE RIO SECO": "SAN JUAN DE RIOSECO",
    "SAN PEDRO": "SAN PEDRO DE LOS MILAGROS",
    "SAN VICENTE": "SAN VICENTE FERRER",
    "SANTAFE DE ANTIOQUIA": "SANTA FE DE ANTIOQUIA",
    "TOLU VIEJO": "SAN JOSE DE TOLUVIEJO",
    "CALI": "SANTIAGO DE CALI",
    "PURISIMA": "PURISIMA DE LA CONCEPCION",
    "PIENDAMO": "PIENDAMO - TUNIA",
    "SOTARA": "SOTARA - PAISPAMBA",
    "CUASPUD": "CUASPUD CARLOSAMA",
    "CERRO SAN ANTONIO": "CERRO DE SAN ANTONIO",
    "CHIBOLO": "CHIVOLO",
    "MARIQUITA": "SAN SEBASTIAN DE MARIQUITA",
}
merged_final['MUNICIPIO'] = merged_final['MUNICIPIO'].replace(reemplazos_mpios)
pob_2024['MUNICIPIO'] = pob_2024['MUNICIPIO'].replace(reemplazos_mpios)


# --- 4. Reemplazos y correcciones en departamentos ---
reemplazos_dptos = {
    "GUAJIRA": "LA GUAJIRA",
    "VALLE": "VALLE DEL CAUCA",
    "SAN ANDRES": "ARCHIPIELAGO DE SAN ANDRES, PROVIDENCIA Y SANTA CATALINA",
    "BOGOTA": "CUNDINAMARCA",
}
merged_final['DEPARTAMENTO'] = merged_final['DEPARTAMENTO'].replace(reemplazos_dptos)
pob_2024['DEPARTAMENTO'] = pob_2024['DEPARTAMENTO'].replace(reemplazos_dptos)


# --- 5. Correcci√≥n especial de Bogot√° ---
mask_bogota = merged_final['MUNICIPIO'].str.contains('BOGOTA', case=False, na=False)
merged_final.loc[mask_bogota, 'DEPARTAMENTO'] = 'CUNDINAMARCA'
merged_final.loc[mask_bogota, 'MUNICIPIO'] = 'BOGOT√Å, D.C.'

mask_bogota_pob = pob_2024['MUNICIPIO'].str.contains('BOGOTA', case=False, na=False)
pob_2024.loc[mask_bogota_pob, 'DEPARTAMENTO'] = 'CUNDINAMARCA'
pob_2024.loc[mask_bogota_pob, 'MUNICIPIO'] = 'BOGOT√Å, D.C.'


# --- 6. Correcciones espec√≠ficas para empalmar con poblaci√≥n ---
pob_2024['MUNICIPIO'] = pob_2024['MUNICIPIO'].replace({
    'MOMPOS': 'SANTA CRUZ DE MOMPOX',
    'SOTARA PAISPAMBA': 'SOTARA - PAISPAMBA'
})


# --- ‚ö†Ô∏è 7. Eliminar registros inv√°lidos (municipio "-") ---
merged_final = merged_final[merged_final['MUNICIPIO'] != '-']
pob_2024 = pob_2024[pob_2024['MUNICIPIO'] != '-']

# Tambi√©n eliminar filas vac√≠as o con "NO REGISTRA"
merged_final = merged_final[~merged_final['MUNICIPIO'].isin(['', 'NO REGISTRA'])]
pob_2024 = pob_2024[~pob_2024['MUNICIPIO'].isin(['', 'NO REGISTRA'])]


# --- 8. Asegurar a√±o como entero ---
merged_final['A√ëO'] = merged_final['A√ëO'].astype(int)
pob_2024['A√ëO'] = pob_2024['A√ëO'].astype(int)


# --- 9. Merge final ---
df_final_pob = merged_final.merge(
    pob_2024,
    on=['DEPARTAMENTO', 'MUNICIPIO', 'A√ëO'],
    how='left',
    indicator='_merge_pob'
)


# --- 10. Verificar coincidencias faltantes ---
sin_pob = (
    df_final_pob[df_final_pob['_merge_pob'] == 'left_only']
    [['DEPARTAMENTO', 'MUNICIPIO']]
    .drop_duplicates()
    .sort_values(['DEPARTAMENTO', 'MUNICIPIO'])
)
print(f"‚ö†Ô∏è Municipios sin coincidencia de poblaci√≥n: {len(sin_pob)}")
display(sin_pob)


# --- 11. Limpieza final ---
df_final_pob = df_final_pob.drop(columns=['_merge_pob'])

print(f"\n‚úÖ Base final combinada con poblaci√≥n: {df_final_pob.shape[0]:,} filas √ó {df_final_pob.shape[1]} columnas")
display(df_final_pob.head(10))

# --- 12. Exportar resultado ---
df_final_pob.to_excel("delitos_con_poblacion_final2024.xlsx", index=False)
print("üìÅ Archivo exportado: delitos_con_poblacion_final2024.xlsx")

for col in df_final_pob.columns:
    print(f"\n=== {col} ===")
    print(df_final_pob[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {df_final_pob[col].nunique()}")