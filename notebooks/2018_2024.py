# -*- coding: utf-8 -*-
"""2018--2024.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a_Z2morMPZb0x-vwtCYB1h2SmW3JFWBp

2018
"""

import pandas as pd

def cargar_delito(url, delito):
    # Por defecto fila 10
    posibles_headers = [10, 9]

    for header_row in posibles_headers:
        try:
            df = pd.read_excel(url, header=header_row).copy()
            # Normalizar nombres
            df.columns = df.columns.str.strip().str.upper().str.replace(" ", "_")

            # Diccionario para unificar columnas
            renombrar = {
                "ARMAS_MEDIOS": "ARMAS_MEDIOS",
                "ARMA_MEDIO": "ARMAS_MEDIOS",
                "ARMAS/MEDIOS": "ARMAS_MEDIOS",
                "ARMAS_Y_MEDIOS": "ARMAS_MEDIOS",
                "CODIGO_DANE": "CODIGO_DANE",
                "FECHA_HECHO": "FECHA_HECHO",
                "GENERO": "GENERO",
                "CANTIDAD": "CANTIDAD",
                "AGRUPA_EDAD_PERSONA": "AGRUPA_EDAD_PERSONA",
                "*AGRUPA_EDAD_PERSONA": "AGRUPA_EDAD_PERSONA",
                "*AGRUPA_EDAD_PERSONA*": "AGRUPA_EDAD_PERSONA"
            }
            df = df.rename(columns=lambda x: renombrar.get(x, x))

            # Seleccionar solo columnas clave
            columnas_validas = [
                "DEPARTAMENTO", "MUNICIPIO", "CODIGO_DANE",
                "ARMAS_MEDIOS", "FECHA_HECHO", "GENERO",
                "AGRUPA_EDAD_PERSONA", "CANTIDAD"
            ]
            df = df[[col for col in columnas_validas if col in df.columns]]

            # Eliminar filas completamente vac√≠as
            df = df.dropna(how="all")

            # Eliminar basura
            basura_regex = "TOTAL|FUENTE|Elaborado|Revisado|Autorizado|Ley 1098|Agrupaci√≥n referente|Contador"
            for col in ["DEPARTAMENTO", "ARMAS_MEDIOS"]:
                if col in df.columns:
                    df = df[~df[col].astype(str).str.contains(basura_regex, na=False, case=False)]

            if not df.empty:
                # CODIGO_DANE num√©rico
                if "CODIGO_DANE" in df.columns:
                    df["CODIGO_DANE"] = pd.to_numeric(df["CODIGO_DANE"], errors="coerce")

                df["TIPO_DELITO"] = delito
                print(f"üìå {delito}: encabezado fijo en fila {header_row}")
                return df
        except Exception as e:
            continue

    print(f"‚ö†Ô∏è {delito}: no se pudo leer con header 9 o 10")
    return pd.DataFrame()


# Diccionario de URLs y delitos para 2018
urls_2018 = [
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/abigeato_2018_2.xlsx", "HURTO CABEZAS GANADO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/amenazas_2018_1.xlsx", "AMENAZAS"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/delitos_sexuales_2018_0.xlsx", "DELITOS SEXUALES"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/extorsion_2018_3.xlsx", "EXTORSI√ìN"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/Homicidio%20Intencional%202018.xlsx", "HOMICIDIO INTENCIONAL"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/homicidios_en_accidente_de_transito_2018_1.xlsx", "HOMICIDIOS EN ACCIDENTE DE TR√ÅNSITO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto_a_personas_2018_1.xlsx", "HURTO A PERSONAS"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto_a_residencias_2018_1.xlsx", "HURTO A RESIDENCIAS"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto_automotores_2018_1.xlsx", "HURTO AUTOMOTORES"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto_motocicletas_2018_0.xlsx", "HURTO MOTOCICLETAS"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto_a_comercio_2018_2.xlsx", "HURTO A COMERCIO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto_a_entidades_financieras_2018_0.xlsx", "HURTO A ENTIDADES FINANCIERAS"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/lesiones_en_accidente_de_transito_2018_0.xlsx", "LESIONES EN ACCIDENTE DE TR√ÅNSITO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/lesiones_personales_2018_0.xlsx", "LESIONES PERSONALES"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/pirateria_terrestre_2018_1.xlsx", "PIRATER√çA TERRESTRE"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/secuestro_2018_3.xlsx", "SECUESTRO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/terrorismo_2018_2.xlsx", "TERRORISMO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/violencia_intrafamiliar_2018_1.xlsx", "VIOLENCIA INTRAFAMILIAR"),
]

# Procesar todos los archivos 2018
dfs_2018 = []
for url, delito in urls_2018:
    df = cargar_delito(url, delito)
    if not df.empty:
        dfs_2018.append(df)
        print(f"‚úÖ {delito}: {df.shape[0]} filas")

# Concatenar todo en un solo DataFrame
df_2018 = pd.concat(dfs_2018, ignore_index=True)

print(f"\nTotal final 2018: {df_2018.shape[0]} filas y {df_2018.shape[1]} columnas")
display(df_2018.head())

# === 14. Valores √∫nicos por columna en df_2018 ===
for col in df_2018.columns:
    print(f"\n=== {col} ===")
    print(df_2018[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {df_2018[col].nunique()}")

# Commented out IPython magic to ensure Python compatibility.
# %pip install unidecode

import pandas as pd
import numpy as np
import unidecode
import re

# --- Estandarizar DEPARTAMENTO ---
df_2018['DEPARTAMENTO'] = df_2018['DEPARTAMENTO'].astype(str).str.strip().str.upper()
df_2018['DEPARTAMENTO'] = df_2018['DEPARTAMENTO'].apply(lambda x: unidecode.unidecode(x))

# --- Estandarizar MUNICIPIO ---
def limpiar_municipio(nombre):
    if pd.isna(nombre):
        return nombre
    nombre = str(nombre).upper().strip()
    nombre = re.sub(r'\(CT\)', '', nombre)  # eliminar (CT)
    nombre = unidecode.unidecode(nombre)     # quitar tildes
    return nombre

df_2018['MUNICIPIO'] = df_2018['MUNICIPIO'].apply(limpiar_municipio)

# Reemplazar 'NAN' como string por NaN
df_2018['MUNICIPIO'] = df_2018['MUNICIPIO'].replace('NAN', np.nan)

# Opcional: eliminar filas donde MUNICIPIO sea NaN
df_2018 = df_2018.dropna(subset=['MUNICIPIO'])

# --- Arreglar FECHA_HECHO ---
def convertir_fecha(valor):
    if isinstance(valor, (float, int)):
        valor_str = str(int(valor))
        return pd.to_datetime(valor_str, format='%Y%m%d', errors='coerce')
    else:
        return pd.to_datetime(valor, errors='coerce')

df_2018['FECHA_HECHO'] = df_2018['FECHA_HECHO'].apply(convertir_fecha)

# --- Resumen de nulos ---
resumen_nulos = pd.DataFrame({
    'Columna': df_2018.columns,
    'Nulos': df_2018.isnull().sum(),
    'Porcentaje_nulos': df_2018.isnull().mean() * 100
})

print(resumen_nulos)

for col in df_2018.columns:
    print(f"\n=== {col} ===")
    print(df_2018[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {df_2018[col].nunique()}")

df_2018.isna().sum()

df_2018['MUNICIPIO'].value_counts(dropna=False).head(10)

print(df_2018['MUNICIPIO'].dtype)   # tipo de dato real
print(df_2018['MUNICIPIO'].isna().sum())  # conteo de nulos
print(df_2018['MUNICIPIO'].head(20))      # primeros valores

df_2018[df_2018['MUNICIPIO'].isna()]

# Ordenar alfab√©ticamente por MUNICIPIO
df_2018 = df_2018.sort_values(by=["MUNICIPIO"], ascending=True).reset_index(drop=True)

print(f"\n Total ordenado: {df_2018.shape[0]} filas y {df_2018.shape[1]} columnas")
display(df_2018.head(20))  # muestra los primeros 20 municipios ordenados

import pandas as pd
import numpy as np

# Crear tabla resumen de nulos
resumen_nulos = pd.DataFrame({
    'Columna': df_2018.columns,
    'Nulos': df_2018.isnull().sum(),
    'NaN explicitos': df_2018.apply(lambda x: x.isna().sum())
})

# Ordenar opcionalmente de mayor a menor nulos
resumen_nulos = resumen_nulos.sort_values(by='Nulos', ascending=False).reset_index(drop=True)

print(resumen_nulos)

import numpy as np

# Reemplazar 'NAN' como string por valores NaN
df_2018['MUNICIPIO'] = df_2018['MUNICIPIO'].replace('NAN', np.nan)

# Ahora contamos nulos y NaN
resumen_nulos = pd.DataFrame({
    'Columna': df_2018.columns,
    'Nulos': df_2018.isnull().sum(),
    'Porcentaje_nulos': df_2018.isnull().mean() * 100
})

print(resumen_nulos)

import numpy as np

# Asegurarnos de que los 'NAN' como texto sean NaN reales
df_2018['MUNICIPIO'].replace('NAN', np.nan, inplace=True)

# Eliminar filas donde MUNICIPIO sea NaN
df_2018 = df_2018.dropna(subset=['MUNICIPIO'])

# Revisar
print(df_2018['MUNICIPIO'].isnull().sum())  # deber√≠a dar 0

import numpy as np

# Reemplazar 'NAN' como string por valores NaN
df_2018['MUNICIPIO'] = df_2018['MUNICIPIO'].replace('NAN', np.nan)

# Ahora contamos nulos y NaN
resumen_nulos = pd.DataFrame({
    'Columna': df_2018.columns,
    'Nulos': df_2018.isnull().sum(),
    'Porcentaje_nulos': df_2018.isnull().mean() * 100
})

print(resumen_nulos)

for col in df_2018.columns:
    print(f"\n=== {col} ===")
    print(df_2018[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {df_2018[col].nunique()}")

"""Poblacion Y DAVIPOLA"""

import pandas as pd
import requests
import numpy as np

# --------------------------
# URLs de insumos externos
# --------------------------
url_poblacion = "https://www.dane.gov.co/files/censo2018/proyecciones-de-poblacion/Municipal/PPED-AreaSexoEdadMun-2018-2042_VP.xlsx"
api_url_divipola = "https://www.datos.gov.co/resource/gdxc-w37w.json?$limit=2000"

# Cargar DIVIPOLA desde la API de datos abiertos
divipola = pd.read_json(api_url_divipola)

# Mostrar las columnas originales
print("üßê Columnas originales en DIVIPOLA:")
print(divipola.columns.tolist())

# (Opcional) ver las primeras filas
display(divipola.head())

df_2018['MUNICIPIO'] = (
    df_2018['MUNICIPIO']
    .astype(str)
    .str.strip()
    .str.upper()
    .apply(lambda x: unidecode.unidecode(x))
)

df_2018['DEPARTAMENTO'] = (
    df_2018['DEPARTAMENTO']
    .astype(str)
    .str.strip()
    .str.upper()
    .apply(lambda x: unidecode.unidecode(x))
)

# --- 1. Importar librer√≠as ---
import pandas as pd
import unidecode

# --- 2. Normalizaci√≥n de texto ---
def normalizar(texto):
    """Convierte a may√∫sculas, elimina tildes, espacios extra y caracteres no est√°ndar"""
    if pd.isna(texto):
        return ''
    texto = str(texto).strip().upper()
    texto = unidecode.unidecode(texto)
    texto = ' '.join(texto.split())  # elimina dobles espacios
    return texto

# --- 3. Estandarizar nombres en ambas bases ---
df_2018['DEPARTAMENTO'] = df_2018['DEPARTAMENTO'].apply(normalizar)
df_2018['MUNICIPIO'] = df_2018['MUNICIPIO'].apply(normalizar)
divipola['dpto'] = divipola['dpto'].apply(normalizar)
divipola['nom_mpio'] = divipola['nom_mpio'].apply(normalizar)

# --- 4. Reemplazos de departamentos ---
reemplazos_dptos = {
    "GUAJIRA": "LA GUAJIRA",
    "VALLE": "VALLE DEL CAUCA",
    "SAN ANDRES": "ARCHIPIELAGO DE SAN ANDRES, PROVIDENCIA Y SANTA CATALINA",
    "BOGOTA": "CUNDINAMARCA",  # Bogot√° se trata como municipio de Cundinamarca
}
df_2018['DEPARTAMENTO'] = df_2018['DEPARTAMENTO'].replace(reemplazos_dptos)
divipola['dpto'] = divipola['dpto'].replace({"BOGOTA, D.C.": "CUNDINAMARCA"})

# --- 5. Correcciones finales de municipios problem√°ticos ---
reemplazos_mpios_final = {
    "CARTAGENA": "CARTAGENA DE INDIAS",
    "CUCUTA": "SAN JOSE DE CUCUTA",
    "DON MATIAS": "DONMATIAS",
    "GUICAN": "GUICAN DE LA SIERRA",
    "LOPEZ": "LOPEZ DE MICAY",
    "MANAURE": "MANAURE BALCON DEL CESAR",
    "SAN ANDRES DE TUMACO": "SAN ANDRES DE TUMACO",
    "SAN ANDRES SOTAVENTO": "SAN ANDRES DE SOTAVENTO",
    "SAN JUAN DE RIO SECO": "SAN JUAN DE RIOSECO",
    "SAN PEDRO": "SAN PEDRO DE LOS MILAGROS",
    "SAN VICENTE": "SAN VICENTE FERRER",
    "SANTAFE DE ANTIOQUIA": "SANTA FE DE ANTIOQUIA",
    "TOLU VIEJO": "SAN JOSE DE TOLUVIEJO",
    "CALI": "SANTIAGO DE CALI",
    "PURISIMA": "PURISIMA DE LA CONCEPCION",
    "PIENDAMO": "PIENDAMO - TUNIA",
    "SOTARA": "SOTARA - PAISPAMBA",
    "CUASPUD": "CUASPUD CARLOSAMA"
}
df_2018['MUNICIPIO'] = df_2018['MUNICIPIO'].replace(reemplazos_mpios_final)

# --- 6. Correcci√≥n de departamentos espec√≠ficos ---
df_2018.loc[df_2018['MUNICIPIO'] == "MANAURE BALCON DEL CESAR", 'DEPARTAMENTO'] = "CESAR"
df_2018.loc[df_2018['MUNICIPIO'] == "SAN ANDRES DE TUMACO", 'DEPARTAMENTO'] = "NARINO"
df_2018.loc[df_2018['MUNICIPIO'] == "SAN ANDRES", 'DEPARTAMENTO'] = "ARCHIPIELAGO DE SAN ANDRES, PROVIDENCIA Y SANTA CATALINA"

# --- 7. Ajuste especial de Bogot√° ---
mask_bogota = df_2018['MUNICIPIO'].str.contains('BOGOTA', case=False, na=False)
df_2018.loc[mask_bogota, 'DEPARTAMENTO'] = 'CUNDINAMARCA'
df_2018.loc[mask_bogota, 'MUNICIPIO'] = 'BOGOTA, D.C.'

divipola.loc[
    divipola['nom_mpio'].str.contains('BOGOTA', case=False, na=False),
    ['dpto', 'nom_mpio']
] = ['CUNDINAMARCA', 'BOGOTA, D.C.']

# --- 8. Correcciones finales (√∫ltimos 5 municipios) ---
reemplazos_finales_extra = {
    "CERRO SAN ANTONIO": "CERRO DE SAN ANTONIO",
    "CHIBOLO": "CHIVOLO",
    "MARIQUITA": "SAN SEBASTIAN DE MARIQUITA",
}
df_2018['MUNICIPIO'] = df_2018['MUNICIPIO'].replace(reemplazos_finales_extra)

# --- 9. Corregir departamentos err√≥neos ---
df_2018.loc[df_2018['MUNICIPIO'] == "SAN PEDRO DE LOS MILAGROS", 'DEPARTAMENTO'] = "ANTIOQUIA"

# --- 10. Agregar a√±o ---
df_2018['A√ëO'] = 2018

# --- 11. Merge final ---
merged_final = df_2018.merge(
    divipola,
    left_on=['DEPARTAMENTO', 'MUNICIPIO'],
    right_on=['dpto', 'nom_mpio'],
    how='left',
    indicator=True
)

# --- 12. Verificar sin coincidencias ---
sin_match_final = (
    merged_final[merged_final['_merge'] == 'left_only'][['DEPARTAMENTO', 'MUNICIPIO']]
    .drop_duplicates()
    .sort_values(['DEPARTAMENTO', 'MUNICIPIO'])
)
print(f"‚úÖ Municipios sin coincidencia tras correcci√≥n final: {len(sin_match_final)}")
display(sin_match_final)

# --- 13. Resultado final ---
print(f"\n‚úÖ Base unida correctamente: {merged_final.shape[0]:,} filas √ó {merged_final.shape[1]} columnas")

for col in merged_final.columns:
    print(f"\n=== {col} ===")
    print(merged_final[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {merged_final[col].nunique()}")

# Comparar los departamentos de ambos DataFrames
set_df = set(df_2018['DEPARTAMENTO'].unique())
set_divi = set(divipola['dpto'].unique())

faltante_en_df2018 = set_divi - set_df
faltante_en_divipola = set_df - set_divi

print("üß© Departamento(s) que est√°n en DIVIPOLA pero no en df_2018:")
print(faltante_en_df2018)

print("\nüîπ Departamento(s) que est√°n en df_2018 pero no en DIVIPOLA:")
print(faltante_en_divipola)

# ========================================
# 2. CARGAR Y PROCESAR POBLACI√ìN
# ========================================

import pandas as pd
import unidecode

print("\nüì• Descargando datos de poblaci√≥n...")

# Leer archivo Excel del DANE
pob = pd.read_excel(
    url_poblacion,
    sheet_name='PobMunicipalx√ÅreaSexoEdad',
    header=7
)

# --- Normalizar nombres de columnas ---
pob.columns = (
    pob.columns.str.upper()
    .str.strip()
    .str.replace(' ', '_')
    .str.replace('√Å', 'A')
    .str.replace('.', '', regex=False)
)

# --- Verificaci√≥n de nombres existentes ---
print(f"Columnas detectadas: {list(pob.columns)}")

# --- Seleccionar solo columnas que existan ---
columnas_requeridas = ['DP', 'DPNOM', 'MPIO', 'MPNOM', 'DPMP', 'A√ëO', 'AREA_GEOGRAFICA', 'TOTAL']
cols_existentes = [col for col in columnas_requeridas if col in pob.columns]
pob = pob[cols_existentes].copy()

print(f"\nColumnas seleccionadas para procesamiento: {pob.columns.tolist()}")

# --- Si no existe MPNOM, intentar usar el nombre alternativo (MPIO) ---
if 'MPNOM' not in pob.columns and 'MPIO' in pob.columns:
    pob = pob.rename(columns={'MPIO': 'MPNOM'})

# --- Normalizar texto de nombres ---
def normalizar(texto):
    if pd.isna(texto):
        return ''
    texto = str(texto).strip().upper()
    texto = unidecode.unidecode(texto)
    texto = ' '.join(texto.split())
    return texto

pob['DPNOM'] = pob['DPNOM'].apply(normalizar)
pob['MPNOM'] = pob['MPNOM'].apply(normalizar)

# --- Filtrar solo filas donde el √°rea geogr√°fica sea TOTAL o TOTALES ---
if 'AREA_GEOGRAFICA' in pob.columns:
    pob = pob[pob['AREA_GEOGRAFICA'].str.contains('TOTAL', case=False, na=False)]

# --- Renombrar columnas para merge posterior ---
pob = pob.rename(columns={
    'DPNOM': 'DEPARTAMENTO',
    'MPNOM': 'CODIGO_DANE_POB	',
    'DPMP': 'MUNICIPIO',
    'TOTAL': 'POBLACION_TOTAL'
})

# --- Filtrar solo a√±o 2018 ---
pob_2018 = pob[pob['A√ëO'] == 2018].copy()

# --- Eliminar duplicados ---
pob_2018 = pob_2018.drop_duplicates(subset=['DEPARTAMENTO', 'MUNICIPIO'])

print(f"‚úÖ Registros de poblaci√≥n 2018 (√°rea TOTAL) procesados: {len(pob_2018):,}")

# --- Vista previa ---
display(pob_2018.head(10))

for col in pob_2018.columns:
    print(f"\n=== {col} ===")
    print(pob_2018[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {pob_2018[col].nunique()}")

# ====================================================
# üî† PASAR TODA LA BASE pob_2018 A MAY√öSCULAS Y NORMALIZAR
# ====================================================

import unidecode
import pandas as pd

def normalizar_texto(valor):
    """Convierte todo texto a may√∫sculas, quita tildes y espacios dobles."""
    if isinstance(valor, str):
        valor = unidecode.unidecode(valor)  # quita tildes
        valor = valor.upper().strip()
        valor = ' '.join(valor.split())      # elimina espacios dobles
    return valor

# Aplicar a todas las columnas de tipo texto
for col in pob_2018.columns:
    if pob_2018[col].dtype == 'object':
        pob_2018[col] = pob_2018[col].apply(normalizar_texto)

print("‚úÖ Toda la base de poblaci√≥n est√° ahora en MAY√öSCULAS y sin tildes.")
display(pob_2018.head(10))

municipios_pob = sorted(pob_2018['MUNICIPIO'].dropna().unique())
print(f"Total de municipios en pob_2018: {len(municipios_pob)}\n")
print(municipios_pob)

# =========================================================
# üîó MERGE FINAL: Base de delitos + DIVIPOLA + POBLACI√ìN
# Compatible con cualquier a√±o (ej. 2018, 2019, etc.)
# =========================================================

import pandas as pd
import unidecode

# --- 1. Funci√≥n de normalizaci√≥n ---
def normalizar(texto):
    """Convierte a may√∫sculas, elimina tildes y espacios extra."""
    if pd.isna(texto):
        return ''
    texto = str(texto).strip().upper()
    texto = unidecode.unidecode(texto)
    texto = ' '.join(texto.split())  # quita espacios dobles
    return texto


# --- 2. Normalizar texto en todas las bases ---
for col in ['DEPARTAMENTO', 'MUNICIPIO']:
    merged_final[col] = merged_final[col].astype(str).apply(normalizar)
    pob_2018[col] = pob_2018[col].astype(str).apply(normalizar)


# --- 3. Reemplazos y correcciones en municipios ---
reemplazos_mpios = {
    "CARTAGENA": "CARTAGENA DE INDIAS",
    "CUCUTA": "SAN JOSE DE CUCUTA",
    "DON MATIAS": "DONMATIAS",
    "GUICAN": "GUICAN DE LA SIERRA",
    "LOPEZ": "LOPEZ DE MICAY",
    "MANAURE": "MANAURE BALCON DEL CESAR",
    "SAN ANDRES DE TUMACO": "SAN ANDRES DE TUMACO",
    "SAN ANDRES SOTAVENTO": "SAN ANDRES DE SOTAVENTO",
    "SAN JUAN DE RIO SECO": "SAN JUAN DE RIOSECO",
    "SAN PEDRO": "SAN PEDRO DE LOS MILAGROS",
    "SAN VICENTE": "SAN VICENTE FERRER",
    "SANTAFE DE ANTIOQUIA": "SANTA FE DE ANTIOQUIA",
    "TOLU VIEJO": "SAN JOSE DE TOLUVIEJO",
    "CALI": "SANTIAGO DE CALI",
    "PURISIMA": "PURISIMA DE LA CONCEPCION",
    "PIENDAMO": "PIENDAMO - TUNIA",
    "SOTARA": "SOTARA - PAISPAMBA",
    "CUASPUD": "CUASPUD CARLOSAMA",
    "CERRO SAN ANTONIO": "CERRO DE SAN ANTONIO",
    "CHIBOLO": "CHIVOLO",
    "MARIQUITA": "SAN SEBASTIAN DE MARIQUITA",
}
merged_final['MUNICIPIO'] = merged_final['MUNICIPIO'].replace(reemplazos_mpios)
pob_2018['MUNICIPIO'] = pob_2018['MUNICIPIO'].replace(reemplazos_mpios)


# --- 4. Reemplazos y correcciones en departamentos ---
reemplazos_dptos = {
    "GUAJIRA": "LA GUAJIRA",
    "VALLE": "VALLE DEL CAUCA",
    "SAN ANDRES": "ARCHIPIELAGO DE SAN ANDRES, PROVIDENCIA Y SANTA CATALINA",
    "BOGOTA": "CUNDINAMARCA",
}
merged_final['DEPARTAMENTO'] = merged_final['DEPARTAMENTO'].replace(reemplazos_dptos)
pob_2018['DEPARTAMENTO'] = pob_2018['DEPARTAMENTO'].replace(reemplazos_dptos)


# --- 5. Correcci√≥n especial de Bogot√° ---
mask_bogota = merged_final['MUNICIPIO'].str.contains('BOGOTA', case=False, na=False)
merged_final.loc[mask_bogota, 'DEPARTAMENTO'] = 'CUNDINAMARCA'
merged_final.loc[mask_bogota, 'MUNICIPIO'] = 'BOGOT√Å, D.C.'

mask_bogota_pob = pob_2018['MUNICIPIO'].str.contains('BOGOTA', case=False, na=False)
pob_2018.loc[mask_bogota_pob, 'DEPARTAMENTO'] = 'CUNDINAMARCA'
pob_2018.loc[mask_bogota_pob, 'MUNICIPIO'] = 'BOGOT√Å, D.C.'


# --- 6. Asegurar a√±o como entero ---
merged_final['A√ëO'] = merged_final['A√ëO'].astype(int)
pob_2018['A√ëO'] = pob_2018['A√ëO'].astype(int)


# --- 7. Merge final por departamento, municipio y a√±o ---
df_final_pob = merged_final.merge(
    pob_2018,
    on=['DEPARTAMENTO', 'MUNICIPIO', 'A√ëO'],
    how='left',
    indicator='_merge_pob'
)


# --- 8. Verificar coincidencias faltantes ---
sin_pob = (
    df_final_pob[df_final_pob['_merge_pob'] == 'left_only']
    [['DEPARTAMENTO', 'MUNICIPIO']]
    .drop_duplicates()
    .sort_values(['DEPARTAMENTO', 'MUNICIPIO'])
)
print(f"‚ö†Ô∏è Municipios sin coincidencia de poblaci√≥n: {len(sin_pob)}")
display(sin_pob)


# --- 9. Limpieza final ---
df_final_pob = df_final_pob.drop(columns=['_merge_pob'])

print(f"\n‚úÖ Base final combinada con poblaci√≥n: {df_final_pob.shape[0]:,} filas √ó {df_final_pob.shape[1]} columnas")
display(df_final_pob.head(10))


# --- 10. Exportar resultado ---
df_final_pob.to_excel("delitos_con_poblacion_final2018.xlsx", index=False)
print("üìÅ Archivo exportado: delitos_con_poblacion_final2018.xlsx")

for col in df_final_pob.columns:
    print(f"\n=== {col} ===")
    print(df_final_pob[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {df_final_pob[col].nunique()}")

"""2019"""

def cargar_delito(url, delito):
    # Por defecto fila 10
    posibles_headers = [8, 9, 10, 11, 12]

    for header_row in posibles_headers:
        try:
            df = pd.read_excel(url, header=header_row).copy()
            # Normalizar nombres
            df.columns = df.columns.str.strip().str.upper().str.replace(" ", "_")

            # Diccionario para unificar columnas
            renombrar = {
                "ARMAS_MEDIOS": "ARMAS_MEDIOS",
                "ARMA_MEDIO": "ARMAS_MEDIOS",
                "ARMAS/MEDIOS": "ARMAS_MEDIOS",
                "ARMAS_Y_MEDIOS": "ARMAS_MEDIOS",
                "CODIGO_DANE": "CODIGO_DANE",
                "FECHA_HECHO": "FECHA_HECHO",
                "GENERO": "GENERO",
                "CANTIDAD": "CANTIDAD",
                "AGRUPA_EDAD_PERSONA": "AGRUPA_EDAD_PERSONA",
                "*AGRUPA_EDAD_PERSONA": "AGRUPA_EDAD_PERSONA",
                "*AGRUPA_EDAD_PERSONA*": "AGRUPA_EDAD_PERSONA"
            }
            df = df.rename(columns=lambda x: renombrar.get(x, x))

            # Seleccionar solo columnas clave
            columnas_validas = [
                "DEPARTAMENTO", "MUNICIPIO", "CODIGO_DANE",
                "ARMAS_MEDIOS", "FECHA_HECHO", "GENERO",
                "AGRUPA_EDAD_PERSONA", "CANTIDAD"
            ]
            df = df[[col for col in columnas_validas if col in df.columns]]

            # Eliminar filas completamente vac√≠as
            df = df.dropna(how="all")

            # Eliminar basura
            basura_regex = "TOTAL|FUENTE|Elaborado|Revisado|Autorizado|Ley 1098|Agrupaci√≥n referente|Contador"
            for col in ["DEPARTAMENTO", "ARMAS_MEDIOS"]:
                if col in df.columns:
                    df = df[~df[col].astype(str).str.contains(basura_regex, na=False, case=False)]

            if not df.empty:
                # CODIGO_DANE num√©rico
                if "CODIGO_DANE" in df.columns:
                    df["CODIGO_DANE"] = pd.to_numeric(df["CODIGO_DANE"], errors="coerce")

                df["TIPO_DELITO"] = delito
                print(f"üìå {delito}: encabezado fijo en fila {header_row}")
                return df
        except Exception as e:
            continue

    print(f"‚ö†Ô∏è {delito}: no se pudo leer con header 9 o 10")
    return pd.DataFrame()

# Diccionario de URLs y delitos para 2019
urls_2019 = [
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/abigeato_2019_3.xlsx", "HURTO CABEZAS GANADO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/amenazas_2019_1.xlsx", "AMENAZAS"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/delitos_sexuales_2019_0.xlsx", "DELITOS SEXUALES"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/extorsion_2019_2.xlsx", "EXTORSI√ìN"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/Homicidio%20Intencional%202019.xlsx", "HOMICIDIO INTENCIONAL"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/homicidios_en_accidente_de_transito_2019.xlsx", "HOMICIDIOS EN ACCIDENTE DE TR√ÅNSITO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto_a_personas_2019_0.xlsx", "HURTO A PERSONAS"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto_a_residencias_2019_0.xlsx", "HURTO A RESIDENCIAS"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto_automotores_2019_0.xlsx", "HURTO AUTOMOTORES"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto_motocicletas_2019_0.xlsx", "HURTO MOTOCICLETAS"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto_a_comercio_2019_0.xlsx", "HURTO A COMERCIO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto_a_entidades_financieras_2019_3.xlsx", "HURTO A ENTIDADES FINANCIERAS"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/lesiones_en_accidente_de_transito_2019_0.xlsx", "LESIONES EN ACCIDENTE DE TR√ÅNSITO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/lesiones_personales_2019_0.xlsx", "LESIONES PERSONALES"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/pirateria_terrestre_2019_3.xlsx", "PIRATER√çA TERRESTRE"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/secuestro_2019_3.xlsx", "SECUESTRO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/terrorismo_2019_2.xlsx", "TERRORISMO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/violencia_intrafamiliar_2019_0.xlsx", "VIOLENCIA INTRAFAMILIAR"),
]

# Procesar todos los archivos 2019
dfs_2019 = []
for url, delito in urls_2019:
    df = cargar_delito(url, delito)
    if not df.empty:
        dfs_2019.append(df)
        print(f"‚úÖ {delito}: {df.shape[0]} filas")

# Concatenar todo en un solo DataFrame
df_2019 = pd.concat(dfs_2019, ignore_index=True)

print(f"\nTotal final 2019: {df_2019.shape[0]} filas y {df_2019.shape[1]} columnas")
display(df_2019.head())

# === 14. Valores √∫nicos por columna en df_2018 ===
for col in df_2019.columns:
    print(f"\n=== {col} ===")
    print(df_2019[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {df_2019[col].nunique()}")

# Commented out IPython magic to ensure Python compatibility.
# %pip install unidecode

import pandas as pd
import numpy as np
import unidecode
import re

# --- Estandarizar DEPARTAMENTO ---
df_2019['DEPARTAMENTO'] = df_2019['DEPARTAMENTO'].astype(str).str.strip().str.upper()
df_2019['DEPARTAMENTO'] = df_2019['DEPARTAMENTO'].apply(lambda x: unidecode.unidecode(x))

# --- Estandarizar MUNICIPIO ---
def limpiar_municipio(nombre):
    if pd.isna(nombre):
        return nombre
    nombre = str(nombre).upper().strip()
    nombre = re.sub(r'\(CT\)', '', nombre)  # eliminar (CT)
    nombre = unidecode.unidecode(nombre)     # quitar tildes
    return nombre

df_2019['MUNICIPIO'] = df_2019['MUNICIPIO'].apply(limpiar_municipio)

# Reemplazar 'NAN' como string por NaN
df_2019['MUNICIPIO'] = df_2019['MUNICIPIO'].replace('NAN', np.nan)

# Opcional: eliminar filas donde MUNICIPIO sea NaN
df_2019 = df_2019.dropna(subset=['MUNICIPIO'])

# --- Arreglar FECHA_HECHO ---
def convertir_fecha(valor):
    if isinstance(valor, (float, int)):
        valor_str = str(int(valor))
        return pd.to_datetime(valor_str, format='%Y%m%d', errors='coerce')
    else:
        return pd.to_datetime(valor, errors='coerce')

df_2019['FECHA_HECHO'] = df_2019['FECHA_HECHO'].apply(convertir_fecha)

# --- Resumen de nulos ---
resumen_nulos = pd.DataFrame({
    'Columna': df_2019.columns,
    'Nulos': df_2019.isnull().sum(),
    'Porcentaje_nulos': df_2019.isnull().mean() * 100
})

print(resumen_nulos)

for col in df_2019.columns:
    print(f"\n=== {col} ===")
    print(df_2019[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {df_2019[col].nunique()}")

df_2019.isna().sum()

df_2019['MUNICIPIO'].value_counts(dropna=False).head(10)

print(df_2019['MUNICIPIO'].dtype)   # tipo de dato real
print(df_2019['MUNICIPIO'].isna().sum())  # conteo de nulos
print(df_2019['MUNICIPIO'].head(20))      # primeros valores

df_2019[df_2019['MUNICIPIO'].isna()]

# Ordenar alfab√©ticamente por MUNICIPIO
df_2018 = df_2019.sort_values(by=["MUNICIPIO"], ascending=True).reset_index(drop=True)

print(f"\n Total ordenado: {df_2019.shape[0]} filas y {df_2019.shape[1]} columnas")
display(df_2019.head(20))  # muestra los primeros 20 municipios ordenados

import pandas as pd
import numpy as np

# Crear tabla resumen de nulos
resumen_nulos = pd.DataFrame({
    'Columna': df_2019.columns,
    'Nulos': df_2019.isnull().sum(),
    'NaN explicitos': df_2019.apply(lambda x: x.isna().sum())
})

# Ordenar opcionalmente de mayor a menor nulos
resumen_nulos = resumen_nulos.sort_values(by='Nulos', ascending=False).reset_index(drop=True)

print(resumen_nulos)

import numpy as np

# Reemplazar 'NAN' como string por valores NaN
df_2019['MUNICIPIO'] = df_2019['MUNICIPIO'].replace('NAN', np.nan)

# Ahora contamos nulos y NaN
resumen_nulos = pd.DataFrame({
    'Columna': df_2019.columns,
    'Nulos': df_2019.isnull().sum(),
    'Porcentaje_nulos': df_2019.isnull().mean() * 100
})

print(resumen_nulos)

import numpy as np

# Asegurarnos de que los 'NAN' como texto sean NaN reales
df_2019['MUNICIPIO'].replace('NAN', np.nan, inplace=True)

# Eliminar filas donde MUNICIPIO sea NaN
df_2019 = df_2019.dropna(subset=['MUNICIPIO'])

# Revisar
print(df_2019['MUNICIPIO'].isnull().sum())  # deber√≠a dar 0

import numpy as np

# Reemplazar 'NAN' como string por valores NaN
df_2019['MUNICIPIO'] = df_2019['MUNICIPIO'].replace('NAN', np.nan)

# Ahora contamos nulos y NaN
resumen_nulos = pd.DataFrame({
    'Columna': df_2019.columns,
    'Nulos': df_2019.isnull().sum(),
    'Porcentaje_nulos': df_2019.isnull().mean() * 100
})

print(resumen_nulos)

for col in df_2019.columns:
    print(f"\n=== {col} ===")
    print(df_2019[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {df_2019[col].nunique()}")

"""Poblacion Y DAVIPOLA"""

import pandas as pd
import requests
import numpy as np

# --------------------------
# URLs de insumos externos
# --------------------------
url_poblacion = "https://www.dane.gov.co/files/censo2018/proyecciones-de-poblacion/Municipal/PPED-AreaSexoEdadMun-2018-2042_VP.xlsx"
api_url_divipola = "https://www.datos.gov.co/resource/gdxc-w37w.json?$limit=2000"

# Cargar DIVIPOLA desde la API de datos abiertos
divipola = pd.read_json(api_url_divipola)

# Mostrar las columnas originales
print("üßê Columnas originales en DIVIPOLA:")
print(divipola.columns.tolist())

# (Opcional) ver las primeras filas
display(divipola.head())

df_2019['MUNICIPIO'] = (
    df_2019['MUNICIPIO']
    .astype(str)
    .str.strip()
    .str.upper()
    .apply(lambda x: unidecode.unidecode(x))
)

df_2019['DEPARTAMENTO'] = (
    df_2019['DEPARTAMENTO']
    .astype(str)
    .str.strip()
    .str.upper()
    .apply(lambda x: unidecode.unidecode(x))
)

# --- 1. Importar librer√≠as ---
import pandas as pd
import unidecode

# --- 2. Normalizaci√≥n de texto ---
def normalizar(texto):
    """Convierte a may√∫sculas, elimina tildes, espacios extra y caracteres no est√°ndar"""
    if pd.isna(texto):
        return ''
    texto = str(texto).strip().upper()
    texto = unidecode.unidecode(texto)
    texto = ' '.join(texto.split())  # elimina dobles espacios
    return texto

# --- 3. Estandarizar nombres en ambas bases ---
df_2019['DEPARTAMENTO'] = df_2019['DEPARTAMENTO'].apply(normalizar)
df_2019['MUNICIPIO'] = df_2019['MUNICIPIO'].apply(normalizar)
divipola['dpto'] = divipola['dpto'].apply(normalizar)
divipola['nom_mpio'] = divipola['nom_mpio'].apply(normalizar)

# --- 4. Eliminar registros sin informaci√≥n ---
df_2019 = df_2019[~df_2019['MUNICIPIO'].isin(['NO REGISTRA'])]
df_2019 = df_2019[~df_2019['DEPARTAMENTO'].isin(['NO REGISTRA'])]

# --- 5. Reemplazos de departamentos ---
reemplazos_dptos = {
    "GUAJIRA": "LA GUAJIRA",
    "VALLE": "VALLE DEL CAUCA",
    "SAN ANDRES": "ARCHIPIELAGO DE SAN ANDRES, PROVIDENCIA Y SANTA CATALINA",
    "BOGOTA": "CUNDINAMARCA",  # Bogot√° se trata como municipio de Cundinamarca
}
df_2019['DEPARTAMENTO'] = df_2019['DEPARTAMENTO'].replace(reemplazos_dptos)
divipola['dpto'] = divipola['dpto'].replace({"BOGOTA, D.C.": "CUNDINAMARCA"})

# --- 6. Correcciones finales de municipios problem√°ticos ---
reemplazos_mpios_final = {
    "CARTAGENA": "CARTAGENA DE INDIAS",
    "CUCUTA": "SAN JOSE DE CUCUTA",
    "DON MATIAS": "DONMATIAS",
    "GUICAN": "GUICAN DE LA SIERRA",
    "LOPEZ": "LOPEZ DE MICAY",
    "MANAURE": "MANAURE BALCON DEL CESAR",
    "MOMPOS": "SANTA CRUZ DE MOMPOX",  # ‚úÖ corregido aqu√≠
    "SAN ANDRES DE TUMACO": "SAN ANDRES DE TUMACO",
    "SAN ANDRES SOTAVENTO": "SAN ANDRES DE SOTAVENTO",
    "SAN JUAN DE RIO SECO": "SAN JUAN DE RIOSECO",
    "SAN PEDRO": "SAN PEDRO DE LOS MILAGROS",
    "SAN VICENTE": "SAN VICENTE FERRER",
    "SANTAFE DE ANTIOQUIA": "SANTA FE DE ANTIOQUIA",
    "TOLU VIEJO": "SAN JOSE DE TOLUVIEJO",
    "CALI": "SANTIAGO DE CALI",
    "PURISIMA": "PURISIMA DE LA CONCEPCION",
    "PIENDAMO": "PIENDAMO - TUNIA",
    "SOTARA": "SOTARA - PAISPAMBA",
    "CUASPUD": "CUASPUD CARLOSAMA"
}
df_2019['MUNICIPIO'] = df_2019['MUNICIPIO'].replace(reemplazos_mpios_final)

# --- 7. Correcci√≥n de departamentos espec√≠ficos ---
df_2019.loc[df_2019['MUNICIPIO'] == "MANAURE BALCON DEL CESAR", 'DEPARTAMENTO'] = "CESAR"
df_2019.loc[df_2019['MUNICIPIO'] == "SAN ANDRES DE TUMACO", 'DEPARTAMENTO'] = "NARINO"
df_2019.loc[df_2019['MUNICIPIO'] == "SAN ANDRES", 'DEPARTAMENTO'] = "ARCHIPIELAGO DE SAN ANDRES, PROVIDENCIA Y SANTA CATALINA"

# --- 8. Ajuste especial de Bogot√° ---
mask_bogota = df_2019['MUNICIPIO'].str.contains('BOGOTA', case=False, na=False)
df_2019.loc[mask_bogota, 'DEPARTAMENTO'] = 'CUNDINAMARCA'
df_2019.loc[mask_bogota, 'MUNICIPIO'] = 'BOGOTA, D.C.'

divipola.loc[
    divipola['nom_mpio'].str.contains('BOGOTA', case=False, na=False),
    ['dpto', 'nom_mpio']
] = ['CUNDINAMARCA', 'BOGOTA, D.C.']

# --- 9. Correcciones finales (√∫ltimos 5 municipios) ---
reemplazos_finales_extra = {
    "CERRO SAN ANTONIO": "CERRO DE SAN ANTONIO",
    "CHIBOLO": "CHIVOLO",
    "MARIQUITA": "SAN SEBASTIAN DE MARIQUITA",
}
df_2019['MUNICIPIO'] = df_2019['MUNICIPIO'].replace(reemplazos_finales_extra)

# --- 10. Corregir departamentos err√≥neos ---
df_2019.loc[df_2019['MUNICIPIO'] == "SAN PEDRO DE LOS MILAGROS", 'DEPARTAMENTO'] = "ANTIOQUIA"

# --- 11. Agregar a√±o ---
df_2019['A√ëO'] = 2019

# --- 12. Merge final con DIVIPOLA ---
merged_final = df_2019.merge(
    divipola,
    left_on=['DEPARTAMENTO', 'MUNICIPIO'],
    right_on=['dpto', 'nom_mpio'],
    how='left',
    indicator=True
)

# --- 13. Verificar sin coincidencias ---
sin_match_final = (
    merged_final[merged_final['_merge'] == 'left_only'][['DEPARTAMENTO', 'MUNICIPIO']]
    .drop_duplicates()
    .sort_values(['DEPARTAMENTO', 'MUNICIPIO'])
)
print(f"‚úÖ Municipios sin coincidencia tras correcci√≥n final: {len(sin_match_final)}")
display(sin_match_final)

# --- 14. Resultado final ---
print(f"\n‚úÖ Base unida correctamente: {merged_final.shape[0]:,} filas √ó {merged_final.shape[1]} columnas")

for col in merged_final.columns:
    print(f"\n=== {col} ===")
    print(merged_final[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {merged_final[col].nunique()}")

# Comparar los departamentos de ambos DataFrames
set_df = set(df_2019['DEPARTAMENTO'].unique())
set_divi = set(divipola['dpto'].unique())

faltante_en_df2019 = set_divi - set_df
faltante_en_divipola = set_df - set_divi

print("üß© Departamento(s) que est√°n en DIVIPOLA pero no en df_2019:")
print(faltante_en_df2019)

print("\nüîπ Departamento(s) que est√°n en df_2019 pero no en DIVIPOLA:")
print(faltante_en_divipola)

# ========================================
# 2. CARGAR Y PROCESAR POBLACI√ìN
# ========================================

import pandas as pd
import unidecode

print("\nüì• Descargando datos de poblaci√≥n...")

# Leer archivo Excel del DANE
pob = pd.read_excel(
    url_poblacion,
    sheet_name='PobMunicipalx√ÅreaSexoEdad',
    header=7
)

# --- Normalizar nombres de columnas ---
pob.columns = (
    pob.columns.str.upper()
    .str.strip()
    .str.replace(' ', '_')
    .str.replace('√Å', 'A')
    .str.replace('.', '', regex=False)
)

# --- Verificaci√≥n de nombres existentes ---
print(f"Columnas detectadas: {list(pob.columns)}")

# --- Seleccionar solo columnas que existan ---
columnas_requeridas = ['DP', 'DPNOM', 'MPIO', 'MPNOM', 'DPMP', 'A√ëO', 'AREA_GEOGRAFICA', 'TOTAL']
cols_existentes = [col for col in columnas_requeridas if col in pob.columns]
pob = pob[cols_existentes].copy()

print(f"\nColumnas seleccionadas para procesamiento: {pob.columns.tolist()}")

# --- Si no existe MPNOM, intentar usar el nombre alternativo (MPIO) ---
if 'MPNOM' not in pob.columns and 'MPIO' in pob.columns:
    pob = pob.rename(columns={'MPIO': 'MPNOM'})

# --- Normalizar texto de nombres ---
def normalizar(texto):
    if pd.isna(texto):
        return ''
    texto = str(texto).strip().upper()
    texto = unidecode.unidecode(texto)
    texto = ' '.join(texto.split())
    return texto

pob['DPNOM'] = pob['DPNOM'].apply(normalizar)
pob['MPNOM'] = pob['MPNOM'].apply(normalizar)

# --- Filtrar solo filas donde el √°rea geogr√°fica sea TOTAL o TOTALES ---
if 'AREA_GEOGRAFICA' in pob.columns:
    pob = pob[pob['AREA_GEOGRAFICA'].str.contains('TOTAL', case=False, na=False)]

# --- Renombrar columnas para merge posterior ---
pob = pob.rename(columns={
    'DPNOM': 'DEPARTAMENTO',
    'MPNOM': 'CODIGO_DANE_POB	',
    'DPMP': 'MUNICIPIO',
    'TOTAL': 'POBLACION_TOTAL'
})

# --- Filtrar solo a√±o 2018 ---
pob_2019 = pob[pob['A√ëO'] == 2019].copy()

# --- Eliminar duplicados ---
pob_2019 = pob_2019.drop_duplicates(subset=['DEPARTAMENTO', 'MUNICIPIO'])

print(f"‚úÖ Registros de poblaci√≥n 2019 (√°rea TOTAL) procesados: {len(pob_2019):,}")

# --- Vista previa ---
display(pob_2019.head(10))

for col in pob_2019.columns:
    print(f"\n=== {col} ===")
    print(pob_2019[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {pob_2019[col].nunique()}")

# ====================================================
# üî† PASAR TODA LA BASE pob_2018 A MAY√öSCULAS Y NORMALIZAR
# ====================================================

import unidecode
import pandas as pd

def normalizar_texto(valor):
    """Convierte todo texto a may√∫sculas, quita tildes y espacios dobles."""
    if isinstance(valor, str):
        valor = unidecode.unidecode(valor)  # quita tildes
        valor = valor.upper().strip()
        valor = ' '.join(valor.split())      # elimina espacios dobles
    return valor

# Aplicar a todas las columnas de tipo texto
for col in pob_2019.columns:
    if pob_2019[col].dtype == 'object':
        pob_2019[col] = pob_2019[col].apply(normalizar_texto)

print("‚úÖ Toda la base de poblaci√≥n est√° ahora en MAY√öSCULAS y sin tildes.")
display(pob_2019.head(10))

municipios_pob = sorted(pob_2019['MUNICIPIO'].dropna().unique())
print(f"Total de municipios en pob_2019: {len(municipios_pob)}\n")
print(municipios_pob)

# =========================================================
# üîó MERGE FINAL: Base de delitos + DIVIPOLA + POBLACI√ìN
# Compatible con cualquier a√±o (ej. 2018, 2019, etc.)
# =========================================================

import pandas as pd
import unidecode

# --- 1. Funci√≥n de normalizaci√≥n ---
def normalizar(texto):
    """Convierte a may√∫sculas, elimina tildes y espacios extra."""
    if pd.isna(texto):
        return ''
    texto = str(texto).strip().upper()
    texto = unidecode.unidecode(texto)
    texto = ' '.join(texto.split())  # quita espacios dobles
    return texto


# --- 2. Normalizar texto en todas las bases ---
for col in ['DEPARTAMENTO', 'MUNICIPIO']:
    merged_final[col] = merged_final[col].astype(str).apply(normalizar)
    pob_2019[col] = pob_2019[col].astype(str).apply(normalizar)


# --- 3. Reemplazos y correcciones en municipios ---
reemplazos_mpios = {
    "CARTAGENA": "CARTAGENA DE INDIAS",
    "CUCUTA": "SAN JOSE DE CUCUTA",
    "DON MATIAS": "DONMATIAS",
    "GUICAN": "GUICAN DE LA SIERRA",
    "LOPEZ": "LOPEZ DE MICAY",
    "MANAURE": "MANAURE BALCON DEL CESAR",
    "SAN ANDRES DE TUMACO": "SAN ANDRES DE TUMACO",
    "SAN ANDRES SOTAVENTO": "SAN ANDRES DE SOTAVENTO",
    "SAN JUAN DE RIO SECO": "SAN JUAN DE RIOSECO",
    "SAN PEDRO": "SAN PEDRO DE LOS MILAGROS",
    "SAN VICENTE": "SAN VICENTE FERRER",
    "SANTAFE DE ANTIOQUIA": "SANTA FE DE ANTIOQUIA",
    "TOLU VIEJO": "SAN JOSE DE TOLUVIEJO",
    "CALI": "SANTIAGO DE CALI",
    "PURISIMA": "PURISIMA DE LA CONCEPCION",
    "PIENDAMO": "PIENDAMO - TUNIA",
    "SOTARA": "SOTARA - PAISPAMBA",
    "CUASPUD": "CUASPUD CARLOSAMA",
    "CERRO SAN ANTONIO": "CERRO DE SAN ANTONIO",
    "CHIBOLO": "CHIVOLO",
    "MARIQUITA": "SAN SEBASTIAN DE MARIQUITA",
}
merged_final['MUNICIPIO'] = merged_final['MUNICIPIO'].replace(reemplazos_mpios)
pob_2019['MUNICIPIO'] = pob_2019['MUNICIPIO'].replace(reemplazos_mpios)


# --- 4. Reemplazos y correcciones en departamentos ---
reemplazos_dptos = {
    "GUAJIRA": "LA GUAJIRA",
    "VALLE": "VALLE DEL CAUCA",
    "SAN ANDRES": "ARCHIPIELAGO DE SAN ANDRES, PROVIDENCIA Y SANTA CATALINA",
    "BOGOTA": "CUNDINAMARCA",
}
merged_final['DEPARTAMENTO'] = merged_final['DEPARTAMENTO'].replace(reemplazos_dptos)
pob_2019['DEPARTAMENTO'] = pob_2019['DEPARTAMENTO'].replace(reemplazos_dptos)


# --- 5. Correcci√≥n especial de Bogot√° ---
mask_bogota = merged_final['MUNICIPIO'].str.contains('BOGOTA', case=False, na=False)
merged_final.loc[mask_bogota, 'DEPARTAMENTO'] = 'CUNDINAMARCA'
merged_final.loc[mask_bogota, 'MUNICIPIO'] = 'BOGOT√Å, D.C.'

mask_bogota_pob = pob_2019['MUNICIPIO'].str.contains('BOGOTA', case=False, na=False)
pob_2019.loc[mask_bogota_pob, 'DEPARTAMENTO'] = 'CUNDINAMARCA'
pob_2019.loc[mask_bogota_pob, 'MUNICIPIO'] = 'BOGOT√Å, D.C.'


# --- 6. Correcciones espec√≠ficas para empalmar con poblaci√≥n ---
pob_2019['MUNICIPIO'] = pob_2019['MUNICIPIO'].replace({
    'MOMPOS': 'SANTA CRUZ DE MOMPOX',
    'SOTARA PAISPAMBA': 'SOTARA - PAISPAMBA'
})


# --- 7. Asegurar a√±o como entero ---
merged_final['A√ëO'] = merged_final['A√ëO'].astype(int)
pob_2019['A√ëO'] = pob_2019['A√ëO'].astype(int)


# --- 8. Merge final por departamento, municipio y a√±o ---
df_final_pob = merged_final.merge(
    pob_2019,
    on=['DEPARTAMENTO', 'MUNICIPIO', 'A√ëO'],
    how='left',
    indicator='_merge_pob'
)


# --- 9. Verificar coincidencias faltantes ---
sin_pob = (
    df_final_pob[df_final_pob['_merge_pob'] == 'left_only']
    [['DEPARTAMENTO', 'MUNICIPIO']]
    .drop_duplicates()
    .sort_values(['DEPARTAMENTO', 'MUNICIPIO'])
)
print(f"‚ö†Ô∏è Municipios sin coincidencia de poblaci√≥n: {len(sin_pob)}")
display(sin_pob)


# --- 10. Limpieza final ---
df_final_pob = df_final_pob.drop(columns=['_merge_pob'])

print(f"\n‚úÖ Base final combinada con poblaci√≥n: {df_final_pob.shape[0]:,} filas √ó {df_final_pob.shape[1]} columnas")
display(df_final_pob.head(10))


# --- 11. Exportar resultado ---
df_final_pob.to_excel("delitos_con_poblacion_final2019.xlsx", index=False)
print("üìÅ Archivo exportado: delitos_con_poblacion_final2019.xlsx")

for col in df_final_pob.columns:
    print(f"\n=== {col} ===")
    print(df_final_pob[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {df_final_pob[col].nunique()}")

"""2020"""

def cargar_delito(url, delito):
    # Por defecto fila 10
    posibles_headers = [10, 9]

    for header_row in posibles_headers:
        try:
            df = pd.read_excel(url, header=header_row).copy()
            # Normalizar nombres
            df.columns = df.columns.str.strip().str.upper().str.replace(" ", "_")

            # Diccionario para unificar columnas
            renombrar = {
                "ARMAS_MEDIOS": "ARMAS_MEDIOS",
                "ARMA_MEDIO": "ARMAS_MEDIOS",
                "ARMAS/MEDIOS": "ARMAS_MEDIOS",
                "ARMAS_Y_MEDIOS": "ARMAS_MEDIOS",
                "CODIGO_DANE": "CODIGO_DANE",
                "FECHA_HECHO": "FECHA_HECHO",
                "GENERO": "GENERO",
                "CANTIDAD": "CANTIDAD",
                "AGRUPA_EDAD_PERSONA": "AGRUPA_EDAD_PERSONA",
                "*AGRUPA_EDAD_PERSONA": "AGRUPA_EDAD_PERSONA",
                "*AGRUPA_EDAD_PERSONA*": "AGRUPA_EDAD_PERSONA"
            }
            df = df.rename(columns=lambda x: renombrar.get(x, x))

            # Seleccionar solo columnas clave
            columnas_validas = [
                "DEPARTAMENTO", "MUNICIPIO", "CODIGO_DANE",
                "ARMAS_MEDIOS", "FECHA_HECHO", "GENERO",
                "AGRUPA_EDAD_PERSONA", "CANTIDAD"
            ]
            df = df[[col for col in columnas_validas if col in df.columns]]

            # Eliminar filas completamente vac√≠as
            df = df.dropna(how="all")

            # Eliminar basura
            basura_regex = "TOTAL|FUENTE|Elaborado|Revisado|Autorizado|Ley 1098|Agrupaci√≥n referente|Contador"
            for col in ["DEPARTAMENTO", "ARMAS_MEDIOS"]:
                if col in df.columns:
                    df = df[~df[col].astype(str).str.contains(basura_regex, na=False, case=False)]

            if not df.empty:
                # CODIGO_DANE num√©rico
                if "CODIGO_DANE" in df.columns:
                    df["CODIGO_DANE"] = pd.to_numeric(df["CODIGO_DANE"], errors="coerce")

                df["TIPO_DELITO"] = delito
                print(f"üìå {delito}: encabezado fijo en fila {header_row}")
                return df
        except Exception as e:
            continue

    print(f"‚ö†Ô∏è {delito}: no se pudo leer con header 9 o 10")
    return pd.DataFrame()


# Diccionario de URLs y delitos 2020
urls_2020 = [
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/abigeato_2020.xls", "HURTO CABEZAS GANADO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/amenazas_2020.xlsx", "AMENAZAS"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/delitos_sexuales_2020.xls", "DELITOS SEXUALES"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/extorsion_2020_1.xls", "EXTORSI√ìN"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/Homicidio%20Intencional%202020.xlsx", "HOMICIDIO INTENCIONAL"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/homicidios_accidente_de_transito_2020_2.xls", "HOMICIDIOS EN ACCIDENTE DE TR√ÅNSITO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto_personas_2020_0.xlsx", "HURTO A PERSONAS"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto_residencias_2020.xls", "HURTO A RESIDENCIAS"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto_automotores_2020_1.xls", "HURTO AUTOMOTORES"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto_a_motocicletas_2020.xls", "HURTO MOTOCICLETAS"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto_a_comercio_2020.xls", "HURTO A COMERCIO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto_entidades_financieras_2020.xls", "HURTO A ENTIDADES FINANCIERAS"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/lesiones_en_accidente_de_transito_2020_1.xls", "LESIONES EN ACCIDENTE DE TR√ÅNSITO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/lesiones_personales_2020.xlsx", "LESIONES PERSONALES"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/pirateria_terrestre_2020_1.xls", "PIRATER√çA TERRESTRE"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/secuestro_2020.xls", "SECUESTRO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/terrorismo_2020_1.xls", "TERRORISMO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/violencia_intrafamiliar_2020.xls_0.xlsx", "VIOLENCIA INTRAFAMILIAR"),
]

# Procesar todos los archivos
dfs_2020 = []
for url, delito in urls_2020:
    df = cargar_delito(url, delito)
    if not df.empty:
        dfs_2020.append(df)
        print(f"‚úÖ {delito}: {df.shape[0]} filas")

# Concatenar todo en un solo DataFrame
df_2020 = pd.concat(dfs_2020, ignore_index=True)

# Ordenar por MUNICIPIO (y opcionalmente tambi√©n por DEPARTAMENTO)
df_2020 = df_2020.sort_values(by=["MUNICIPIO", "DEPARTAMENTO"]).reset_index(drop=True)

print(f"\nTotal final 2020: {df_2020.shape[0]} filas y {df_2020.shape[1]} columnas")
display(df_2020.head())

# === 14. Valores √∫nicos por columna en df_2018 ===
for col in df_2020.columns:
    print(f"\n=== {col} ===")
    print(df_2020[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {df_2020[col].nunique()}")

# Commented out IPython magic to ensure Python compatibility.
# %pip install unidecode

import pandas as pd
import numpy as np
import unidecode
import re

# --- Estandarizar DEPARTAMENTO ---
df_2020['DEPARTAMENTO'] = df_2020['DEPARTAMENTO'].astype(str).str.strip().str.upper()
df_2020['DEPARTAMENTO'] = df_2020['DEPARTAMENTO'].apply(lambda x: unidecode.unidecode(x))

# --- Estandarizar MUNICIPIO ---
def limpiar_municipio(nombre):
    if pd.isna(nombre):
        return nombre
    nombre = str(nombre).upper().strip()
    nombre = re.sub(r'\(CT\)', '', nombre)  # eliminar (CT)
    nombre = unidecode.unidecode(nombre)     # quitar tildes
    return nombre

df_2020['MUNICIPIO'] = df_2020['MUNICIPIO'].apply(limpiar_municipio)

# Reemplazar 'NAN' como string por NaN
df_2020['MUNICIPIO'] = df_2020['MUNICIPIO'].replace('NAN', np.nan)

# Opcional: eliminar filas donde MUNICIPIO sea NaN
df_2020 = df_2020.dropna(subset=['MUNICIPIO'])

# --- Arreglar FECHA_HECHO ---
def convertir_fecha(valor):
    if isinstance(valor, (float, int)):
        valor_str = str(int(valor))
        return pd.to_datetime(valor_str, format='%Y%m%d', errors='coerce')
    else:
        return pd.to_datetime(valor, errors='coerce')

df_2020['FECHA_HECHO'] = df_2020['FECHA_HECHO'].apply(convertir_fecha)

# --- Resumen de nulos ---
resumen_nulos = pd.DataFrame({
    'Columna': df_2020.columns,
    'Nulos': df_2020.isnull().sum(),
    'Porcentaje_nulos': df_2020.isnull().mean() * 100
})

print(resumen_nulos)

for col in df_2020.columns:
    print(f"\n=== {col} ===")
    print(df_2020[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {df_2020[col].nunique()}")

df_2020.isna().sum()

df_2020['MUNICIPIO'].value_counts(dropna=False).head(10)

print(df_2020['MUNICIPIO'].dtype)   # tipo de dato real
print(df_2020['MUNICIPIO'].isna().sum())  # conteo de nulos
print(df_2020['MUNICIPIO'].head(20))      # primeros valores

df_2020[df_2020['MUNICIPIO'].isna()]

# Ordenar alfab√©ticamente por MUNICIPIO
df_2020 = df_2020.sort_values(by=["MUNICIPIO"], ascending=True).reset_index(drop=True)

print(f"\n Total ordenado: {df_2020.shape[0]} filas y {df_2020.shape[1]} columnas")
display(df_2020.head(20))  # muestra los primeros 20 municipios ordenados

import pandas as pd
import numpy as np

# Crear tabla resumen de nulos
resumen_nulos = pd.DataFrame({
    'Columna': df_2020.columns,
    'Nulos': df_2020.isnull().sum(),
    'NaN explicitos': df_2020.apply(lambda x: x.isna().sum())
})

# Ordenar opcionalmente de mayor a menor nulos
resumen_nulos = resumen_nulos.sort_values(by='Nulos', ascending=False).reset_index(drop=True)

print(resumen_nulos)

import numpy as np

# Reemplazar 'NAN' como string por valores NaN
df_2020['MUNICIPIO'] = df_2020['MUNICIPIO'].replace('NAN', np.nan)

# Ahora contamos nulos y NaN
resumen_nulos = pd.DataFrame({
    'Columna': df_2020.columns,
    'Nulos': df_2020.isnull().sum(),
    'Porcentaje_nulos': df_2020.isnull().mean() * 100
})

print(resumen_nulos)

import numpy as np

# Asegurarnos de que los 'NAN' como texto sean NaN reales
df_2020['MUNICIPIO'].replace('NAN', np.nan, inplace=True)

# Eliminar filas donde MUNICIPIO sea NaN
df_2020 = df_2020.dropna(subset=['MUNICIPIO'])

# Revisar
print(df_2020['MUNICIPIO'].isnull().sum())  # deber√≠a dar 0

import numpy as np

# Reemplazar 'NAN' como string por valores NaN
df_2020['MUNICIPIO'] = df_2020['MUNICIPIO'].replace('NAN', np.nan)

# Ahora contamos nulos y NaN
resumen_nulos = pd.DataFrame({
    'Columna': df_2020.columns,
    'Nulos': df_2020.isnull().sum(),
    'Porcentaje_nulos': df_2020.isnull().mean() * 100
})

print(resumen_nulos)

for col in df_2020.columns:
    print(f"\n=== {col} ===")
    print(df_2020[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {df_2020[col].nunique()}")

"""Poblacion Y DAVIPOLA"""

import pandas as pd
import requests
import numpy as np

# --------------------------
# URLs de insumos externos
# --------------------------
url_poblacion = "https://www.dane.gov.co/files/censo2018/proyecciones-de-poblacion/Municipal/PPED-AreaSexoEdadMun-2018-2042_VP.xlsx"
api_url_divipola = "https://www.datos.gov.co/resource/gdxc-w37w.json?$limit=2000"

# Cargar DIVIPOLA desde la API de datos abiertos
divipola = pd.read_json(api_url_divipola)

# Mostrar las columnas originales
print("üßê Columnas originales en DIVIPOLA:")
print(divipola.columns.tolist())

# (Opcional) ver las primeras filas
display(divipola.head())

df_2020['MUNICIPIO'] = (
    df_2020['MUNICIPIO']
    .astype(str)
    .str.strip()
    .str.upper()
    .apply(lambda x: unidecode.unidecode(x))
)

df_2020['DEPARTAMENTO'] = (
    df_2020['DEPARTAMENTO']
    .astype(str)
    .str.strip()
    .str.upper()
    .apply(lambda x: unidecode.unidecode(x))
)

# =========================================================
# üîó MERGE FINAL: Base de delitos + DIVIPOLA (A√±o 2020)
# =========================================================

# --- 1. Importar librer√≠as ---
import pandas as pd
import unidecode

# --- 2. Normalizaci√≥n de texto ---
def normalizar(texto):
    """Convierte a may√∫sculas, elimina tildes, espacios extra y caracteres no est√°ndar"""
    if pd.isna(texto):
        return ''
    texto = str(texto).strip().upper()
    texto = unidecode.unidecode(texto)
    texto = ' '.join(texto.split())  # elimina dobles espacios
    return texto

# --- 3. Estandarizar nombres en ambas bases ---
df_2020['DEPARTAMENTO'] = df_2020['DEPARTAMENTO'].apply(normalizar)
df_2020['MUNICIPIO'] = df_2020['MUNICIPIO'].apply(normalizar)
divipola['dpto'] = divipola['dpto'].apply(normalizar)
divipola['nom_mpio'] = divipola['nom_mpio'].apply(normalizar)

# --- 4. Eliminar registros sin informaci√≥n ---
df_2020 = df_2020[~df_2020['MUNICIPIO'].isin(['NO REGISTRA'])]
df_2020 = df_2020[~df_2020['DEPARTAMENTO'].isin(['NO REGISTRA'])]

# --- 5. Estandarizar valores en variables categ√≥ricas ---
# Genero
df_2020['GENERO'] = df_2020['GENERO'].replace({
    'NO REPORTA': 'NO REPORTADO',
    'NO REPORTADO ': 'NO REPORTADO',
    '-': 'NO REPORTADO'
})
# Agrupaci√≥n de edad
df_2020['AGRUPA_EDAD_PERSONA'] = df_2020['AGRUPA_EDAD_PERSONA'].replace({
    'NO REPORTA': 'NO REPORTADO',
    'NO REPORTADO ': 'NO REPORTADO',
    ' ': 'NO REPORTADO'
})

# --- 6. Reemplazos de departamentos ---
reemplazos_dptos = {
    "GUAJIRA": "LA GUAJIRA",
    "VALLE": "VALLE DEL CAUCA",
    "SAN ANDRES": "ARCHIPIELAGO DE SAN ANDRES, PROVIDENCIA Y SANTA CATALINA",
    "BOGOTA": "CUNDINAMARCA",  # Bogot√° se trata como municipio de Cundinamarca
}
df_2020['DEPARTAMENTO'] = df_2020['DEPARTAMENTO'].replace(reemplazos_dptos)
divipola['dpto'] = divipola['dpto'].replace({"BOGOTA, D.C.": "CUNDINAMARCA"})

# --- 7. Correcciones finales de municipios problem√°ticos ---
reemplazos_mpios_final = {
    "CARTAGENA": "CARTAGENA DE INDIAS",
    "CUCUTA": "SAN JOSE DE CUCUTA",
    "DON MATIAS": "DONMATIAS",
    "GUICAN": "GUICAN DE LA SIERRA",
    "LOPEZ": "LOPEZ DE MICAY",
    "MANAURE": "MANAURE BALCON DEL CESAR",
    "MOMPOS": "SANTA CRUZ DE MOMPOX",
    "SAN ANDRES DE TUMACO": "SAN ANDRES DE TUMACO",
    "SAN ANDRES SOTAVENTO": "SAN ANDRES DE SOTAVENTO",
    "SAN JUAN DE RIO SECO": "SAN JUAN DE RIOSECO",
    "SAN PEDRO": "SAN PEDRO DE LOS MILAGROS",
    "SAN VICENTE": "SAN VICENTE FERRER",
    "SANTAFE DE ANTIOQUIA": "SANTA FE DE ANTIOQUIA",
    "TOLU VIEJO": "SAN JOSE DE TOLUVIEJO",
    "CALI": "SANTIAGO DE CALI",
    "PURISIMA": "PURISIMA DE LA CONCEPCION",
    "PIENDAMO": "PIENDAMO - TUNIA",
    "SOTARA": "SOTARA - PAISPAMBA",
    "CUASPUD": "CUASPUD CARLOSAMA"
}
df_2020['MUNICIPIO'] = df_2020['MUNICIPIO'].replace(reemplazos_mpios_final)

# --- 8. Correcci√≥n de departamentos espec√≠ficos ---
df_2020.loc[df_2020['MUNICIPIO'] == "MANAURE BALCON DEL CESAR", 'DEPARTAMENTO'] = "CESAR"
df_2020.loc[df_2020['MUNICIPIO'] == "SAN ANDRES DE TUMACO", 'DEPARTAMENTO'] = "NARINO"
df_2020.loc[df_2020['MUNICIPIO'] == "SAN ANDRES", 'DEPARTAMENTO'] = "ARCHIPIELAGO DE SAN ANDRES, PROVIDENCIA Y SANTA CATALINA"

# --- 9. Ajuste especial de Bogot√° ---
mask_bogota = df_2020['MUNICIPIO'].str.contains('BOGOTA', case=False, na=False)
df_2020.loc[mask_bogota, 'DEPARTAMENTO'] = 'CUNDINAMARCA'
df_2020.loc[mask_bogota, 'MUNICIPIO'] = 'BOGOTA, D.C.'

divipola.loc[
    divipola['nom_mpio'].str.contains('BOGOTA', case=False, na=False),
    ['dpto', 'nom_mpio']
] = ['CUNDINAMARCA', 'BOGOTA, D.C.']

# --- 10. Correcciones finales (√∫ltimos 5 municipios) ---
reemplazos_finales_extra = {
    "CERRO SAN ANTONIO": "CERRO DE SAN ANTONIO",
    "CHIBOLO": "CHIVOLO",
    "MARIQUITA": "SAN SEBASTIAN DE MARIQUITA",
}
df_2020['MUNICIPIO'] = df_2020['MUNICIPIO'].replace(reemplazos_finales_extra)

# --- 11. Corregir departamentos err√≥neos ---
df_2020.loc[df_2020['MUNICIPIO'] == "SAN PEDRO DE LOS MILAGROS", 'DEPARTAMENTO'] = "ANTIOQUIA"

# --- 12. Agregar a√±o ---
df_2020['A√ëO'] = 2020

# --- 13. Merge final con DIVIPOLA ---
merged_final = df_2020.merge(
    divipola,
    left_on=['DEPARTAMENTO', 'MUNICIPIO'],
    right_on=['dpto', 'nom_mpio'],
    how='left',
    indicator=True
)

# --- 14. Verificar sin coincidencias ---
sin_match_final = (
    merged_final[merged_final['_merge'] == 'left_only'][['DEPARTAMENTO', 'MUNICIPIO']]
    .drop_duplicates()
    .sort_values(['DEPARTAMENTO', 'MUNICIPIO'])
)
print(f"‚úÖ Municipios sin coincidencia tras correcci√≥n final: {len(sin_match_final)}")
display(sin_match_final)

# --- 15. Resultado final ---
print(f"\n‚úÖ Base unida correctamente: {merged_final.shape[0]:,} filas √ó {merged_final.shape[1]} columnas")

for col in merged_final.columns:
    print(f"\n=== {col} ===")
    print(merged_final[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {merged_final[col].nunique()}")

# Comparar los departamentos de ambos DataFrames
set_df = set(df_2020['DEPARTAMENTO'].unique())
set_divi = set(divipola['dpto'].unique())

faltante_en_df2020 = set_divi - set_df
faltante_en_divipola = set_df - set_divi

print("üß© Departamento(s) que est√°n en DIVIPOLA pero no en df_2020:")
print(faltante_en_df2020)

print("\nüîπ Departamento(s) que est√°n en df_2020 pero no en DIVIPOLA:")
print(faltante_en_divipola)

# ========================================
# 2. CARGAR Y PROCESAR POBLACI√ìN
# ========================================

import pandas as pd
import unidecode

print("\nüì• Descargando datos de poblaci√≥n...")

# Leer archivo Excel del DANE
pob = pd.read_excel(
    url_poblacion,
    sheet_name='PobMunicipalx√ÅreaSexoEdad',
    header=7
)

# --- Normalizar nombres de columnas ---
pob.columns = (
    pob.columns.str.upper()
    .str.strip()
    .str.replace(' ', '_')
    .str.replace('√Å', 'A')
    .str.replace('.', '', regex=False)
)

# --- Verificaci√≥n de nombres existentes ---
print(f"Columnas detectadas: {list(pob.columns)}")

# --- Seleccionar solo columnas que existan ---
columnas_requeridas = ['DP', 'DPNOM', 'MPIO', 'MPNOM', 'DPMP', 'A√ëO', 'AREA_GEOGRAFICA', 'TOTAL']
cols_existentes = [col for col in columnas_requeridas if col in pob.columns]
pob = pob[cols_existentes].copy()

print(f"\nColumnas seleccionadas para procesamiento: {pob.columns.tolist()}")

# --- Si no existe MPNOM, intentar usar el nombre alternativo (MPIO) ---
if 'MPNOM' not in pob.columns and 'MPIO' in pob.columns:
    pob = pob.rename(columns={'MPIO': 'MPNOM'})

# --- Normalizar texto de nombres ---
def normalizar(texto):
    if pd.isna(texto):
        return ''
    texto = str(texto).strip().upper()
    texto = unidecode.unidecode(texto)
    texto = ' '.join(texto.split())
    return texto

pob['DPNOM'] = pob['DPNOM'].apply(normalizar)
pob['MPNOM'] = pob['MPNOM'].apply(normalizar)

# --- Filtrar solo filas donde el √°rea geogr√°fica sea TOTAL o TOTALES ---
if 'AREA_GEOGRAFICA' in pob.columns:
    pob = pob[pob['AREA_GEOGRAFICA'].str.contains('TOTAL', case=False, na=False)]

# --- Renombrar columnas para merge posterior ---
pob = pob.rename(columns={
    'DPNOM': 'DEPARTAMENTO',
    'MPNOM': 'CODIGO_DANE_POB	',
    'DPMP': 'MUNICIPIO',
    'TOTAL': 'POBLACION_TOTAL'
})

# --- Filtrar solo a√±o 2018 ---
pob_2020 = pob[pob['A√ëO'] == 2020].copy()

# --- Eliminar duplicados ---
pob_2020 = pob_2020.drop_duplicates(subset=['DEPARTAMENTO', 'MUNICIPIO'])

print(f"‚úÖ Registros de poblaci√≥n 2020 (√°rea TOTAL) procesados: {len(pob_2020):,}")

# --- Vista previa ---
display(pob_2020.head(10))

for col in pob_2020.columns:
    print(f"\n=== {col} ===")
    print(pob_2020[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {pob_2020[col].nunique()}")

# ====================================================
# üî† PASAR TODA LA BASE pob_2018 A MAY√öSCULAS Y NORMALIZAR
# ====================================================

import unidecode
import pandas as pd

def normalizar_texto(valor):
    """Convierte todo texto a may√∫sculas, quita tildes y espacios dobles."""
    if isinstance(valor, str):
        valor = unidecode.unidecode(valor)  # quita tildes
        valor = valor.upper().strip()
        valor = ' '.join(valor.split())      # elimina espacios dobles
    return valor

# Aplicar a todas las columnas de tipo texto
for col in pob_2020.columns:
    if pob_2020[col].dtype == 'object':
        pob_2020[col] = pob_2020[col].apply(normalizar_texto)

print("‚úÖ Toda la base de poblaci√≥n est√° ahora en MAY√öSCULAS y sin tildes.")
display(pob_2020.head(10))

municipios_pob = sorted(pob_2020['MUNICIPIO'].dropna().unique())
print(f"Total de municipios en pob_2020: {len(municipios_pob)}\n")
print(municipios_pob)

# =========================================================
# üîó MERGE FINAL: Base de delitos + DIVIPOLA + POBLACI√ìN
# Compatible con cualquier a√±o (ej. 2018, 2019, etc.)
# =========================================================

import pandas as pd
import unidecode

# --- 1. Funci√≥n de normalizaci√≥n ---
def normalizar(texto):
    """Convierte a may√∫sculas, elimina tildes y espacios extra."""
    if pd.isna(texto):
        return ''
    texto = str(texto).strip().upper()
    texto = unidecode.unidecode(texto)
    texto = ' '.join(texto.split())  # quita espacios dobles
    return texto


# --- 2. Normalizar texto en todas las bases ---
for col in ['DEPARTAMENTO', 'MUNICIPIO']:
    merged_final[col] = merged_final[col].astype(str).apply(normalizar)
    pob_2020[col] = pob_2020[col].astype(str).apply(normalizar)


# --- 3. Reemplazos y correcciones en municipios ---
reemplazos_mpios = {
    "CARTAGENA": "CARTAGENA DE INDIAS",
    "CUCUTA": "SAN JOSE DE CUCUTA",
    "DON MATIAS": "DONMATIAS",
    "GUICAN": "GUICAN DE LA SIERRA",
    "LOPEZ": "LOPEZ DE MICAY",
    "MANAURE": "MANAURE BALCON DEL CESAR",
    "SAN ANDRES DE TUMACO": "SAN ANDRES DE TUMACO",
    "SAN ANDRES SOTAVENTO": "SAN ANDRES DE SOTAVENTO",
    "SAN JUAN DE RIO SECO": "SAN JUAN DE RIOSECO",
    "SAN PEDRO": "SAN PEDRO DE LOS MILAGROS",
    "SAN VICENTE": "SAN VICENTE FERRER",
    "SANTAFE DE ANTIOQUIA": "SANTA FE DE ANTIOQUIA",
    "TOLU VIEJO": "SAN JOSE DE TOLUVIEJO",
    "CALI": "SANTIAGO DE CALI",
    "PURISIMA": "PURISIMA DE LA CONCEPCION",
    "PIENDAMO": "PIENDAMO - TUNIA",
    "SOTARA": "SOTARA - PAISPAMBA",
    "CUASPUD": "CUASPUD CARLOSAMA",
    "CERRO SAN ANTONIO": "CERRO DE SAN ANTONIO",
    "CHIBOLO": "CHIVOLO",
    "MARIQUITA": "SAN SEBASTIAN DE MARIQUITA",
}
merged_final['MUNICIPIO'] = merged_final['MUNICIPIO'].replace(reemplazos_mpios)
pob_2020['MUNICIPIO'] = pob_2020['MUNICIPIO'].replace(reemplazos_mpios)


# --- 4. Reemplazos y correcciones en departamentos ---
reemplazos_dptos = {
    "GUAJIRA": "LA GUAJIRA",
    "VALLE": "VALLE DEL CAUCA",
    "SAN ANDRES": "ARCHIPIELAGO DE SAN ANDRES, PROVIDENCIA Y SANTA CATALINA",
    "BOGOTA": "CUNDINAMARCA",
}
merged_final['DEPARTAMENTO'] = merged_final['DEPARTAMENTO'].replace(reemplazos_dptos)
pob_2020['DEPARTAMENTO'] = pob_2020['DEPARTAMENTO'].replace(reemplazos_dptos)


# --- 5. Correcci√≥n especial de Bogot√° ---
mask_bogota = merged_final['MUNICIPIO'].str.contains('BOGOTA', case=False, na=False)
merged_final.loc[mask_bogota, 'DEPARTAMENTO'] = 'CUNDINAMARCA'
merged_final.loc[mask_bogota, 'MUNICIPIO'] = 'BOGOT√Å, D.C.'

mask_bogota_pob = pob_2020['MUNICIPIO'].str.contains('BOGOTA', case=False, na=False)
pob_2020.loc[mask_bogota_pob, 'DEPARTAMENTO'] = 'CUNDINAMARCA'
pob_2020.loc[mask_bogota_pob, 'MUNICIPIO'] = 'BOGOT√Å, D.C.'


# --- 6. Asegurar a√±o como entero ---
merged_final['A√ëO'] = 2020 # Add the year 2020 to merged_final
merged_final['A√ëO'] = merged_final['A√ëO'].astype(int)
pob_2020['A√ëO'] = pob_2020['A√ëO'].astype(int)


# --- 7. Merge final por departamento, municipio y a√±o ---
df_final_pob = merged_final.merge(
    pob_2020,
    on=['DEPARTAMENTO', 'MUNICIPIO', 'A√ëO'],
    how='left',
    indicator='_merge_pob'
)


# --- 8. Verificar coincidencias faltantes ---
sin_pob = (
    df_final_pob[df_final_pob['_merge_pob'] == 'left_only']
    [['DEPARTAMENTO', 'MUNICIPIO']]
    .drop_duplicates()
    .sort_values(['DEPARTAMENTO', 'MUNICIPIO'])
)
print(f"‚ö†Ô∏è Municipios sin coincidencia de poblaci√≥n: {len(sin_pob)}")
display(sin_pob)


# --- 9. Limpieza final ---
df_final_pob = df_final_pob.drop(columns=['_merge_pob'])

print(f"\n‚úÖ Base final combinada con poblaci√≥n: {df_final_pob.shape[0]:,} filas √ó {df_final_pob.shape[1]} columnas")
display(df_final_pob.head(10))


# --- 10. Exportar resultado ---
df_final_pob.to_excel("delitos_con_poblacion_final2020.xlsx", index=False)
print("üìÅ Archivo exportado: delitos_con_poblacion_final2020.xlsx")

for col in df_final_pob.columns:
    print(f"\n=== {col} ===")
    print(df_final_pob[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {df_final_pob[col].nunique()}")

for col in df_2020.columns:
    print(f"\n=== {col} ===")
    print(df_2020[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {df_2020[col].nunique()}")

df_2020.isna().sum()

df_2020['MUNICIPIO'].value_counts(dropna=False).head(10)

print(df_2020['MUNICIPIO'].dtype)   # tipo de dato real
print(df_2020['MUNICIPIO'].isna().sum())  # conteo de nulos
print(df_2020['MUNICIPIO'].head(20))      # primeros valores

df_2020[df_2020['MUNICIPIO'].isna()]

# Ordenar alfab√©ticamente por MUNICIPIO
df_2020 = df_2020.sort_values(by=["MUNICIPIO"], ascending=True).reset_index(drop=True)

print(f"\n Total ordenado: {df_2020.shape[0]} filas y {df_2020.shape[1]} columnas")
display(df_2020.head(20))  # muestra los primeros 20 municipios ordenados

import pandas as pd
import numpy as np

# Crear tabla resumen de nulos
resumen_nulos = pd.DataFrame({
    'Columna': df_2020.columns,
    'Nulos': df_2020.isnull().sum(),
    'NaN explicitos': df_2020.apply(lambda x: x.isna().sum())
})

# Ordenar opcionalmente de mayor a menor nulos
resumen_nulos = resumen_nulos.sort_values(by='Nulos', ascending=False).reset_index(drop=True)

print(resumen_nulos)

import numpy as np

# Reemplazar 'NAN' como string por valores NaN
df_2020['MUNICIPIO'] = df_2020['MUNICIPIO'].replace('NAN', np.nan)

# Ahora contamos nulos y NaN
resumen_nulos = pd.DataFrame({
    'Columna': df_2020.columns,
    'Nulos': df_2020.isnull().sum(),
    'Porcentaje_nulos': df_2020.isnull().mean() * 100
})

print(resumen_nulos)

import numpy as np

# Asegurarnos de que los 'NAN' como texto sean NaN reales
df_2020['MUNICIPIO'].replace('NAN', np.nan, inplace=True)

# Eliminar filas donde MUNICIPIO sea NaN
df_2020 = df_2020.dropna(subset=['MUNICIPIO'])

# Revisar
print(df_2020['MUNICIPIO'].isnull().sum())  # deber√≠a dar 0

import numpy as np

# Reemplazar 'NAN' como string por valores NaN
df_2020['MUNICIPIO'] = df_2020['MUNICIPIO'].replace('NAN', np.nan)

# Ahora contamos nulos y NaN
resumen_nulos = pd.DataFrame({
    'Columna': df_2020.columns,
    'Nulos': df_2020.isnull().sum(),
    'Porcentaje_nulos': df_2020.isnull().mean() * 100
})

print(resumen_nulos)

for col in df_2020.columns:
    print(f"\n=== {col} ===")
    print(df_2020[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {df_2020[col].nunique()}")

"""Poblacion Y DAVIPOLA"""

import pandas as pd
import requests
import numpy as np

# --------------------------
# URLs de insumos externos
# --------------------------
url_poblacion = "https://www.dane.gov.co/files/censo2018/proyecciones-de-poblacion/Municipal/PPED-AreaSexoEdadMun-2018-2042_VP.xlsx"
api_url_divipola = "https://www.datos.gov.co/resource/gdxc-w37w.json?$limit=2000"

# Cargar DIVIPOLA desde la API de datos abiertos
divipola = pd.read_json(api_url_divipola)

# Mostrar las columnas originales
print("üßê Columnas originales en DIVIPOLA:")
print(divipola.columns.tolist())

# (Opcional) ver las primeras filas
display(divipola.head())

df_2020['MUNICIPIO'] = (
    df_2020['MUNICIPIO']
    .astype(str)
    .str.strip()
    .str.upper()
    .apply(lambda x: unidecode.unidecode(x))
)

df_2020['DEPARTAMENTO'] = (
    df_2020['DEPARTAMENTO']
    .astype(str)
    .str.strip()
    .str.upper()
    .apply(lambda x: unidecode.unidecode(x))
)

# =========================================================
# üîó MERGE FINAL: Base de delitos + DIVIPOLA (A√±o 2020)
# =========================================================

# --- 1. Importar librer√≠as ---
import pandas as pd
import unidecode

# --- 2. Normalizaci√≥n de texto ---
def normalizar(texto):
    """Convierte a may√∫sculas, elimina tildes, espacios extra y caracteres no est√°ndar"""
    if pd.isna(texto):
        return ''
    texto = str(texto).strip().upper()
    texto = unidecode.unidecode(texto)
    texto = ' '.join(texto.split())  # elimina dobles espacios
    return texto

# --- 3. Estandarizar nombres en ambas bases ---
df_2020['DEPARTAMENTO'] = df_2020['DEPARTAMENTO'].apply(normalizar)
df_2020['MUNICIPIO'] = df_2020['MUNICIPIO'].apply(normalizar)
divipola['dpto'] = divipola['dpto'].apply(normalizar)
divipola['nom_mpio'] = divipola['nom_mpio'].apply(normalizar)

# --- 4. Eliminar registros sin informaci√≥n ---
df_2020 = df_2020[~df_2020['MUNICIPIO'].isin(['NO REGISTRA'])]
df_2020 = df_2020[~df_2020['DEPARTAMENTO'].isin(['NO REGISTRA'])]

# --- 5. Estandarizar valores en variables categ√≥ricas ---
# Genero
df_2020['GENERO'] = df_2020['GENERO'].replace({
    'NO REPORTA': 'NO REPORTADO',
    'NO REPORTADO ': 'NO REPORTADO',
    '-': 'NO REPORTADO'
})
# Agrupaci√≥n de edad
df_2020['AGRUPA_EDAD_PERSONA'] = df_2020['AGRUPA_EDAD_PERSONA'].replace({
    'NO REPORTA': 'NO REPORTADO',
    'NO REPORTADO ': 'NO REPORTADO',
    ' ': 'NO REPORTADO'
})

# --- 6. Reemplazos de departamentos ---
reemplazos_dptos = {
    "GUAJIRA": "LA GUAJIRA",
    "VALLE": "VALLE DEL CAUCA",
    "SAN ANDRES": "ARCHIPIELAGO DE SAN ANDRES, PROVIDENCIA Y SANTA CATALINA",
    "BOGOTA": "CUNDINAMARCA",  # Bogot√° se trata como municipio de Cundinamarca
}
df_2020['DEPARTAMENTO'] = df_2020['DEPARTAMENTO'].replace(reemplazos_dptos)
divipola['dpto'] = divipola['dpto'].replace({"BOGOTA, D.C.": "CUNDINAMARCA"})

# --- 7. Correcciones finales de municipios problem√°ticos ---
reemplazos_mpios_final = {
    "CARTAGENA": "CARTAGENA DE INDIAS",
    "CUCUTA": "SAN JOSE DE CUCUTA",
    "DON MATIAS": "DONMATIAS",
    "GUICAN": "GUICAN DE LA SIERRA",
    "LOPEZ": "LOPEZ DE MICAY",
    "MANAURE": "MANAURE BALCON DEL CESAR",
    "MOMPOS": "SANTA CRUZ DE MOMPOX",
    "SAN ANDRES DE TUMACO": "SAN ANDRES DE TUMACO",
    "SAN ANDRES SOTAVENTO": "SAN ANDRES DE SOTAVENTO",
    "SAN JUAN DE RIO SECO": "SAN JUAN DE RIOSECO",
    "SAN PEDRO": "SAN PEDRO DE LOS MILAGROS",
    "SAN VICENTE": "SAN VICENTE FERRER",
    "SANTAFE DE ANTIOQUIA": "SANTA FE DE ANTIOQUIA",
    "TOLU VIEJO": "SAN JOSE DE TOLUVIEJO",
    "CALI": "SANTIAGO DE CALI",
    "PURISIMA": "PURISIMA DE LA CONCEPCION",
    "PIENDAMO": "PIENDAMO - TUNIA",
    "SOTARA": "SOTARA - PAISPAMBA",
    "CUASPUD": "CUASPUD CARLOSAMA"
}
df_2020['MUNICIPIO'] = df_2020['MUNICIPIO'].replace(reemplazos_mpios_final)

# --- 8. Correcci√≥n de departamentos espec√≠ficos ---
df_2020.loc[df_2020['MUNICIPIO'] == "MANAURE BALCON DEL CESAR", 'DEPARTAMENTO'] = "CESAR"
df_2020.loc[df_2020['MUNICIPIO'] == "SAN ANDRES DE TUMACO", 'DEPARTAMENTO'] = "NARINO"
df_2020.loc[df_2020['MUNICIPIO'] == "SAN ANDRES", 'DEPARTAMENTO'] = "ARCHIPIELAGO DE SAN ANDRES, PROVIDENCIA Y SANTA CATALINA"

# --- 9. Ajuste especial de Bogot√° ---
mask_bogota = df_2020['MUNICIPIO'].str.contains('BOGOTA', case=False, na=False)
df_2020.loc[mask_bogota, 'DEPARTAMENTO'] = 'CUNDINAMARCA'
df_2020.loc[mask_bogota, 'MUNICIPIO'] = 'BOGOTA, D.C.'

divipola.loc[
    divipola['nom_mpio'].str.contains('BOGOTA', case=False, na=False),
    ['dpto', 'nom_mpio']
] = ['CUNDINAMARCA', 'BOGOTA, D.C.']

# --- 10. Correcciones finales (√∫ltimos 5 municipios) ---
reemplazos_finales_extra = {
    "CERRO SAN ANTONIO": "CERRO DE SAN ANTONIO",
    "CHIBOLO": "CHIVOLO",
    "MARIQUITA": "SAN SEBASTIAN DE MARIQUITA",
}
df_2020['MUNICIPIO'] = df_2020['MUNICIPIO'].replace(reemplazos_finales_extra)

# --- 11. Corregir departamentos err√≥neos ---
df_2020.loc[df_2020['MUNICIPIO'] == "SAN PEDRO DE LOS MILAGROS", 'DEPARTAMENTO'] = "ANTIOQUIA"

# --- 12. Agregar a√±o ---
df_2020['A√ëO'] = 2020

# --- 13. Merge final con DIVIPOLA ---
merged_final = df_2020.merge(
    divipola,
    left_on=['DEPARTAMENTO', 'MUNICIPIO'],
    right_on=['dpto', 'nom_mpio'],
    how='left',
    indicator=True
)

# --- 14. Verificar sin coincidencias ---
sin_match_final = (
    merged_final[merged_final['_merge'] == 'left_only'][['DEPARTAMENTO', 'MUNICIPIO']]
    .drop_duplicates()
    .sort_values(['DEPARTAMENTO', 'MUNICIPIO'])
)
print(f"‚úÖ Municipios sin coincidencia tras correcci√≥n final: {len(sin_match_final)}")
display(sin_match_final)

# --- 15. Resultado final ---
print(f"\n‚úÖ Base unida correctamente: {merged_final.shape[0]:,} filas √ó {merged_final.shape[1]} columnas")

for col in merged_final.columns:
    print(f"\n=== {col} ===")
    print(merged_final[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {merged_final[col].nunique()}")

# Comparar los departamentos de ambos DataFrames
set_df = set(df_2020['DEPARTAMENTO'].unique())
set_divi = set(divipola['dpto'].unique())

faltante_en_df2020 = set_divi - set_df
faltante_en_divipola = set_df - set_divi

print("üß© Departamento(s) que est√°n en DIVIPOLA pero no en df_2020:")
print(faltante_en_df2020)

print("\nüîπ Departamento(s) que est√°n en df_2020 pero no en DIVIPOLA:")
print(faltante_en_divipola)

# ========================================
# 2. CARGAR Y PROCESAR POBLACI√ìN
# ========================================

import pandas as pd
import unidecode

print("\nüì• Descargando datos de poblaci√≥n...")

# Leer archivo Excel del DANE
pob = pd.read_excel(
    url_poblacion,
    sheet_name='PobMunicipalx√ÅreaSexoEdad',
    header=7
)

# --- Normalizar nombres de columnas ---
pob.columns = (
    pob.columns.str.upper()
    .str.strip()
    .str.replace(' ', '_')
    .str.replace('√Å', 'A')
    .str.replace('.', '', regex=False)
)

# --- Verificaci√≥n de nombres existentes ---
print(f"Columnas detectadas: {list(pob.columns)}")

# --- Seleccionar solo columnas que existan ---
columnas_requeridas = ['DP', 'DPNOM', 'MPIO', 'MPNOM', 'DPMP', 'A√ëO', 'AREA_GEOGRAFICA', 'TOTAL']
cols_existentes = [col for col in columnas_requeridas if col in pob.columns]
pob = pob[cols_existentes].copy()

print(f"\nColumnas seleccionadas para procesamiento: {pob.columns.tolist()}")

# --- Si no existe MPNOM, intentar usar el nombre alternativo (MPIO) ---
if 'MPNOM' not in pob.columns and 'MPIO' in pob.columns:
    pob = pob.rename(columns={'MPIO': 'MPNOM'})

# --- Normalizar texto de nombres ---
def normalizar(texto):
    if pd.isna(texto):
        return ''
    texto = str(texto).strip().upper()
    texto = unidecode.unidecode(texto)
    texto = ' '.join(texto.split())
    return texto

pob['DPNOM'] = pob['DPNOM'].apply(normalizar)
pob['MPNOM'] = pob['MPNOM'].apply(normalizar)

# --- Filtrar solo filas donde el √°rea geogr√°fica sea TOTAL o TOTALES ---
if 'AREA_GEOGRAFICA' in pob.columns:
    pob = pob[pob['AREA_GEOGRAFICA'].str.contains('TOTAL', case=False, na=False)]

# --- Renombrar columnas para merge posterior ---
pob = pob.rename(columns={
    'DPNOM': 'DEPARTAMENTO',
    'MPNOM': 'CODIGO_DANE_POB	',
    'DPMP': 'MUNICIPIO',
    'TOTAL': 'POBLACION_TOTAL'
})

# --- Filtrar solo a√±o 2018 ---
pob_2020 = pob[pob['A√ëO'] == 2020].copy()

# --- Eliminar duplicados ---
pob_2020 = pob_2020.drop_duplicates(subset=['DEPARTAMENTO', 'MUNICIPIO'])

print(f"‚úÖ Registros de poblaci√≥n 2020 (√°rea TOTAL) procesados: {len(pob_2020):,}")

# --- Vista previa ---
display(pob_2020.head(10))

for col in pob_2020.columns:
    print(f"\n=== {col} ===")
    print(pob_2020[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {pob_2020[col].nunique()}")

# ====================================================
# üî† PASAR TODA LA BASE pob_2018 A MAY√öSCULAS Y NORMALIZAR
# ====================================================

import unidecode
import pandas as pd

def normalizar_texto(valor):
    """Convierte todo texto a may√∫sculas, quita tildes y espacios dobles."""
    if isinstance(valor, str):
        valor = unidecode.unidecode(valor)  # quita tildes
        valor = valor.upper().strip()
        valor = ' '.join(valor.split())      # elimina espacios dobles
    return valor

# Aplicar a todas las columnas de tipo texto
for col in pob_2020.columns:
    if pob_2020[col].dtype == 'object':
        pob_2020[col] = pob_2020[col].apply(normalizar_texto)

print("‚úÖ Toda la base de poblaci√≥n est√° ahora en MAY√öSCULAS y sin tildes.")
display(pob_2020.head(10))

municipios_pob = sorted(pob_2020['MUNICIPIO'].dropna().unique())
print(f"Total de municipios en pob_2020: {len(municipios_pob)}\n")
print(municipios_pob)

# =========================================================
# üîó MERGE FINAL: Base de delitos + DIVIPOLA + POBLACI√ìN
# Compatible con cualquier a√±o (ej. 2018, 2019, etc.)
# =========================================================

import pandas as pd
import unidecode

# --- 1. Funci√≥n de normalizaci√≥n ---
def normalizar(texto):
    """Convierte a may√∫sculas, elimina tildes y espacios extra."""
    if pd.isna(texto):
        return ''
    texto = str(texto).strip().upper()
    texto = unidecode.unidecode(texto)
    texto = ' '.join(texto.split())  # quita espacios dobles
    return texto


# --- 2. Normalizar texto en todas las bases ---
for col in ['DEPARTAMENTO', 'MUNICIPIO']:
    merged_final[col] = merged_final[col].astype(str).apply(normalizar)
    pob_2020[col] = pob_2020[col].astype(str).apply(normalizar)


# --- 3. Reemplazos y correcciones en municipios ---
reemplazos_mpios = {
    "CARTAGENA": "CARTAGENA DE INDIAS",
    "CUCUTA": "SAN JOSE DE CUCUTA",
    "DON MATIAS": "DONMATIAS",
    "GUICAN": "GUICAN DE LA SIERRA",
    "LOPEZ": "LOPEZ DE MICAY",
    "MANAURE": "MANAURE BALCON DEL CESAR",
    "SAN ANDRES DE TUMACO": "SAN ANDRES DE TUMACO",
    "SAN ANDRES SOTAVENTO": "SAN ANDRES DE SOTAVENTO",
    "SAN JUAN DE RIO SECO": "SAN JUAN DE RIOSECO",
    "SAN PEDRO": "SAN PEDRO DE LOS MILAGROS",
    "SAN VICENTE": "SAN VICENTE FERRER",
    "SANTAFE DE ANTIOQUIA": "SANTA FE DE ANTIOQUIA",
    "TOLU VIEJO": "SAN JOSE DE TOLUVIEJO",
    "CALI": "SANTIAGO DE CALI",
    "PURISIMA": "PURISIMA DE LA CONCEPCION",
    "PIENDAMO": "PIENDAMO - TUNIA",
    "SOTARA": "SOTARA - PAISPAMBA",
    "CUASPUD": "CUASPUD CARLOSAMA",
    "CERRO SAN ANTONIO": "CERRO DE SAN ANTONIO",
    "CHIBOLO": "CHIVOLO",
    "MARIQUITA": "SAN SEBASTIAN DE MARIQUITA",
}
merged_final['MUNICIPIO'] = merged_final['MUNICIPIO'].replace(reemplazos_mpios)
pob_2020['MUNICIPIO'] = pob_2020['MUNICIPIO'].replace(reemplazos_mpios)


# --- 4. Reemplazos y correcciones en departamentos ---
reemplazos_dptos = {
    "GUAJIRA": "LA GUAJIRA",
    "VALLE": "VALLE DEL CAUCA",
    "SAN ANDRES": "ARCHIPIELAGO DE SAN ANDRES, PROVIDENCIA Y SANTA CATALINA",
    "BOGOTA": "CUNDINAMARCA",
}
merged_final['DEPARTAMENTO'] = merged_final['DEPARTAMENTO'].replace(reemplazos_dptos)
pob_2020['DEPARTAMENTO'] = pob_2020['DEPARTAMENTO'].replace(reemplazos_dptos)


# --- 5. Correcci√≥n especial de Bogot√° ---
mask_bogota = merged_final['MUNICIPIO'].str.contains('BOGOTA', case=False, na=False)
merged_final.loc[mask_bogota, 'DEPARTAMENTO'] = 'CUNDINAMARCA'
merged_final.loc[mask_bogota, 'MUNICIPIO'] = 'BOGOT√Å, D.C.'

mask_bogota_pob = pob_2020['MUNICIPIO'].str.contains('BOGOTA', case=False, na=False)
pob_2020.loc[mask_bogota_pob, 'DEPARTAMENTO'] = 'CUNDINAMARCA'
pob_2020.loc[mask_bogota_pob, 'MUNICIPIO'] = 'BOGOT√Å, D.C.'


# --- 6. Asegurar a√±o como entero ---
merged_final['A√ëO'] = 2020 # Add the year 2020 to merged_final
merged_final['A√ëO'] = merged_final['A√ëO'].astype(int)
pob_2020['A√ëO'] = pob_2020['A√ëO'].astype(int)


# --- 7. Merge final por departamento, municipio y a√±o ---
df_final_pob = merged_final.merge(
    pob_2020,
    on=['DEPARTAMENTO', 'MUNICIPIO', 'A√ëO'],
    how='left',
    indicator='_merge_pob'
)


# --- 8. Verificar coincidencias faltantes ---
sin_pob = (
    df_final_pob[df_final_pob['_merge_pob'] == 'left_only']
    [['DEPARTAMENTO', 'MUNICIPIO']]
    .drop_duplicates()
    .sort_values(['DEPARTAMENTO', 'MUNICIPIO'])
)
print(f"‚ö†Ô∏è Municipios sin coincidencia de poblaci√≥n: {len(sin_pob)}")
display(sin_pob)


# --- 9. Limpieza final ---
df_final_pob = df_final_pob.drop(columns=['_merge_pob'])

print(f"\n‚úÖ Base final combinada con poblaci√≥n: {df_final_pob.shape[0]:,} filas √ó {df_final_pob.shape[1]} columnas")
display(df_final_pob.head(10))


# --- 10. Exportar resultado ---
df_final_pob.to_excel("delitos_con_poblacion_final2020.xlsx", index=False)
print("üìÅ Archivo exportado: delitos_con_poblacion_final2020.xlsx")

for col in df_final_pob.columns:
    print(f"\n=== {col} ===")
    print(df_final_pob[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {df_final_pob[col].nunique()}")

"""2021"""

import pandas as pd
def cargar_delito(url, delito):
    # Probar varios posibles encabezados
    posibles_headers = [8, 9, 10, 11, 12]

    for header_row in posibles_headers:
        try:
            df = pd.read_excel(url, header=header_row).copy()
            df.columns = df.columns.str.strip().str.upper().str.replace(" ", "_")

            renombrar = {
                "ARMAS_MEDIOS": "ARMAS_MEDIOS",
                "ARMA_MEDIO": "ARMAS_MEDIOS",
                "ARMAS/MEDIOS": "ARMAS_MEDIOS",
                "ARMAS_Y_MEDIOS": "ARMAS_MEDIOS",
                "CODIGO_DANE": "CODIGO_DANE",
                "FECHA_HECHO": "FECHA_HECHO",
                "GENERO": "GENERO",
                "CANTIDAD": "CANTIDAD",
                "AGRUPA_EDAD_PERSONA": "AGRUPA_EDAD_PERSONA",
                "*AGRUPA_EDAD_PERSONA": "AGRUPA_EDAD_PERSONA",
                "*AGRUPA_EDAD_PERSONA*": "AGRUPA_EDAD_PERSONA"
            }
            df = df.rename(columns=lambda x: renombrar.get(x, x))

            columnas_validas = [
                "DEPARTAMENTO", "MUNICIPIO", "CODIGO_DANE",
                "ARMAS_MEDIOS", "FECHA_HECHO", "GENERO",
                "AGRUPA_EDAD_PERSONA", "CANTIDAD"
            ]
            df = df[[col for col in columnas_validas if col in df.columns]]

            df = df.dropna(how="all")

            basura_regex = "TOTAL|FUENTE|Elaborado|Revisado|Autorizado|Ley 1098|Agrupaci√≥n referente|Contador"
            for col in ["DEPARTAMENTO", "ARMAS_MEDIOS"]:
                if col in df.columns:
                    df = df[~df[col].astype(str).str.contains(basura_regex, na=False, case=False)]

            if not df.empty:
                if "CODIGO_DANE" in df.columns:
                    df["CODIGO_DANE"] = pd.to_numeric(df["CODIGO_DANE"], errors="coerce")

                df["TIPO_DELITO"] = delito
                print(f"üìå {delito}: encabezado fijo en fila {header_row}")
                return df
        except Exception:
            continue

    # Si lleg√≥ aqu√≠, fall√≥ con todas
    print(f"‚ö†Ô∏è {delito}: no se pudo leer con headers {posibles_headers}")
    return pd.DataFrame()

# Diccionario de URLs y delitos 2021
urls_2021 = [
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/abigeato_6.xls", "HURTO CABEZAS GANADO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/amenazas_11.xls", "AMENAZAS"),
    #("https://www.policia.gov.co/sites/default/files/delitos-impacto/delitos_sexuales_9.xls", "DELITOS SEXUALES"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/extorsion_9.xls", "EXTORSI√ìN"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/Homicidio%20Intencional%202021.xlsx", "HOMICIDIO INTENCIONAL"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/homicidios_en_accidente_de_transito_9.xls", "HOMICIDIOS EN ACCIDENTE DE TR√ÅNSITO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto_a_personas_9.xlsx", "HURTO A PERSONAS"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto_a_residencias_5.xlsx", "HURTO A RESIDENCIAS"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto_automotores_5.xlsx", "HURTO AUTOMOTORES"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto_a_motocicletas_5.xlsx", "HURTO MOTOCICLETAS"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto_a_comercio_9.xls", "HURTO A COMERCIO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto_entidades_financieras_9.xls", "HURTO A ENTIDADES FINANCIERAS"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/lesiones_en_accidente_de_transito_5.xls", "LESIONES EN ACCIDENTE DE TR√ÅNSITO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/lesiones_personales_5.xls", "LESIONES PERSONALES"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/hurto_a_pirateria_terrestre_9.xls", "PIRATER√çA TERRESTRE"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/secuestro_9.xls", "SECUESTRO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/terrorismo_9.xls", "TERRORISMO"),
    ("https://www.policia.gov.co/sites/default/files/delitos-impacto/violencia_intrafamiliar_10.xls", "VIOLENCIA INTRAFAMILIAR"),
]

# Procesar todos los archivos
dfs_2021 = []
for url, delito in urls_2021:
    df = cargar_delito(url, delito)
    if not df.empty:
        dfs_2021.append(df)
        print(f"‚úÖ {delito}: {df.shape[0]} filas")

# Concatenar todo en un solo DataFrame
df_2021 = pd.concat(dfs_2021, ignore_index=True)

# Ordenar por MUNICIPIO y DEPARTAMENTO
df_2021 = df_2021.sort_values(by=["MUNICIPIO", "DEPARTAMENTO"]).reset_index(drop=True)

print(f"\nTotal final 2021: {df_2021.shape[0]} filas y {df_2021.shape[1]} columnas")
display(df_2021.head())

# === 14. Valores √∫nicos por columna en df_2018 ===
for col in df_2021.columns:
    print(f"\n=== {col} ===")
    print(df_2021[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {df_2021[col].nunique()}")



import pandas as pd
import numpy as np
import unidecode
import re

# --- LIMPIEZA Y ESTANDARIZACI√ìN DE VARIABLES CLAVE ---

# === DEPARTAMENTO ===
df_2021['DEPARTAMENTO'] = (
    df_2021['DEPARTAMENTO']
    .astype(str)
    .str.strip()
    .str.upper()
    .apply(lambda x: unidecode.unidecode(x))
)

# Correcciones comunes en nombres de departamentos
reemplazos_depto = {
    'CHOCO': 'CHOC√ì',
    'CORDOBA': 'C√ìRDOBA',
    'GUAVIARE ': 'GUAVIARE',
    'VALLE DEL CAUCA': 'VALLE',
    'BOGOTA D.C.': 'CUNDINAMARCA',
    'BOGOTA': 'CUNDINAMARCA',
}
df_2021['DEPARTAMENTO'] = df_2021['DEPARTAMENTO'].replace(reemplazos_depto)

# === MUNICIPIO ===
def limpiar_municipio(nombre):
    if pd.isna(nombre):
        return np.nan
    nombre = str(nombre).upper().strip()
    nombre = re.sub(r'\(CT\)', '', nombre)          # eliminar (CT)
    nombre = re.sub(r'[^A-Z√ë\s]', '', nombre)       # eliminar caracteres no alfab√©ticos
    nombre = unidecode.unidecode(nombre)            # quitar tildes
    nombre = nombre.replace('  ', ' ')              # quitar dobles espacios
    return nombre.strip()

df_2021['MUNICIPIO'] = df_2021['MUNICIPIO'].apply(limpiar_municipio)
df_2021['MUNICIPIO'] = df_2021['MUNICIPIO'].replace('NAN', np.nan)
df_2021 = df_2021.dropna(subset=['MUNICIPIO'])

# === FECHA_HECHO ===
def convertir_fecha(valor):
    # Si el valor est√° vac√≠o o es NaN
    if pd.isna(valor):
        return pd.NaT

    # Si es un n√∫mero tipo Excel (por ejemplo 20210515 o un serial)
    if isinstance(valor, (int, float)):
        try:
            valor_str = str(int(valor))
            if len(valor_str) == 8:  # formato YYYYMMDD
                return pd.to_datetime(valor_str, format='%Y%m%d', errors='coerce')
            else:
                return pd.to_datetime(valor, errors='coerce')
        except Exception:
            return pd.NaT

    # Si es una cadena con formato de fecha
    if isinstance(valor, str):
        return pd.to_datetime(valor.strip(), errors='coerce')

    # Cualquier otro tipo
    return pd.NaT

# Aplicar la funci√≥n corregida
df_2021['FECHA_HECHO'] = df_2021['FECHA_HECHO'].apply(convertir_fecha)

# --- RESUMEN DE NULOS ---
resumen_nulos = pd.DataFrame({
    'Columna': df_2021.columns,
    'Nulos': df_2021.isnull().sum(),
    'Porcentaje_nulos': df_2021.isnull().mean() * 100
})

print("=== RESUMEN DE NULOS ===")
print(resumen_nulos)

# --- VERIFICACI√ìN DE VALORES √öNICOS ---
for col in ['DEPARTAMENTO', 'MUNICIPIO', 'CODIGO_DANE', 'ARMAS_MEDIOS',
            'GENERO', 'AGRUPA_EDAD_PERSONA', 'CANTIDAD', 'TIPO_DELITO']:
    print(f"\n=== {col} ===")
    print(df_2021[col].unique())
    print("Total de valores √∫nicos:", df_2021[col].nunique())

# --- Cargar solo la base de DELITOS SEXUALES ---
url_ds = "https://www.policia.gov.co/sites/default/files/delitos-impacto/delitos_sexuales_9.xls"
delito = "DELITOS SEXUALES"

df_ds = cargar_delito(url_ds, delito)

print(f"‚úÖ {delito}: {df_ds.shape[0]} filas, {df_ds.shape[1]} columnas\n")

# --- Mostrar nombres de columnas ---
print("üìã Columnas detectadas:")
print(df_ds.columns.tolist(), "\n")

# --- Mostrar valores √∫nicos por columna ---
for col in df_ds.columns:
    print(f"\nüîπ {col} ({df_ds[col].nunique()} valores √∫nicos)")
    print(df_ds[col].unique())

import pandas as pd

# Columnas est√°ndar que esperas tener
COLUMNAS_OBJETIVO = [
    "DEPARTAMENTO", "MUNICIPIO", "CODIGO_DANE", "ARMAS_MEDIOS",
    "GENERO", "AGRUPA_EDAD_PERSONA", "CANTIDAD", "TIPO_DELITO"
]

def encontrar_fila_encabezado(ruta_o_url, max_filas_a_inspeccionar=30):
    """
    Lee las primeras filas sin cabecera y busca la fila que contiene
    los nombres de columna objetivo (por coincidencia parcial).
    Devuelve el √≠ndice (0-based) de la fila que debe usarse como header.
    Si no encuentra una coincidencia clara, devuelve None.
    """
    preview = pd.read_excel(ruta_o_url, header=None, nrows=max_filas_a_inspeccionar)
    # normalizar valores de cada celda a string may√∫scula sin espacios extremos
    preview_norm = preview.applymap(lambda x: str(x).strip().upper() if not pd.isna(x) else "")

    for idx in range(len(preview_norm)):
        fila = preview_norm.iloc[idx].tolist()
        # Contamos cu√°ntas columnas objetivo aparecen (coincidencia parcial)
        coincidencias = 0
        for objetivo in COLUMNAS_OBJETIVO:
            # si aparece exactamente o aparece palabra clave
            if any(objetivo in str(c) for c in fila if c):
                coincidencias += 1
        # si encontramos al menos 3-4 coincidencias consideramos que es el header correcto
        if coincidencias >= 3:
            return idx
    return None

def normalizar_colnames(df):
    """Quita espacios y pone may√∫sculas a los nombres de columnas."""
    df = df.rename(columns=lambda x: str(x).strip().upper())
    df.columns = [c.replace("\n", " ").strip() for c in df.columns]
    return df

def cargar_delito(ruta_o_url, tipo_delito=None, force_header=None, max_preview_rows=40):
    """
    Lee correctamente un archivo de delitos (ruta local o URL).
    - detecta la fila de encabezado autom√°ticamente
    - normaliza columnas
    - reordena y devuelve s√≥lo las columnas objetivo (si existen)
    - agrega columna TIPO_DELITO si se pasa tipo_delito
    Par√°metros:
      ruta_o_url: string (ruta local o URL)
      tipo_delito: string (opcional) para asignar en la columna TIPO_DELITO
      force_header: int (opcional) forzar √≠ndice de fila header (0-based)
    """
    # 1) encontrar fila de encabezado
    if force_header is None:
        header_idx = encontrar_fila_encabezado(ruta_o_url, max_filas_a_inspeccionar=max_preview_rows)
    else:
        header_idx = force_header

    # si no encontramos, probamos con header=8 y header=9 como fallback (comunes)
    if header_idx is None:
        for candidato in (8, 9, 0):
            try:
                df_try = pd.read_excel(ruta_o_url, header=candidato, nrows=3)
                # si tiene m√°s de 1 columna asumimos √©xito
                if df_try.shape[1] > 1:
                    header_idx = candidato
                    break
            except Exception:
                continue

    # 2) lectura final con header detectado (o error si no se detect√≥ nada)
    if header_idx is None:
        raise ValueError("No se pudo detectar la fila de encabezado. Usa force_header=<fila 0-based>.")
    df = pd.read_excel(ruta_o_url, header=header_idx)

    # 3) normalizar nombres de columnas
    df = normalizar_colnames(df)

    # 4) arreglos y limpieza de valores de texto comunes
    # quitar espacios en strings de todas las columnas object
    for c in df.select_dtypes(include=['object']).columns:
        df[c] = df[c].astype(str).str.strip()

    # corregir errores tipogr√°ficos comunes
    df = df.replace({"NO RESPORTADO": "NO REPORTADO", "NO RESPORTADO ": "NO REPORTADO"})

    # 5) asegurarnos de que exista la columna TIPO_DELITO
    if tipo_delito is not None:
        df["TIPO_DELITO"] = tipo_delito
    else:
        # si no la hay, crearla vac√≠a para mantener consistencia
        if "TIPO_DELITO" not in df.columns:
            df["TIPO_DELITO"] = pd.NA

    # 6) tratar CODIGO_DANE si existe (normalizar a int/str seg√∫n convenga)
    if "CODIGO_DANE" in df.columns:
        # intentar convertir a entero sin perder valores no convertibles
        df["CODIGO_DANE"] = pd.to_numeric(df["CODIGO_DANE"], errors="coerce").astype("Int64")

    # 7) reordenar columnas seg√∫n objetivo (mantener las que falten si no est√°n)
    columnas_presentes = [c for c in COLUMNAS_OBJETIVO if c in df.columns]
    # a√±adir el resto de columnas que existan pero no est√°n en objetivo al final
    resto = [c for c in df.columns if c not in columnas_presentes]
    columnas_final = columnas_presentes + resto
    df = df.reindex(columns=columnas_final)

    # 8) Opcional: si quieres devolver s√≥lo las columnas objetivo, descomenta:
    # df = df.reindex(columns=COLUMNAS_OBJETIVO)

    return df

pd.read_excel(url_ds, header=None).head(15)

import pandas as pd

# Ruta o URL del archivo
url = "https://www.policia.gov.co/sites/default/files/delitos-impacto/delitos_sexuales_9.xls"

# Leer con el encabezado correcto (fila 10 visible en Excel ‚Üí header=9)
df = pd.read_excel(url, header=9)

# Normalizar nombres de columnas
df.columns = df.columns.str.strip().str.upper()

# Verificamos columnas disponibles
print("Columnas detectadas:", df.columns.tolist())

# Intercambiar las columnas 'DEPARTAMENTO' y 'ARMAS_MEDIOS'
if "DEPARTAMENTO" in df.columns and "ARMAS_MEDIOS" in df.columns:
    df.rename(columns={"DEPARTAMENTO": "TEMP",
                       "ARMAS_MEDIOS": "DEPARTAMENTO"}, inplace=True)
    df.rename(columns={"TEMP": "ARMAS_MEDIOS"}, inplace=True)

# Agregar tipo de delito
df["TIPO_DELITO"] = "DELITOS SEXUALES"

# Limpiar y estandarizar texto
for c in df.select_dtypes(include='object').columns:
    df[c] = df[c].astype(str).str.strip().str.upper()

# Corregir errores comunes
df.replace({"NO RESPORTADO": "NO REPORTADO"}, inplace=True)

# Verificar resultados
print("\nValores √∫nicos en DEPARTAMENTO:")
print(df["DEPARTAMENTO"].dropna().unique()[:20])
print(f"Total: {df['DEPARTAMENTO'].nunique()} departamentos √∫nicos")

print("\nValores √∫nicos en ARMAS_MEDIOS:")
print(df["ARMAS_MEDIOS"].dropna().unique()[:20])
print(f"Total: {df['ARMAS_MEDIOS'].nunique()} tipos de armas/medios √∫nicos")

# Ver 5 primeras filas
print("\nVista previa:")
print(df.head())

# Lista de valores no v√°lidos (pie de p√°gina o totales)
valores_invalidos = [
    'TOTAL',
    'FUENTE:                            DIJIN-POLIC√çA NACIONAL. DATOS EXTRAIDOS EL DIA 5 DE ENERO  DEL A√ëO 2023.',
    '*AGRUPACI√ìN REFERENTE A LA CLASIFICACI√ìN DEL C√ìDIGO DE INFANCIA Y ADOLESCENCIA LEY 1098 DE DEL 8 DE NOVIEMBRE DE 2006, EN SU ART√çCULO 3 DONDE SE ESTABLECEN LOS MENORES ENTRE LOS 0 Y LOS 12 A√ëOS, ADOLESCENTES ENTRE LOS 13 Y LOS 17 A√ëOS Y ADULTOS DE 18 EN ADELANTE.',
    'ELABORADO: SUBINTENDENTE CECILIA ANGEL NEITA'
]

# Filtrar filas v√°lidas
df = df[~df["ARMAS_MEDIOS"].isin(valores_invalidos)].copy()

# Revisar nuevamente los valores √∫nicos
print("ARMAS_MEDIOS limpios:", df["ARMAS_MEDIOS"].unique())
print(f"Total armas/medios √∫nicos: {df['ARMAS_MEDIOS'].nunique()}")

# Lista de departamentos v√°lidos en Colombia (may√∫sculas)
departamentos_validos = [
    'AMAZONAS', 'ANTIOQUIA', 'ARAUCA', 'ATL√ÅNTICO', 'BOL√çVAR', 'BOYAC√Å',
    'CALDAS', 'CAQUET√Å', 'CASANARE', 'CAUCA', 'CESAR', 'CHOC√ì', 'C√ìRDOBA',
    'CUNDINAMARCA', 'GUAIN√çA', 'GUAJIRA', 'GUAVIARE', 'HUILA', 'MAGDALENA',
    'META', 'NARI√ëO', 'NORTE DE SANTANDER', 'PUTUMAYO', 'QUIND√çO', 'RISARALDA',
    'SAN ANDR√âS Y PROVIDENCIA', 'SANTANDER', 'SUCRE', 'TOLIMA', 'VALLE DEL CAUCA',
    'VAUP√âS', 'VICHADA', 'BOGOT√Å, D.C.'
]

# Convertir a may√∫sculas para comparar
df["DEPARTAMENTO"] = df["DEPARTAMENTO"].str.upper().str.strip()

# Filtrar solo los departamentos v√°lidos
df = df[df["DEPARTAMENTO"].isin(departamentos_validos)].copy()

# Mostrar verificaci√≥n final
print("DEPARTAMENTOS √∫nicos limpios:")
print(df["DEPARTAMENTO"].unique())
print(f"Total departamentos √∫nicos: {df['DEPARTAMENTO'].nunique()}")

import pandas as pd
import numpy as np
import unidecode
import re

# --- 1Ô∏è‚É£ Reasignar correctamente las columnas ---
# El contenido de DEPARTAMENTO y ARMAS_MEDIOS est√° invertido
df_2021.rename(columns={
    'DEPARTAMENTO': 'DEPARTAMENTO_TEMP',
    'ARMAS_MEDIOS': 'ARMAS_MEDIOS_TEMP'
}, inplace=True)

# Ahora los corregimos
df_2021['ARMAS_MEDIOS'] = df_2021['DEPARTAMENTO_TEMP']
df_2021['DEPARTAMENTO'] = df_2021['ARMAS_MEDIOS_TEMP']

# Eliminamos las temporales
df_2021.drop(columns=['DEPARTAMENTO_TEMP', 'ARMAS_MEDIOS_TEMP'], inplace=True)

# --- 2Ô∏è‚É£ Estandarizar nombres de columnas ---
df_2021.columns = df_2021.columns.str.strip().str.upper().str.replace(" ", "_")

# --- 3Ô∏è‚É£ Corregir textos con errores tipogr√°ficos ---
df_2021['GENERO'] = df_2021['GENERO'].replace({'NO RESPORTADO ': 'NO REPORTADO'})
df_2021['AGRUPA_EDAD_PERSONA'] = df_2021['AGRUPA_EDAD_PERSONA'].replace({'NO RESPORTADO ': 'NO REPORTADO'})

# --- 4Ô∏è‚É£ Estandarizar nombres en DEPARTAMENTO ---
df_2021['DEPARTAMENTO'] = (
    df_2021['DEPARTAMENTO']
    .astype(str)
    .str.strip()
    .str.upper()
    .apply(lambda x: unidecode.unidecode(x))
)

reemplazos_depto = {
    'CHOCO': 'CHOC√ì',
    'CORDOBA': 'C√ìRDOBA',
    'GUAVIARE ': 'GUAVIARE',
    'VALLE DEL CAUCA': 'VALLE',
    'BOGOTA D.C.': 'CUNDINAMARCA',
    'BOGOTA': 'CUNDINAMARCA',
}
df_2021['DEPARTAMENTO'] = df_2021['DEPARTAMENTO'].replace(reemplazos_depto)

# --- 5Ô∏è‚É£ Limpiar MUNICIPIO ---
def limpiar_municipio(nombre):
    if pd.isna(nombre):
        return np.nan
    nombre = str(nombre).upper().strip()
    nombre = re.sub(r'\(CT\)', '', nombre)
    nombre = re.sub(r'[^A-Z√ë\s]', '', nombre)
    nombre = unidecode.unidecode(nombre)
    return re.sub(r'\s+', ' ', nombre).strip()

df_2021['MUNICIPIO'] = df_2021['MUNICIPIO'].apply(limpiar_municipio)
df_2021 = df_2021.dropna(subset=['MUNICIPIO'])

# --- 6Ô∏è‚É£ Convertir FECHA_HECHO ---
def convertir_fecha(valor):
    if pd.isna(valor):
        return pd.NaT
    try:
        return pd.to_datetime(valor, errors='coerce')
    except Exception:
        return pd.NaT

df_2021['FECHA_HECHO'] = df_2021['FECHA_HECHO'].apply(convertir_fecha)

# --- 7Ô∏è‚É£ Eliminar registros que son notas de pie o totales ---
valores_invalidos = [
    'TOTAL',
    'FUENTE:                            DIJIN-POLIC√çA NACIONAL. DATOS EXTRAIDOS EL DIA 5 DE ENERO  DEL A√ëO 2023.',
    '*AGRUPACI√ìN REFERENTE A LA CLASIFICACI√ìN DEL C√ìDIGO DE INFANCIA Y ADOLESCENCIA LEY 1098 DE DEL 8 DE NOVIEMBRE DE 2006, EN SU ART√çCULO 3 DONDE SE ESTABLECEN LOS MENORES ENTRE LOS 0 Y LOS 12 A√ëOS, ADOLESCENTES ENTRE LOS 13 Y LOS 17 A√ëOS Y ADULTOS DE 18 EN ADELANTE.',
    'ELABORADO: SUBINTENDENTE CECILIA ANGEL NEITA'
]
df_2021 = df_2021[~df_2021['ARMAS_MEDIOS'].isin(valores_invalidos)].copy()

# --- 8Ô∏è‚É£ Resumen de nulos ---
resumen_nulos = pd.DataFrame({
    'Columna': df_2021.columns,
    'Nulos': df_2021.isnull().sum(),
    'Porcentaje_nulos': df_2021.isnull().mean() * 100
})
print("=== RESUMEN DE NULOS ===")
print(resumen_nulos)

# --- 9Ô∏è‚É£ Verificaci√≥n de valores √∫nicos ---
for col in ['DEPARTAMENTO', 'ARMAS_MEDIOS', 'MUNICIPIO', 'CODIGO_DANE',
            'GENERO', 'AGRUPA_EDAD_PERSONA', 'CANTIDAD', 'TIPO_DELITO']:
    print(f"\n=== {col} ===")
    print(df_2021[col].unique())
    print("Total de valores √∫nicos:", df_2021[col].nunique())

df_2021.isna().sum()

df_2021['MUNICIPIO'].value_counts(dropna=False).head(10)

print(df_2021['MUNICIPIO'].dtype)   # tipo de dato real
print(df_2021['MUNICIPIO'].isna().sum())  # conteo de nulos
print(df_2021['MUNICIPIO'].head(20))      # primeros valores

df_2021[df_2021['MUNICIPIO'].isna()]

# Ordenar alfab√©ticamente por MUNICIPIO
df_2021 = df_2021.sort_values(by=["MUNICIPIO"], ascending=True).reset_index(drop=True)

print(f"\n Total ordenado: {df_2021.shape[0]} filas y {df_2021.shape[1]} columnas")
display(df_2021.head(20))  # muestra los primeros 20 municipios ordenados

import pandas as pd
import numpy as np

# Crear tabla resumen de nulos
resumen_nulos = pd.DataFrame({
    'Columna': df_2021.columns,
    'Nulos': df_2021.isnull().sum(),
    'NaN explicitos': df_2021.apply(lambda x: x.isna().sum())
})

# Ordenar opcionalmente de mayor a menor nulos
resumen_nulos = resumen_nulos.sort_values(by='Nulos', ascending=False).reset_index(drop=True)

print(resumen_nulos)

import numpy as np

# Reemplazar 'NAN' como string por valores NaN
df_2021['MUNICIPIO'] = df_2021['MUNICIPIO'].replace('NAN', np.nan)

# Ahora contamos nulos y NaN
resumen_nulos = pd.DataFrame({
    'Columna': df_2021.columns,
    'Nulos': df_2021.isnull().sum(),
    'Porcentaje_nulos': df_2021.isnull().mean() * 100
})

print(resumen_nulos)

import numpy as np

# Asegurarnos de que los 'NAN' como texto sean NaN reales
df_2021['MUNICIPIO'].replace('NAN', np.nan, inplace=True)

# Eliminar filas donde MUNICIPIO sea NaN
df_2021= df_2021.dropna(subset=['MUNICIPIO'])

# Revisar
print(df_2021['MUNICIPIO'].isnull().sum())  # deber√≠a dar 0

import numpy as np

# Reemplazar 'NAN' como string por valores NaN
df_2021['MUNICIPIO'] = df_2021['MUNICIPIO'].replace('NAN', np.nan)

# Ahora contamos nulos y NaN
resumen_nulos = pd.DataFrame({
    'Columna': df_2021.columns,
    'Nulos': df_2021.isnull().sum(),
    'Porcentaje_nulos': df_2021.isnull().mean() * 100
})

print(resumen_nulos)

for col in df_2021.columns:
    print(f"\n=== {col} ===")
    print(df_2021[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {df_2021[col].nunique()}")

"""Poblacion Y DAVIPOLA"""

import pandas as pd
import requests
import numpy as np

# --------------------------
# URLs de insumos externos
# --------------------------
url_poblacion = "https://www.dane.gov.co/files/censo2018/proyecciones-de-poblacion/Municipal/PPED-AreaSexoEdadMun-2018-2042_VP.xlsx"
api_url_divipola = "https://www.datos.gov.co/resource/gdxc-w37w.json?$limit=2000"

# Cargar DIVIPOLA desde la API de datos abiertos
divipola = pd.read_json(api_url_divipola)

# Mostrar las columnas originales
print("üßê Columnas originales en DIVIPOLA:")
print(divipola.columns.tolist())

# (Opcional) ver las primeras filas
display(divipola.head())

df_2021['MUNICIPIO'] = (
    df_2021['MUNICIPIO']
    .astype(str)
    .str.strip()
    .str.upper()
    .apply(lambda x: unidecode.unidecode(x))
)

df_2021['DEPARTAMENTO'] = (
    df_2021['DEPARTAMENTO']
    .astype(str)
    .str.strip()
    .str.upper()
    .apply(lambda x: unidecode.unidecode(x))
)

import pandas as pd
import unidecode
from difflib import get_close_matches

# --- 1. Funci√≥n de normalizaci√≥n ---
def normalizar(texto):
    """Convierte a may√∫sculas, elimina tildes y espacios extra."""
    if pd.isna(texto):
        return ''
    texto = str(texto).strip().upper()
    texto = unidecode.unidecode(texto)
    texto = ' '.join(texto.split())  # quita espacios dobles
    return texto

# Aplicar normalizaci√≥n a la base de datos
df_2021['DEPARTAMENTO'] = df_2021['DEPARTAMENTO'].apply(normalizar)
df_2021['MUNICIPIO'] = df_2021['MUNICIPIO'].apply(normalizar)
divipola['dpto'] = divipola['dpto'].apply(normalizar)
divipola['nom_mpio'] = divipola['nom_mpio'].apply(normalizar)

# --- 2. Detectar municipios sin coincidencia ---
merged_final = df_2021.merge(
    divipola,
    left_on=['DEPARTAMENTO', 'MUNICIPIO'],
    right_on=['dpto', 'nom_mpio'],
    how='left',
    indicator=True
)

# Filtrar los municipios sin coincidencia
sin_match = merged_final[merged_final['_merge'] == 'left_only'][['DEPARTAMENTO', 'MUNICIPIO']].drop_duplicates()

# --- 3. Correcci√≥n autom√°tica de errores de digitaci√≥n ---
municipios_divipola = divipola['nom_mpio'].unique().tolist()

# Funci√≥n para corregir el nombre del municipio
def corregir_nombre(nombre):
    match = get_close_matches(nombre, municipios_divipola, n=1, cutoff=0.85)
    return match[0] if match else nombre

# Corregir los municipios sin coincidencia
if not sin_match.empty:
    sin_match['MUNICIPIO_CORREGIDO'] = sin_match['MUNICIPIO'].apply(corregir_nombre)

    # Realizar el merge de las correcciones autom√°ticas
    df_2021 = df_2021.merge(sin_match[['DEPARTAMENTO', 'MUNICIPIO', 'MUNICIPIO_CORREGIDO']],
                             on=['DEPARTAMENTO', 'MUNICIPIO'], how='left')

    # Aplicar las correcciones autom√°ticas
    if 'MUNICIPIO_CORREGIDO' in df_2021.columns:
        df_2021['MUNICIPIO'] = df_2021['MUNICIPIO_CORREGIDO'].fillna(df_2021['MUNICIPIO'])
        df_2021.drop(columns='MUNICIPIO_CORREGIDO', inplace=True, errors='ignore')

# --- 4. Merge final corregido ---
merged_final = df_2021.merge(
    divipola,
    left_on=['DEPARTAMENTO', 'MUNICIPIO'],
    right_on=['dpto', 'nom_mpio'],
    how='left',
    indicator=True
)

# --- 5. Verificaci√≥n final de municipios sin coincidencia ---
sin_match_final = merged_final[merged_final['_merge'] == 'left_only'][['DEPARTAMENTO', 'MUNICIPIO']].drop_duplicates()

print(f"‚úÖ Municipios sin coincidencia tras correcci√≥n autom√°tica: {len(sin_match_final)}")
display(sin_match_final.head(30))

# --- 6. Resultado final ---
print(f"\n‚úÖ Base unida correctamente: {merged_final.shape[0]:,} filas √ó {merged_final.shape[1]} columnas")

# --- 7. Correcci√≥n final de municipios problem√°ticos (si existen) ---
correcciones_finales = {
    "BOGOT DC": "BOGOTA, D.C.",
    "MOMPS": "SANTA CRUZ DE MOMPOX",
    "TOG": "TOGOI",
    "TOL VIEJO": "SAN JOSE DE TOLUVIEJO",
    "PIENDAM": "PIENDAMO - TUNIA",
    "PURSIMA": "PURISIMA DE LA CONCEPCION",
    "LPEZ": "LOPEZ DE MICAY",
    "CCUTA": "SAN JOSE DE CUCUTA",
    "GICN": "GUICAN DE LA SIERRA"
}

# Aplicar correcciones manuales
df_2021['MUNICIPIO'] = df_2021['MUNICIPIO'].replace(correcciones_finales)

# --- 8. Rehacer merge tras correcci√≥n manual ---
merged_final = df_2021.merge(
    divipola,
    left_on=['DEPARTAMENTO', 'MUNICIPIO'],
    right_on=['dpto', 'nom_mpio'],
    how='left',
    indicator=True
)

# --- 9. Verificaci√≥n final despu√©s de la correcci√≥n manual ---
sin_match_final = merged_final[merged_final['_merge'] == 'left_only'][['DEPARTAMENTO', 'MUNICIPIO']].drop_duplicates()

print(f"‚úÖ Municipios sin coincidencia tras correcci√≥n manual: {len(sin_match_final)}")
display(sin_match_final.head(30))

# --- 10. Corregir municipio TOG√úI si persiste ---
df_2021.loc[df_2021['MUNICIPIO'] == 'TOG√úI', 'DEPARTAMENTO'] = 'BOYAC√Å'

# Rehacer el merge final despu√©s de la correcci√≥n de TOG√úI
merged_final = df_2021.merge(
    divipola,
    left_on=['DEPARTAMENTO', 'MUNICIPIO'],
    right_on=['dpto', 'nom_mpio'],
    how='left',
    indicator=True
)

# --- 11. Verificaci√≥n final despu√©s de la correcci√≥n de TOG√úI ---
sin_match_final = merged_final[merged_final['_merge'] == 'left_only'][['DEPARTAMENTO', 'MUNICIPIO']].drop_duplicates()

print(f"‚úÖ Municipios sin coincidencia tras correcci√≥n de TOG√úI: {len(sin_match_final)}")
display(sin_match_final.head(30))

import pandas as pd
import unidecode
from difflib import get_close_matches

# ==========================================================
# 1. Funci√≥n de normalizaci√≥n
# ==========================================================
def normalizar(texto):
    """Convierte a may√∫sculas, elimina tildes y espacios extra."""
    if pd.isna(texto):
        return ''
    texto = str(texto).strip().upper()
    texto = unidecode.unidecode(texto)
    texto = ' '.join(texto.split())
    return texto

# Aplicar normalizaci√≥n
df_2021['DEPARTAMENTO'] = df_2021['DEPARTAMENTO'].apply(normalizar)
df_2021['MUNICIPIO'] = df_2021['MUNICIPIO'].apply(normalizar)
divipola['dpto'] = divipola['dpto'].apply(normalizar)
divipola['nom_mpio'] = divipola['nom_mpio'].apply(normalizar)

# ==========================================================
# 2. Correcci√≥n departamental (errores m√°s comunes)
# ==========================================================
correccion_departamentos = {
    'VALLE': 'VALLE DEL CAUCA',
    'GUAJIRA': 'LA GUAJIRA',
    'BOLIVAR': 'BOLIVAR',
    'NARINO': 'NARI√ëO',
    'CORDOBA': 'C√ìRDOBA',
    'BOYACA': 'BOYAC√Å',
    'ATLANTICO': 'ATL√ÅNTICO'
}

df_2021['DEPARTAMENTO'] = df_2021['DEPARTAMENTO'].replace(correccion_departamentos)

# ==========================================================
# 3. Merge con DIVIPOLA
# ==========================================================
merged_final = df_2021.merge(
    divipola,
    left_on=['DEPARTAMENTO', 'MUNICIPIO'],
    right_on=['dpto', 'nom_mpio'],
    how='left',
    indicator=True
)

sin_match = merged_final[merged_final['_merge'] == 'left_only'][['DEPARTAMENTO', 'MUNICIPIO']].drop_duplicates()
print(f"üîé Municipios sin coincidencia tras corregir departamentos: {len(sin_match)}")
display(sin_match.head(30))

# ==========================================================
# 4. Correcci√≥n autom√°tica de municipios (errores menores)
# ==========================================================
municipios_divipola = divipola['nom_mpio'].unique().tolist()

def corregir_nombre(nombre):
    match = get_close_matches(nombre, municipios_divipola, n=1, cutoff=0.85)
    return match[0] if match else nombre

if not sin_match.empty:
    sin_match['MUNICIPIO_CORREGIDO'] = sin_match['MUNICIPIO'].apply(corregir_nombre)
    df_2021 = df_2021.merge(sin_match[['DEPARTAMENTO', 'MUNICIPIO', 'MUNICIPIO_CORREGIDO']],
                            on=['DEPARTAMENTO', 'MUNICIPIO'], how='left')
    df_2021['MUNICIPIO'] = df_2021['MUNICIPIO_CORREGIDO'].fillna(df_2021['MUNICIPIO'])
    df_2021.drop(columns='MUNICIPIO_CORREGIDO', inplace=True, errors='ignore')

# ==========================================================
# 5. Correcciones manuales espec√≠ficas
# ==========================================================
correcciones_finales = {
    "BOGOT DC": "BOGOTA, D.C.",
    "MOMPS": "SANTA CRUZ DE MOMPOX",
    "TOG": "TOGOI",
    "TOL VIEJO": "SAN JOSE DE TOLUVIEJO",
    "PIENDAM": "PIENDAMO - TUNIA",
    "PURSIMA": "PURISIMA DE LA CONCEPCION",
    "LPEZ": "LOPEZ DE MICAY",
    "CCUTA": "SAN JOSE DE CUCUTA",
    "GICN": "GUICAN DE LA SIERRA"
}
df_2021['MUNICIPIO'] = df_2021['MUNICIPIO'].replace(correcciones_finales)

# ==========================================================
# 6. Merge final despu√©s de todas las correcciones
# ==========================================================
merged_final = df_2021.merge(
    divipola,
    left_on=['DEPARTAMENTO', 'MUNICIPIO'],
    right_on=['dpto', 'nom_mpio'],
    how='left',
    indicator=True
)

sin_match_final = merged_final[merged_final['_merge'] == 'left_only'][['DEPARTAMENTO', 'MUNICIPIO']].drop_duplicates()

print(f"‚úÖ Municipios sin coincidencia tras correcci√≥n total: {len(sin_match_final)}")
display(sin_match_final.head(30))

print(f"\n‚úÖ Base unida correctamente: {merged_final.shape[0]:,} filas √ó {merged_final.shape[1]} columnas")

import pandas as pd
import unidecode
from difflib import get_close_matches

# --- 1. Funci√≥n de normalizaci√≥n ---
def normalizar(texto):
    """Convierte a may√∫sculas, elimina tildes y espacios extra."""
    if pd.isna(texto):
        return ''
    texto = str(texto).strip().upper()
    texto = unidecode.unidecode(texto)
    texto = ' '.join(texto.split())  # quita espacios dobles
    return texto

# --- 2. Filtrar y corregir municipios irregulares ---
nombres_irregulares = ['ACIDO', 'AGUA CALIENTE', 'VEHICULO', 'NAN', 'NO REPORTADO', 'SIN EMPLEO DE ARMAS']
df_2021['MUNICIPIO'] = df_2021['MUNICIPIO'].replace(nombres_irregulares, 'DESCONOCIDO')

# --- 3. Crear un diccionario de referencia municipio ‚Üí departamento correcto ---
mapa_mpios_correctos = divipola.set_index('nom_mpio')['dpto'].to_dict()

# Si el municipio existe en el diccionario y su dpto no coincide, se corrige
def corregir_departamento(row):
    mun = row['MUNICIPIO']
    dep_actual = row['DEPARTAMENTO']
    dep_correcto = mapa_mpios_correctos.get(mun, dep_actual)
    return dep_correcto

df_2021['DEPARTAMENTO'] = df_2021.apply(corregir_departamento, axis=1)

# --- 4. Normalizar departamentos y municipios ---
df_2021['DEPARTAMENTO'] = df_2021['DEPARTAMENTO'].apply(normalizar)
df_2021['MUNICIPIO'] = df_2021['MUNICIPIO'].apply(normalizar)
divipola['dpto'] = divipola['dpto'].apply(normalizar)
divipola['nom_mpio'] = divipola['nom_mpio'].apply(normalizar)

# --- 5. Rehacer merge despu√©s de correcci√≥n de departamento ---
merged_final = df_2021.merge(
    divipola,
    left_on=['DEPARTAMENTO', 'MUNICIPIO'],
    right_on=['dpto', 'nom_mpio'],
    how='left',
    indicator=True
)

# --- 6. Verificaci√≥n de municipios sin coincidencia ---
sin_match_final = (
    merged_final[merged_final['_merge'] == 'left_only'][['DEPARTAMENTO', 'MUNICIPIO']]
    .drop_duplicates()
    .sort_values(['DEPARTAMENTO', 'MUNICIPIO'])
)

print(f"‚úÖ Municipios sin coincidencia tras correcci√≥n: {len(sin_match_final)}")
display(sin_match_final)

# --- 7. Correcci√≥n autom√°tica de errores de digitaci√≥n ---
municipios_divipola = divipola['nom_mpio'].unique().tolist()

def corregir_nombre(nombre, cutoff=0.75):  # Umbral ajustado
    match = get_close_matches(nombre, municipios_divipola, n=1, cutoff=cutoff)
    return match[0] if match else nombre

# Aplicar correcci√≥n autom√°tica a los municipios sin coincidencia
if not sin_match_final.empty:
    sin_match_final['MUNICIPIO_CORREGIDO'] = sin_match_final['MUNICIPIO'].apply(corregir_nombre)

    # Aplicar correcciones autom√°ticas
    df_2021 = df_2021.merge(sin_match_final[['DEPARTAMENTO', 'MUNICIPIO', 'MUNICIPIO_CORREGIDO']],
                            on=['DEPARTAMENTO', 'MUNICIPIO'], how='left')

    if 'MUNICIPIO_CORREGIDO' in df_2021.columns:
        df_2021['MUNICIPIO'] = df_2021['MUNICIPIO_CORREGIDO'].fillna(df_2021['MUNICIPIO'])
        df_2021.drop(columns='MUNICIPIO_CORREGIDO', inplace=True, errors='ignore')

# --- 8. Merge final corregido ---
merged_final = df_2021.merge(
    divipola,
    left_on=['DEPARTAMENTO', 'MUNICIPIO'],
    right_on=['dpto', 'nom_mpio'],
    how='left',
    indicator=True
)

# --- 9. Verificaci√≥n final ---
sin_match_final = (
    merged_final[merged_final['_merge'] == 'left_only'][['DEPARTAMENTO', 'MUNICIPIO']]
    .drop_duplicates()
    .sort_values(['DEPARTAMENTO', 'MUNICIPIO'])
)

print(f"‚úÖ Municipios sin coincidencia tras correcci√≥n autom√°tica: {len(sin_match_final)}")
display(sin_match_final.head(30))

# --- 10. Guardar municipios sin coincidencia en un archivo ---
sin_match_final.to_csv('municipios_sin_coincidencia.csv', index=False)

# --- 11. Resultado final ---
print(f"\n‚úÖ Base unida correctamente: {merged_final.shape[0]:,} filas √ó {merged_final.shape[1]} columnas")

# ==========================================================
# 7. Correcciones manuales finales (√∫ltimos municipios)
# ==========================================================
correcciones_municipios_finales = {
    # Casos de departamentos mal asignados
    ('BOLIVAR', 'CARTAGO'): ('VALLE DEL CAUCA', 'CARTAGO'),
    ('CAUCA', 'SOTAQUIRA'): ('BOYACA', 'SOTAQUIRA'),
    ('TOLIMA', 'ARAUQUITA'): ('ARAUCA', 'ARAUQUITA'),

    # Casos de nombres incompletos o con error tipogr√°fico
    ('NARINO', 'CUASPUD'): ('NARI√ëO', 'CUASPUD - CARLOSAMA'),
    ('ANTIOQUIA', 'SAN VICENTE'): ('ANTIOQUIA', 'SAN VICENTE FERRER'),
    ('TOLIMA', 'MARIQUITA'): ('TOLIMA', 'SAN SEBASTIAN DE MARIQUITA'),
    ('VALLE DEL CAUCA', 'CALI'): ('VALLE DEL CAUCA', 'SANTIAGO DE CALI')
}

# Aplicar las correcciones
for (dep, mun), (dep_corr, mun_corr) in correcciones_municipios_finales.items():
    mask = (df_2021['DEPARTAMENTO'] == dep) & (df_2021['MUNICIPIO'] == mun)
    df_2021.loc[mask, ['DEPARTAMENTO', 'MUNICIPIO']] = dep_corr, mun_corr

# Rehacer el merge final
merged_final = df_2021.merge(
    divipola,
    left_on=['DEPARTAMENTO', 'MUNICIPIO'],
    right_on=['dpto', 'nom_mpio'],
    how='left',
    indicator=True
)

# Mostrar municipios sin coincidencia finales
sin_match_final = merged_final[merged_final['_merge'] == 'left_only'][['DEPARTAMENTO', 'MUNICIPIO']].drop_duplicates()

print(f"‚úÖ Municipios sin coincidencia tras correcci√≥n final: {len(sin_match_final)}")
display(sin_match_final)

# =========================================================
# üîß Correcci√≥n final manual de CUASPUD
# =========================================================

# Corregir el municipio manualmente
df_2021.loc[(df_2021['DEPARTAMENTO'] == 'NARINO') & (df_2021['MUNICIPIO'] == 'CUASPUD'),
            'MUNICIPIO'] = 'CUASPUD CARLOSAMA'

# Rehacer el merge final con DIVIPOLA
merged_final = df_2021.merge(
    divipola,
    left_on=['DEPARTAMENTO', 'MUNICIPIO'],
    right_on=['dpto', 'nom_mpio'],
    how='left',
    indicator=True
)

# Verificar municipios sin coincidencia
sin_match_final = (
    merged_final[merged_final['_merge'] == 'left_only'][['DEPARTAMENTO', 'MUNICIPIO']]
    .drop_duplicates()
    .sort_values(['DEPARTAMENTO', 'MUNICIPIO'])
)

print(f"‚úÖ Municipios sin coincidencia tras correcci√≥n manual final: {len(sin_match_final)}")
display(sin_match_final)

# Resultado final
print(f"\n‚úÖ Base unida correctamente: {merged_final.shape[0]:,} filas √ó {merged_final.shape[1]} columnas")

for col in merged_final.columns:
    print(f"\n=== {col} ===")
    print(merged_final[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {merged_final[col].nunique()}")

# Comparar los departamentos de ambos DataFrames
set_df = set(df_2021['DEPARTAMENTO'].unique())
set_divi = set(divipola['dpto'].unique())

faltante_en_df2021 = set_divi - set_df
faltante_en_divipola = set_df - set_divi

print("üß© Departamento(s) que est√°n en DIVIPOLA pero no en df_2021:")
print(faltante_en_df2021)

print("\nüîπ Departamento(s) que est√°n en df_2021 pero no en DIVIPOLA:")
print(faltante_en_divipola)

# ========================================
# 2. CARGAR Y PROCESAR POBLACI√ìN
# ========================================

import pandas as pd
import unidecode

print("\nüì• Descargando datos de poblaci√≥n...")

# Leer archivo Excel del DANE
pob = pd.read_excel(
    url_poblacion,
    sheet_name='PobMunicipalx√ÅreaSexoEdad',
    header=7
)

# --- Normalizar nombres de columnas ---
pob.columns = (
    pob.columns.str.upper()
    .str.strip()
    .str.replace(' ', '_')
    .str.replace('√Å', 'A')
    .str.replace('.', '', regex=False)
)

# --- Verificaci√≥n de nombres existentes ---
print(f"Columnas detectadas: {list(pob.columns)}")

# --- Seleccionar solo columnas que existan ---
columnas_requeridas = ['DP', 'DPNOM', 'MPIO', 'MPNOM', 'DPMP', 'A√ëO', 'AREA_GEOGRAFICA', 'TOTAL']
cols_existentes = [col for col in columnas_requeridas if col in pob.columns]
pob = pob[cols_existentes].copy()

print(f"\nColumnas seleccionadas para procesamiento: {pob.columns.tolist()}")

# --- Si no existe MPNOM, intentar usar el nombre alternativo (MPIO) ---
if 'MPNOM' not in pob.columns and 'MPIO' in pob.columns:
    pob = pob.rename(columns={'MPIO': 'MPNOM'})

# --- Normalizar texto de nombres ---
def normalizar(texto):
    if pd.isna(texto):
        return ''
    texto = str(texto).strip().upper()
    texto = unidecode.unidecode(texto)
    texto = ' '.join(texto.split())
    return texto

pob['DPNOM'] = pob['DPNOM'].apply(normalizar)
pob['MPNOM'] = pob['MPNOM'].apply(normalizar)

# --- Filtrar solo filas donde el √°rea geogr√°fica sea TOTAL o TOTALES ---
if 'AREA_GEOGRAFICA' in pob.columns:
    pob = pob[pob['AREA_GEOGRAFICA'].str.contains('TOTAL', case=False, na=False)]

# --- Renombrar columnas para merge posterior ---
pob = pob.rename(columns={
    'DPNOM': 'DEPARTAMENTO',
    'MPNOM': 'CODIGO_DANE_POB	',
    'DPMP': 'MUNICIPIO',
    'TOTAL': 'POBLACION_TOTAL'
})

# --- Filtrar solo a√±o 2018 ---
pob_2021 = pob[pob['A√ëO'] == 2021].copy()

# --- Eliminar duplicados ---
pob_2021 = pob_2021.drop_duplicates(subset=['DEPARTAMENTO', 'MUNICIPIO'])

print(f"‚úÖ Registros de poblaci√≥n 2021 (√°rea TOTAL) procesados: {len(pob_2021):,}")

# --- Vista previa ---
display(pob_2021.head(10))

for col in pob_2021.columns:
    print(f"\n=== {col} ===")
    print(pob_2021[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {pob_2021[col].nunique()}")

# ====================================================
# üî† PASAR TODA LA BASE pob_2018 A MAY√öSCULAS Y NORMALIZAR
# ====================================================

import unidecode
import pandas as pd

def normalizar_texto(valor):
    """Convierte todo texto a may√∫sculas, quita tildes y espacios dobles."""
    if isinstance(valor, str):
        valor = unidecode.unidecode(valor)  # quita tildes
        valor = valor.upper().strip()
        valor = ' '.join(valor.split())      # elimina espacios dobles
    return valor

# Aplicar a todas las columnas de tipo texto
for col in pob_2021.columns:
    if pob_2021[col].dtype == 'object':
        pob_2021[col] = pob_2021[col].apply(normalizar_texto)

print("‚úÖ Toda la base de poblaci√≥n est√° ahora en MAY√öSCULAS y sin tildes.")
display(pob_2021.head(10))

municipios_pob = sorted(pob_2021['MUNICIPIO'].dropna().unique())
print(f"Total de municipios en pob_2021: {len(municipios_pob)}\n")
print(municipios_pob)

import pandas as pd
import unidecode

# --- 1. Funci√≥n de normalizaci√≥n ---
def normalizar(texto):
    """Convierte a may√∫sculas, elimina tildes y espacios extra."""
    if pd.isna(texto):
        return ''
    texto = str(texto).strip().upper()
    texto = unidecode.unidecode(texto)
    texto = ' '.join(texto.split())  # quita espacios dobles
    return texto


# --- 2. Normalizar texto en todas las bases ---
for col in ['DEPARTAMENTO', 'MUNICIPIO']:
    merged_final[col] = merged_final[col].astype(str).apply(normalizar)
    pob_2021[col] = pob_2021[col].astype(str).apply(normalizar)


# --- 3. Reemplazos y correcciones en municipios ---
reemplazos_mpios = {
    "CARTAGENA": "CARTAGENA DE INDIAS",
    "CUCUTA": "SAN JOSE DE CUCUTA",
    "DON MATIAS": "DONMATIAS",
    "GUICAN": "GUICAN DE LA SIERRA",
    "LOPEZ": "LOPEZ DE MICAY",
    "MANAURE": "MANAURE BALCON DEL CESAR",
    "SAN ANDRES DE TUMACO": "SAN ANDRES DE TUMACO",
    "SAN ANDRES SOTAVENTO": "SAN ANDRES DE SOTAVENTO",
    "SAN JUAN DE RIO SECO": "SAN JUAN DE RIOSECO",
    "SAN PEDRO": "SAN PEDRO DE LOS MILAGROS",
    "SAN VICENTE": "SAN VICENTE FERRER",
    "SANTAFE DE ANTIOQUIA": "SANTA FE DE ANTIOQUIA",
    "TOLU VIEJO": "SAN JOSE DE TOLUVIEJO",
    "CALI": "SANTIAGO DE CALI",
    "PURISIMA": "PURISIMA DE LA CONCEPCION",
    "PIENDAMO": "PIENDAMO - TUNIA",
    "SOTARA": "SOTARA - PAISPAMBA",
    "CUASPUD": "CUASPUD CARLOSAMA",  # Correci√≥n manual para CUASPUD
    "CERRO SAN ANTONIO": "CERRO DE SAN ANTONIO",
    "CHIBOLO": "CHIVOLO",
    "MARIQUITA": "SAN SEBASTIAN DE MARIQUITA",
    "LA VICTORIA": "LA VICTORIA AMAZONAS",  # Correci√≥n manual para LA VICTORIA
    "PUERTO SANTANDER": "PUERTO SANTANDER AMAZONAS",  # Correci√≥n manual para PUERTO SANTANDER
    "SANTA CRUZ DE MOMPOX": "SANTA CRUZ DE MOMPOX BOLIVAR",  # Correci√≥n manual para MOMPOX
    "PUERTO COLOMBIA": "PUERTO COLOMBIA GUAINIA"  # Correci√≥n manual para PUERTO COLOMBIA
}

# Aplicamos las correcciones manuales en ambas bases de datos
merged_final['MUNICIPIO'] = merged_final['MUNICIPIO'].replace(reemplazos_mpios)
pob_2021['MUNICIPIO'] = pob_2021['MUNICIPIO'].replace(reemplazos_mpios)


# --- 4. Reemplazos y correcciones en departamentos ---
reemplazos_dptos = {
    "GUAJIRA": "LA GUAJIRA",
    "VALLE": "VALLE DEL CAUCA",
    "SAN ANDRES": "ARCHIPIELAGO DE SAN ANDRES, PROVIDENCIA Y SANTA CATALINA",
    "BOGOTA": "CUNDINAMARCA",
}
merged_final['DEPARTAMENTO'] = merged_final['DEPARTAMENTO'].replace(reemplazos_dptos)
pob_2021['DEPARTAMENTO'] = pob_2021['DEPARTAMENTO'].replace(reemplazos_dptos)


# --- 5. Correcci√≥n especial de Bogot√° ---
mask_bogota = merged_final['MUNICIPIO'].str.contains('BOGOTA', case=False, na=False)
merged_final.loc[mask_bogota, 'DEPARTAMENTO'] = 'CUNDINAMARCA'
merged_final.loc[mask_bogota, 'MUNICIPIO'] = 'BOGOT√Å, D.C.'

mask_bogota_pob = pob_2021['MUNICIPIO'].str.contains('BOGOTA', case=False, na=False)
pob_2021.loc[mask_bogota_pob, 'DEPARTAMENTO'] = 'CUNDINAMARCA'
pob_2021.loc[mask_bogota_pob, 'MUNICIPIO'] = 'BOGOT√Å, D.C.'

# --- 6. Correcciones espec√≠ficas para empalmar con poblaci√≥n ---
pob_2021['MUNICIPIO'] = pob_2021['MUNICIPIO'].replace({
    'MOMPOS': 'SANTA CRUZ DE MOMPOX',
    'SOTARA PAISPAMBA': 'SOTARA - PAISPAMBA'
})

# --- ‚ôôÔ∏è 6B. Correcciones especiales detectadas ---
merged_final['MUNICIPIO'] = merged_final['MUNICIPIO'].replace({
    # AMAZONAS
    'LA VICTORIA AMAZONAS': 'LA VICTORIA',
    'PUERTO SANTANDER AMAZONAS': 'PUERTO SANTANDER',
    # GUAIN√çA
    'PUERTO COLOMBIA GUAINIA': 'PUERTO COLOMBIA',
    # MOMPOX con doble nombre
    'SANTA CRUZ DE MOMPOX BOLIVAR': 'SANTA CRUZ DE MOMPOX',
})

pob_2021['MUNICIPIO'] = pob_2021['MUNICIPIO'].replace({
    'LA VICTORIA AMAZONAS': 'LA VICTORIA',
    'PUERTO SANTANDER AMAZONAS': 'PUERTO SANTANDER',
    'PUERTO COLOMBIA GUAINIA': 'PUERTO COLOMBIA',
    'SANTA CRUZ DE MOMPOX BOLIVAR': 'SANTA CRUZ DE MOMPOX',
})

# --- 6D. Correcci√≥n final para CUASPUD ---
merged_final['MUNICIPIO'] = merged_final['MUNICIPIO'].replace({
    'CUASPUD - CARLOSAMA': 'CUASPUD CARLOSAMA'
})
pob_2021['MUNICIPIO'] = pob_2021['MUNICIPIO'].replace({
    'CUASPUD - CARLOSAMA': 'CUASPUD CARLOSAMA'
})

# --- 6. Asegurar a√±o como entero ---
merged_final['A√ëO'] = 2021 # Add the year 2020 to merged_final
merged_final['A√ëO'] = merged_final['A√ëO'].astype(int)
pob_2021['A√ëO'] = pob_2021['A√ëO'].astype(int)

# --- 6C. Eliminar municipios no oficiales seg√∫n DIVIPOLA ---
municipios_no_oficiales = [
    'LA VICTORIA',
    'PUERTO SANTANDER',
    'PUERTO COLOMBIA'
]
merged_final = merged_final[~merged_final['MUNICIPIO'].isin(municipios_no_oficiales)]


# --- 7. Merge final por departamento, municipio y a√±o ---
df_final_pob = merged_final.merge(
    pob_2021,
    on=['DEPARTAMENTO', 'MUNICIPIO', 'A√ëO'],
    how='left',
    indicator='_merge_pob'
)


# --- 8. Verificar coincidencias faltantes ---
sin_pob = (
    df_final_pob[df_final_pob['_merge_pob'] == 'left_only']
    [['DEPARTAMENTO', 'MUNICIPIO']]
    .drop_duplicates()
    .sort_values(['DEPARTAMENTO', 'MUNICIPIO'])
)
print(f"‚ö†Ô∏è Municipios sin coincidencia de poblaci√≥n: {len(sin_pob)}")
display(sin_pob)


# --- 9. Limpieza final ---
df_final_pob = df_final_pob.drop(columns=['_merge_pob'])

print(f"\n‚úÖ Base final combinada con poblaci√≥n: {df_final_pob.shape[0]:,} filas √ó {df_final_pob.shape[1]} columnas")
display(df_final_pob.head(10))


# --- 10. Exportar resultado ---
df_final_pob.to_excel("delitos_con_poblacion_final2021.xlsx", index=False)
print("üìÅ Archivo exportado: delitos_con_poblacion_final2021.xlsx")

for col in df_final_pob.columns:
    print(f"\n=== {col} ===")
    print(df_final_pob[col].dropna().unique())  # quitar nulos antes de listar
    print(f"Total de valores √∫nicos: {df_final_pob[col].nunique()}")